# æ•™å­¦å¤§çº²ç”Ÿæˆç³»ç»Ÿæ•°æ®æ¨¡å‹è®¾è®¡

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†æ•™å­¦å¤§çº²ç”Ÿæˆç³»ç»Ÿçš„æ•°æ®æ¨¡å‹è®¾è®¡ï¼ŒåŒ…æ‹¬æ–°å¢æ¨¡å‹ã€ç°æœ‰æ¨¡å‹æ‰©å±•ã€æ•°æ®å…³ç³»è®¾è®¡å’Œæ•°æ®åº“ä¼˜åŒ–ç­–ç•¥ã€‚

## ğŸ—„ï¸ æ•°æ®æ¨¡å‹æ¶æ„

### æ¨¡å‹åˆ†å±‚è®¾è®¡

```mermaid
graph TB
    subgraph "ä¸šåŠ¡æ ¸å¿ƒå±‚"
        A[TeachingPreparationWorkflow]
        B[IterativeAnalysisSession]
        C[KnowledgePointHierarchy]
        D[CourseHourAllocation]
        E[PersonalizedLessonPlan]
    end

    subgraph "åˆ†æç»“æœå±‚"
        F[AnalysisRoundResult]
        G[KnowledgePointMapping]
        H[QualityAssessment]
        I[HumanReviewRecord]
    end

    subgraph "åŸºç¡€æ•°æ®å±‚"
        J[EnhancedExamSyllabus]
        K[TextbookContent]
        L[CourseAssignment]
        M[User]
    end

    A --> B
    A --> C
    A --> D
    A --> E
    B --> F
    C --> G
    F --> H
    A --> I

    B --> J
    B --> K
    A --> L
    A --> M
```

## ğŸ†• æ–°å¢æ ¸å¿ƒæ¨¡å‹

### 1. æ•™å­¦å‡†å¤‡å·¥ä½œæµæ¨¡å‹

```python
class TeachingPreparationWorkflow(BaseModel, UserRelatedModel, StatusTrackingModel):
    """æ•™å­¦å‡†å¤‡å·¥ä½œæµ - ç®¡ç†6é˜¶æ®µå¤„ç†æµç¨‹"""

    STAGE_CHOICES = [
        ('course_info', 'è¯¾ç¨‹ä¿¡æ¯ç¡®å®š'),
        ('resource_collection', 'èµ„æºæ”¶é›†éªŒè¯'),
        ('syllabus_analysis', 'è€ƒçº²å¤šè½®åˆ†æ'),
        ('textbook_analysis', 'æ•™æå¤šè½®åˆ†æ'),
        ('syllabus_generation', 'æ™ºèƒ½å¤§çº²ç”Ÿæˆ'),
        ('lesson_plan_generation', 'ä¸ªæ€§åŒ–æ•™æ¡ˆç”Ÿæˆ'),
    ]

    WORKFLOW_STATUS_CHOICES = [
        ('created', 'å·²åˆ›å»º'),
        ('in_progress', 'è¿›è¡Œä¸­'),
        ('paused', 'å·²æš‚åœ'),
        ('completed', 'å·²å®Œæˆ'),
        ('failed', 'å¤±è´¥'),
        ('cancelled', 'å·²å–æ¶ˆ'),
    ]

    # å…³è”å­—æ®µ
    course_assignment = models.OneToOneField(
        'learning.CourseAssignment',
        on_delete=models.CASCADE,
        verbose_name="è¯¾ç¨‹åˆ†é…",
        related_name="preparation_workflow"
    )

    # å·¥ä½œæµçŠ¶æ€
    workflow_status = models.CharField(
        max_length=20,
        choices=WORKFLOW_STATUS_CHOICES,
        default='created',
        verbose_name="å·¥ä½œæµçŠ¶æ€",
        db_index=True
    )
    current_stage = models.CharField(
        max_length=30,
        choices=STAGE_CHOICES,
        default='course_info',
        verbose_name="å½“å‰é˜¶æ®µ",
        db_index=True
    )

    # é˜¶æ®µçŠ¶æ€è·Ÿè¸ª
    stage_status = models.JSONField(
        default=dict,
        verbose_name="å„é˜¶æ®µçŠ¶æ€",
        help_text="è®°å½•æ¯ä¸ªé˜¶æ®µçš„å®ŒæˆçŠ¶æ€å’Œæ—¶é—´"
    )
    stage_results = models.JSONField(
        default=dict,
        verbose_name="å„é˜¶æ®µç»“æœ",
        help_text="å­˜å‚¨æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºç»“æœ"
    )
    quality_scores = models.JSONField(
        default=dict,
        verbose_name="è´¨é‡è¯„åˆ†",
        help_text="å„é˜¶æ®µçš„è´¨é‡è¯„åˆ†è®°å½•"
    )

    # äººå·¥ç›‘ç£è®°å½•
    human_review_points = models.JSONField(
        default=list,
        verbose_name="äººå·¥å®¡æ ¸è®°å½•",
        help_text="è®°å½•äººå·¥å¹²é¢„å’Œå®¡æ ¸çš„èŠ‚ç‚¹"
    )

    # é…ç½®å‚æ•°
    workflow_config = models.JSONField(
        default=dict,
        verbose_name="å·¥ä½œæµé…ç½®",
        help_text="å·¥ä½œæµæ‰§è¡Œçš„é…ç½®å‚æ•°"
    )

    # æ—¶é—´è·Ÿè¸ª
    started_at = models.DateTimeField(
        null=True, blank=True,
        verbose_name="å¼€å§‹æ—¶é—´"
    )
    completed_at = models.DateTimeField(
        null=True, blank=True,
        verbose_name="å®Œæˆæ—¶é—´"
    )
    estimated_completion_time = models.DateTimeField(
        null=True, blank=True,
        verbose_name="é¢„è®¡å®Œæˆæ—¶é—´"
    )

    # é”™è¯¯å¤„ç†
    error_log = models.JSONField(
        default=list,
        verbose_name="é”™è¯¯æ—¥å¿—",
        help_text="è®°å½•å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ä¿¡æ¯"
    )

    class Meta:
        db_table = "teaching_preparation_workflows"
        verbose_name = "æ•™å­¦å‡†å¤‡å·¥ä½œæµ"
        verbose_name_plural = "æ•™å­¦å‡†å¤‡å·¥ä½œæµ"
        indexes = [
            models.Index(fields=["user", "workflow_status"]),
            models.Index(fields=["current_stage", "created_at"]),
            models.Index(fields=["course_assignment", "workflow_status"]),
        ]
        ordering = ["-created_at"]

    def __str__(self):
        return f"å·¥ä½œæµ-{self.course_assignment.course.name}-{self.get_current_stage_display()}"

    def get_stage_completion_percentage(self):
        """è·å–æ•´ä½“å®Œæˆç™¾åˆ†æ¯”"""
        total_stages = len(self.STAGE_CHOICES)
        completed_stages = sum(
            1 for stage_code, _ in self.STAGE_CHOICES
            if self.stage_status.get(stage_code, {}).get('status') == 'completed'
        )
        return (completed_stages / total_stages) * 100

    def can_advance_to_next_stage(self):
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥æ¨è¿›åˆ°ä¸‹ä¸€é˜¶æ®µ"""
        current_stage_status = self.stage_status.get(self.current_stage, {})
        return current_stage_status.get('status') == 'completed'

    def get_next_stage(self):
        """è·å–ä¸‹ä¸€é˜¶æ®µ"""
        stage_codes = [code for code, _ in self.STAGE_CHOICES]
        current_index = stage_codes.index(self.current_stage)

        if current_index < len(stage_codes) - 1:
            return stage_codes[current_index + 1]
        return None

    def mark_stage_completed(self, stage, result_data, quality_score=None):
        """æ ‡è®°é˜¶æ®µå®Œæˆ"""
        self.stage_status[stage] = {
            'status': 'completed',
            'completed_at': timezone.now().isoformat(),
            'quality_score': quality_score
        }
        self.stage_results[stage] = result_data

        if quality_score:
            self.quality_scores[stage] = quality_score

        self.save()

    def add_human_review(self, stage, reviewer, decision, comments):
        """æ·»åŠ äººå·¥å®¡æ ¸è®°å½•"""
        review_record = {
            'stage': stage,
            'reviewer_id': reviewer.id,
            'reviewer_name': reviewer.get_full_name(),
            'decision': decision,  # 'approved', 'rejected', 'needs_revision'
            'comments': comments,
            'review_time': timezone.now().isoformat()
        }
        self.human_review_points.append(review_record)
        self.save()
```

### 2. è¿­ä»£åˆ†æä¼šè¯æ¨¡å‹

```python
class IterativeAnalysisSession(BaseModel, JSONDataMixin):
    """è¿­ä»£åˆ†æä¼šè¯ - ç®¡ç†å¤šè½®AIåˆ†æè¿‡ç¨‹"""

    DOCUMENT_TYPE_CHOICES = [
        ('syllabus', 'è€ƒè¯•å¤§çº²'),
        ('textbook', 'æ•™æå†…å®¹'),
        ('reference', 'å‚è€ƒèµ„æ–™'),
    ]

    SESSION_STATUS_CHOICES = [
        ('created', 'å·²åˆ›å»º'),
        ('analyzing', 'åˆ†æä¸­'),
        ('paused', 'å·²æš‚åœ'),
        ('completed', 'å·²å®Œæˆ'),
        ('failed', 'å¤±è´¥'),
        ('terminated', 'å·²ç»ˆæ­¢'),
    ]

    TERMINATION_REASON_CHOICES = [
        ('quality_threshold_met', 'è´¨é‡é˜ˆå€¼è¾¾åˆ°'),
        ('max_rounds_reached', 'è¾¾åˆ°æœ€å¤§è½®æ¬¡'),
        ('quality_converged', 'è´¨é‡æ”¶æ•›'),
        ('content_saturated', 'å†…å®¹é¥±å’Œ'),
        ('manual_termination', 'äººå·¥ç»ˆæ­¢'),
        ('error_occurred', 'å‘ç”Ÿé”™è¯¯'),
    ]

    # å…³è”å­—æ®µ
    workflow = models.ForeignKey(
        TeachingPreparationWorkflow,
        on_delete=models.CASCADE,
        verbose_name="æ‰€å±å·¥ä½œæµ",
        related_name="analysis_sessions"
    )

    # åˆ†æé…ç½®
    document_type = models.CharField(
        max_length=20,
        choices=DOCUMENT_TYPE_CHOICES,
        verbose_name="æ–‡æ¡£ç±»å‹",
        db_index=True
    )
    document_reference = models.JSONField(
        default=dict,
        verbose_name="æ–‡æ¡£å¼•ç”¨",
        help_text="å­˜å‚¨æ–‡æ¡£çš„å¼•ç”¨ä¿¡æ¯"
    )

    # ä¼šè¯çŠ¶æ€
    session_status = models.CharField(
        max_length=20,
        choices=SESSION_STATUS_CHOICES,
        default='created',
        verbose_name="ä¼šè¯çŠ¶æ€",
        db_index=True
    )
    current_round = models.PositiveIntegerField(
        default=0,
        verbose_name="å½“å‰è½®æ¬¡"
    )
    max_rounds = models.PositiveIntegerField(
        default=5,
        verbose_name="æœ€å¤§è½®æ¬¡"
    )

    # åˆ†æé…ç½®
    analysis_config = models.JSONField(
        default=dict,
        verbose_name="åˆ†æé…ç½®",
        help_text="åˆ†æå‚æ•°å’Œé…ç½®é€‰é¡¹"
    )
    quality_threshold = models.FloatField(
        default=0.85,
        verbose_name="è´¨é‡é˜ˆå€¼",
        validators=[MinValueValidator(0.0), MaxValueValidator(1.0)]
    )

    # ä¸Šä¸‹æ–‡æ•°æ®
    context_data = models.JSONField(
        default=dict,
        verbose_name="ä¸Šä¸‹æ–‡æ•°æ®",
        help_text="åˆ†æè¿‡ç¨‹ä¸­ç§¯ç´¯çš„ä¸Šä¸‹æ–‡ä¿¡æ¯"
    )

    # ç»ˆæ­¢æ¡ä»¶
    termination_reason = models.CharField(
        max_length=30,
        choices=TERMINATION_REASON_CHOICES,
        blank=True,
        verbose_name="ç»ˆæ­¢åŸå› "
    )
    termination_details = models.JSONField(
        default=dict,
        verbose_name="ç»ˆæ­¢è¯¦æƒ…",
        help_text="ç»ˆæ­¢æ—¶çš„è¯¦ç»†ä¿¡æ¯"
    )

    # æ—¶é—´è·Ÿè¸ª
    started_at = models.DateTimeField(
        null=True, blank=True,
        verbose_name="å¼€å§‹æ—¶é—´"
    )
    completed_at = models.DateTimeField(
        null=True, blank=True,
        verbose_name="å®Œæˆæ—¶é—´"
    )
    estimated_remaining_time = models.DurationField(
        null=True, blank=True,
        verbose_name="é¢„è®¡å‰©ä½™æ—¶é—´"
    )

    # èµ„æºä½¿ç”¨ç»Ÿè®¡
    total_tokens_used = models.PositiveIntegerField(
        default=0,
        verbose_name="æ€»Tokenä½¿ç”¨é‡"
    )
    total_cost = models.DecimalField(
        max_digits=10, decimal_places=4,
        default=0,
        verbose_name="æ€»æˆæœ¬"
    )

    class Meta:
        db_table = "iterative_analysis_sessions"
        verbose_name = "è¿­ä»£åˆ†æä¼šè¯"
        verbose_name_plural = "è¿­ä»£åˆ†æä¼šè¯"
        indexes = [
            models.Index(fields=["workflow", "document_type"]),
            models.Index(fields=["session_status", "created_at"]),
            models.Index(fields=["current_round", "max_rounds"]),
        ]
        ordering = ["-created_at"]

    def __str__(self):
        return f"åˆ†æä¼šè¯-{self.get_document_type_display()}-ç¬¬{self.current_round}è½®"

    def get_progress_percentage(self):
        """è·å–åˆ†æè¿›åº¦ç™¾åˆ†æ¯”"""
        if self.max_rounds == 0:
            return 0
        return min((self.current_round / self.max_rounds) * 100, 100)

    def get_latest_quality_score(self):
        """è·å–æœ€æ–°çš„è´¨é‡è¯„åˆ†"""
        latest_round = self.round_results.order_by('-round_number').first()
        return latest_round.quality_score if latest_round else 0

    def can_continue_analysis(self):
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥ç»§ç»­åˆ†æ"""
        return (
            self.session_status == 'analyzing' and
            self.current_round < self.max_rounds and
            not self.termination_reason
        )

    def estimate_remaining_time(self):
        """ä¼°ç®—å‰©ä½™æ—¶é—´"""
        if self.current_round == 0:
            return timedelta(minutes=30)  # é»˜è®¤ä¼°ç®—

        # åŸºäºå·²å®Œæˆè½®æ¬¡çš„å¹³å‡æ—¶é—´ä¼°ç®—
        completed_rounds = self.round_results.filter(status='completed')
        if completed_rounds.exists():
            avg_time_per_round = sum(
                (r.completed_at - r.started_at).total_seconds()
                for r in completed_rounds
            ) / completed_rounds.count()

            remaining_rounds = self.max_rounds - self.current_round
            return timedelta(seconds=avg_time_per_round * remaining_rounds)

        return timedelta(minutes=20)  # é»˜è®¤ä¼°ç®—
```

### 3. åˆ†æè½®æ¬¡ç»“æœæ¨¡å‹

```python
class AnalysisRoundResult(BaseModel, JSONDataMixin):
    """åˆ†æè½®æ¬¡ç»“æœ - å­˜å‚¨æ¯è½®åˆ†æçš„è¯¦ç»†ç»“æœ"""

    ROUND_STATUS_CHOICES = [
        ('pending', 'å¾…å¤„ç†'),
        ('processing', 'å¤„ç†ä¸­'),
        ('completed', 'å·²å®Œæˆ'),
        ('failed', 'å¤±è´¥'),
        ('skipped', 'å·²è·³è¿‡'),
    ]

    ANALYSIS_FOCUS_CHOICES = [
        ('framework', 'æ¡†æ¶åˆ†æ'),
        ('content_deep_dive', 'å†…å®¹æ·±åº¦åˆ†æ'),
        ('knowledge_extraction', 'çŸ¥è¯†ç‚¹æå–'),
        ('relationship_analysis', 'å…³ç³»åˆ†æ'),
        ('quality_refinement', 'è´¨é‡ä¼˜åŒ–'),
    ]

    # å…³è”å­—æ®µ
    analysis_session = models.ForeignKey(
        IterativeAnalysisSession,
        on_delete=models.CASCADE,
        verbose_name="åˆ†æä¼šè¯",
        related_name="round_results"
    )

    # è½®æ¬¡ä¿¡æ¯
    round_number = models.PositiveIntegerField(
        verbose_name="è½®æ¬¡ç¼–å·",
        db_index=True
    )
    round_status = models.CharField(
        max_length=20,
        choices=ROUND_STATUS_CHOICES,
        default='pending',
        verbose_name="è½®æ¬¡çŠ¶æ€"
    )
    analysis_focus = models.CharField(
        max_length=30,
        choices=ANALYSIS_FOCUS_CHOICES,
        verbose_name="åˆ†æç„¦ç‚¹"
    )

    # è¾“å…¥æ•°æ®
    input_context = models.JSONField(
        default=dict,
        verbose_name="è¾“å…¥ä¸Šä¸‹æ–‡",
        help_text="æœ¬è½®åˆ†æçš„è¾“å…¥ä¸Šä¸‹æ–‡æ•°æ®"
    )
    focus_areas = models.JSONField(
        default=list,
        verbose_name="ç„¦ç‚¹é¢†åŸŸ",
        help_text="æœ¬è½®é‡ç‚¹åˆ†æçš„é¢†åŸŸ"
    )

    # åˆ†æç»“æœ
    extracted_content = models.JSONField(
        default=dict,
        verbose_name="æå–å†…å®¹",
        help_text="æœ¬è½®åˆ†ææå–çš„ç»“æ„åŒ–å†…å®¹"
    )
    analysis_insights = models.JSONField(
        default=list,
        verbose_name="åˆ†ææ´å¯Ÿ",
        help_text="æœ¬è½®åˆ†æäº§ç”Ÿçš„å…³é”®æ´å¯Ÿ"
    )
    improvements_identified = models.JSONField(
        default=list,
        verbose_name="è¯†åˆ«çš„æ”¹è¿›ç‚¹",
        help_text="ç›¸æ¯”å‰è½®çš„æ”¹è¿›å’Œä¼˜åŒ–ç‚¹"
    )

    # è´¨é‡è¯„ä¼°
    quality_score = models.FloatField(
        default=0.0,
        verbose_name="è´¨é‡è¯„åˆ†",
        validators=[MinValueValidator(0.0), MaxValueValidator(1.0)]
    )
    quality_metrics = models.JSONField(
        default=dict,
        verbose_name="è´¨é‡æŒ‡æ ‡",
        help_text="è¯¦ç»†çš„è´¨é‡è¯„ä¼°æŒ‡æ ‡"
    )

    # AIè°ƒç”¨ä¿¡æ¯
    ai_model_used = models.CharField(
        max_length=50,
        default='deepseek-chat',
        verbose_name="ä½¿ç”¨çš„AIæ¨¡å‹"
    )
    tokens_used = models.PositiveIntegerField(
        default=0,
        verbose_name="Tokenä½¿ç”¨é‡"
    )
    processing_cost = models.DecimalField(
        max_digits=8, decimal_places=4,
        default=0,
        verbose_name="å¤„ç†æˆæœ¬"
    )

    # æ—¶é—´è·Ÿè¸ª
    started_at = models.DateTimeField(
        null=True, blank=True,
        verbose_name="å¼€å§‹æ—¶é—´"
    )
    completed_at = models.DateTimeField(
        null=True, blank=True,
        verbose_name="å®Œæˆæ—¶é—´"
    )
    processing_duration = models.DurationField(
        null=True, blank=True,
        verbose_name="å¤„ç†æ—¶é•¿"
    )

    # é”™è¯¯ä¿¡æ¯
    error_message = models.TextField(
        blank=True,
        verbose_name="é”™è¯¯ä¿¡æ¯"
    )
    error_details = models.JSONField(
        default=dict,
        verbose_name="é”™è¯¯è¯¦æƒ…"
    )

    class Meta:
        db_table = "analysis_round_results"
        verbose_name = "åˆ†æè½®æ¬¡ç»“æœ"
        verbose_name_plural = "åˆ†æè½®æ¬¡ç»“æœ"
        indexes = [
            models.Index(fields=["analysis_session", "round_number"]),
            models.Index(fields=["round_status", "created_at"]),
            models.Index(fields=["quality_score", "round_number"]),
        ]
        unique_together = [["analysis_session", "round_number"]]
        ordering = ["analysis_session", "round_number"]

    def __str__(self):
        return f"ç¬¬{self.round_number}è½®-{self.get_analysis_focus_display()}"

    def get_processing_time(self):
        """è·å–å¤„ç†æ—¶é—´"""
        if self.started_at and self.completed_at:
            return self.completed_at - self.started_at
        return None

    def calculate_improvement_rate(self):
        """è®¡ç®—ç›¸æ¯”å‰è½®çš„æ”¹è¿›ç‡"""
        previous_round = AnalysisRoundResult.objects.filter(
            analysis_session=self.analysis_session,
            round_number=self.round_number - 1
        ).first()

        if previous_round and previous_round.quality_score > 0:
            return (self.quality_score - previous_round.quality_score) / previous_round.quality_score
        return 0

    def get_new_content_ratio(self):
        """è·å–æ–°å¢å†…å®¹æ¯”ä¾‹"""
        previous_round = AnalysisRoundResult.objects.filter(
            analysis_session=self.analysis_session,
            round_number=self.round_number - 1
        ).first()

        if not previous_round:
            return 1.0  # ç¬¬ä¸€è½®å…¨æ˜¯æ–°å†…å®¹

        # è®¡ç®—æ–°å¢å†…å®¹çš„æ¯”ä¾‹ï¼ˆç®€åŒ–å®ç°ï¼‰
        current_content_size = len(str(self.extracted_content))
        previous_content_size = len(str(previous_round.extracted_content))

        if previous_content_size == 0:
            return 1.0

        return max(0, (current_content_size - previous_content_size) / previous_content_size)
```

### 4. çŸ¥è¯†ç‚¹å±‚çº§ç»“æ„æ¨¡å‹

```python
class KnowledgePointHierarchy(BaseModel, JSONDataMixin):
    """çŸ¥è¯†ç‚¹å±‚çº§ç»“æ„ - å­˜å‚¨çŸ¥è¯†ç‚¹å…³ç³»å’Œæƒé‡"""

    HIERARCHY_TYPE_CHOICES = [
        ('syllabus', 'è€ƒçº²çŸ¥è¯†ç‚¹'),
        ('textbook', 'æ•™æçŸ¥è¯†ç‚¹'),
        ('integrated', 'æ•´åˆçŸ¥è¯†ç‚¹'),
    ]

    # å…³è”å­—æ®µ
    workflow = models.ForeignKey(
        TeachingPreparationWorkflow,
        on_delete=models.CASCADE,
        verbose_name="æ‰€å±å·¥ä½œæµ",
        related_name="knowledge_hierarchies"
    )
    source_analysis_session = models.ForeignKey(
        IterativeAnalysisSession,
        on_delete=models.CASCADE,
        verbose_name="æºåˆ†æä¼šè¯",
        related_name="generated_hierarchies"
    )

    # å±‚çº§ä¿¡æ¯
    hierarchy_type = models.CharField(
        max_length=20,
        choices=HIERARCHY_TYPE_CHOICES,
        verbose_name="å±‚çº§ç±»å‹",
        db_index=True
    )
    hierarchy_version = models.CharField(
        max_length=20,
        default='1.0',
        verbose_name="å±‚çº§ç‰ˆæœ¬"
    )

    # å±‚çº§æ•°æ®
    hierarchy_data = models.JSONField(
        default=dict,
        verbose_name="å±‚çº§ç»“æ„æ•°æ®",
        help_text="å®Œæ•´çš„çŸ¥è¯†ç‚¹å±‚çº§ç»“æ„"
    )
    knowledge_points = models.JSONField(
        default=list,
        verbose_name="çŸ¥è¯†ç‚¹åˆ—è¡¨",
        help_text="æ‰å¹³åŒ–çš„çŸ¥è¯†ç‚¹åˆ—è¡¨"
    )

    # æƒé‡å’Œå…³ç³»
    importance_weights = models.JSONField(
        default=dict,
        verbose_name="é‡è¦æ€§æƒé‡",
        help_text="å„çŸ¥è¯†ç‚¹çš„é‡è¦æ€§æƒé‡"
    )
    dependency_graph = models.JSONField(
        default=dict,
        verbose_name="ä¾èµ–å…³ç³»å›¾",
        help_text="çŸ¥è¯†ç‚¹é—´çš„ä¾èµ–å…³ç³»"
    )
    difficulty_levels = models.JSONField(
        default=dict,
        verbose_name="éš¾åº¦ç­‰çº§",
        help_text="å„çŸ¥è¯†ç‚¹çš„éš¾åº¦ç­‰çº§"
    )

    # ç»Ÿè®¡ä¿¡æ¯
    total_knowledge_points = models.PositiveIntegerField(
        default=0,
        verbose_name="çŸ¥è¯†ç‚¹æ€»æ•°"
    )
    max_depth = models.PositiveIntegerField(
        default=0,
        verbose_name="æœ€å¤§å±‚çº§æ·±åº¦"
    )
    coverage_score = models.FloatField(
        default=0.0,
        verbose_name="è¦†ç›–åº¦è¯„åˆ†",
        validators=[MinValueValidator(0.0), MaxValueValidator(1.0)]
    )

    # è´¨é‡è¯„ä¼°
    hierarchy_quality_score = models.FloatField(
        default=0.0,
        verbose_name="å±‚çº§è´¨é‡è¯„åˆ†",
        validators=[MinValueValidator(0.0), MaxValueValidator(1.0)]
    )
    validation_results = models.JSONField(
        default=dict,
        verbose_name="éªŒè¯ç»“æœ",
        help_text="å±‚çº§ç»“æ„çš„éªŒè¯ç»“æœ"
    )

    class Meta:
        db_table = "knowledge_point_hierarchies"
        verbose_name = "çŸ¥è¯†ç‚¹å±‚çº§ç»“æ„"
        verbose_name_plural = "çŸ¥è¯†ç‚¹å±‚çº§ç»“æ„"
        indexes = [
            models.Index(fields=["workflow", "hierarchy_type"]),
            models.Index(fields=["hierarchy_quality_score", "created_at"]),
            models.Index(fields=["total_knowledge_points", "max_depth"]),
        ]
        ordering = ["-created_at"]

    def __str__(self):
        return f"{self.get_hierarchy_type_display()}-{self.total_knowledge_points}ä¸ªçŸ¥è¯†ç‚¹"

    def get_knowledge_point_by_id(self, point_id):
        """æ ¹æ®IDè·å–çŸ¥è¯†ç‚¹"""
        for point in self.knowledge_points:
            if point.get('id') == point_id:
                return point
        return None

    def get_children_points(self, parent_id):
        """è·å–å­çŸ¥è¯†ç‚¹"""
        children = []
        for point in self.knowledge_points:
            if point.get('parent_id') == parent_id:
                children.append(point)
        return children

    def calculate_point_weight(self, point_id):
        """è®¡ç®—çŸ¥è¯†ç‚¹æƒé‡"""
        base_weight = self.importance_weights.get(point_id, 0.5)

        # è€ƒè™‘å­èŠ‚ç‚¹æƒé‡
        children = self.get_children_points(point_id)
        if children:
            children_weight = sum(
                self.importance_weights.get(child['id'], 0.5)
                for child in children
            ) / len(children)
            # çˆ¶èŠ‚ç‚¹æƒé‡ = è‡ªèº«æƒé‡ * 0.6 + å­èŠ‚ç‚¹å¹³å‡æƒé‡ * 0.4
            return base_weight * 0.6 + children_weight * 0.4

        return base_weight

    def get_learning_path(self, target_point_id):
        """è·å–åˆ°ç›®æ ‡çŸ¥è¯†ç‚¹çš„å­¦ä¹ è·¯å¾„"""
        path = []
        current_id = target_point_id

        while current_id:
            point = self.get_knowledge_point_by_id(current_id)
            if not point:
                break

            path.insert(0, point)
            current_id = point.get('parent_id')

        return path
```

### 5. è¯¾æ—¶åˆ†é…æ–¹æ¡ˆæ¨¡å‹

```python
class CourseHourAllocation(BaseModel, JSONDataMixin):
    """è¯¾æ—¶åˆ†é…æ–¹æ¡ˆ - æ™ºèƒ½è¯¾æ—¶åˆ†é…ç»“æœ"""

    ALLOCATION_STRATEGY_CHOICES = [
        ('importance_weighted', 'é‡è¦æ€§æƒé‡åˆ†é…'),
        ('difficulty_adjusted', 'éš¾åº¦è°ƒæ•´åˆ†é…'),
        ('balanced', 'å¹³è¡¡åˆ†é…'),
        ('custom', 'è‡ªå®šä¹‰åˆ†é…'),
    ]

    ALLOCATION_STATUS_CHOICES = [
        ('draft', 'è‰ç¨¿'),
        ('calculated', 'å·²è®¡ç®—'),
        ('reviewed', 'å·²å®¡æ ¸'),
        ('approved', 'å·²æ‰¹å‡†'),
        ('implemented', 'å·²å®æ–½'),
    ]

    # å…³è”å­—æ®µ
    workflow = models.OneToOneField(
        TeachingPreparationWorkflow,
        on_delete=models.CASCADE,
        verbose_name="æ‰€å±å·¥ä½œæµ",
        related_name="hour_allocation"
    )
    knowledge_hierarchy = models.ForeignKey(
        KnowledgePointHierarchy,
        on_delete=models.CASCADE,
        verbose_name="çŸ¥è¯†ç‚¹å±‚çº§",
        related_name="hour_allocations"
    )

    # åˆ†é…ç­–ç•¥
    allocation_strategy = models.CharField(
        max_length=30,
        choices=ALLOCATION_STRATEGY_CHOICES,
        verbose_name="åˆ†é…ç­–ç•¥",
        db_index=True
    )
    allocation_status = models.CharField(
        max_length=20,
        choices=ALLOCATION_STATUS_CHOICES,
        default='draft',
        verbose_name="åˆ†é…çŠ¶æ€"
    )

    # è¯¾ç¨‹é…ç½®
    total_hours = models.PositiveIntegerField(
        verbose_name="æ€»è¯¾æ—¶æ•°"
    )
    available_hour_modes = models.JSONField(
        default=list,
        verbose_name="å¯ç”¨è¯¾æ—¶æ¨¡å¼",
        help_text="å¦‚[2, 4]è¡¨ç¤ºæ”¯æŒ2è¯¾æ—¶å’Œ4è¯¾æ—¶æ¨¡å¼"
    )
    course_constraints = models.JSONField(
        default=dict,
        verbose_name="è¯¾ç¨‹çº¦æŸ",
        help_text="è¯¾ç¨‹ç›¸å…³çš„çº¦æŸæ¡ä»¶"
    )

    # åˆ†é…ç»“æœ
    hour_distribution = models.JSONField(
        default=dict,
        verbose_name="è¯¾æ—¶åˆ†é…è¯¦æƒ…",
        help_text="è¯¦ç»†çš„è¯¾æ—¶åˆ†é…ç»“æœ"
    )
    session_breakdown = models.JSONField(
        default=list,
        verbose_name="è¯¾æ¬¡åˆ†è§£",
        help_text="æŒ‰è¯¾æ¬¡çš„è¯¦ç»†åˆ†è§£"
    )

    # åˆ†é…ä¾æ®
    allocation_rationale = models.JSONField(
        default=dict,
        verbose_name="åˆ†é…ä¾æ®",
        help_text="åˆ†é…å†³ç­–çš„è¯¦ç»†ä¾æ®"
    )
    weight_factors = models.JSONField(
        default=dict,
        verbose_name="æƒé‡å› å­",
        help_text="å½±å“åˆ†é…çš„å„ç§æƒé‡å› å­"
    )

    # äººå·¥è°ƒæ•´
    manual_adjustments = models.JSONField(
        default=list,
        verbose_name="äººå·¥è°ƒæ•´è®°å½•",
        help_text="äººå·¥è°ƒæ•´çš„å†å²è®°å½•"
    )
    adjustment_reasons = models.JSONField(
        default=dict,
        verbose_name="è°ƒæ•´åŸå› ",
        help_text="äººå·¥è°ƒæ•´çš„åŸå› è¯´æ˜"
    )

    # è´¨é‡è¯„ä¼°
    allocation_quality_score = models.FloatField(
        default=0.0,
        verbose_name="åˆ†é…è´¨é‡è¯„åˆ†",
        validators=[MinValueValidator(0.0), MaxValueValidator(10.0)]
    )
    feasibility_score = models.FloatField(
        default=0.0,
        verbose_name="å¯è¡Œæ€§è¯„åˆ†",
        validators=[MinValueValidator(0.0), MaxValueValidator(10.0)]
    )
    teacher_satisfaction_score = models.FloatField(
        null=True, blank=True,
        verbose_name="æ•™å¸ˆæ»¡æ„åº¦è¯„åˆ†",
        validators=[MinValueValidator(0.0), MaxValueValidator(10.0)]
    )

    # å®æ–½è·Ÿè¸ª
    implementation_progress = models.JSONField(
        default=dict,
        verbose_name="å®æ–½è¿›åº¦",
        help_text="è¯¾æ—¶åˆ†é…çš„å®é™…å®æ–½è¿›åº¦"
    )
    actual_hours_used = models.JSONField(
        default=dict,
        verbose_name="å®é™…ä½¿ç”¨è¯¾æ—¶",
        help_text="å®é™…æ•™å­¦ä¸­ä½¿ç”¨çš„è¯¾æ—¶è®°å½•"
    )

    class Meta:
        db_table = "course_hour_allocations"
        verbose_name = "è¯¾æ—¶åˆ†é…æ–¹æ¡ˆ"
        verbose_name_plural = "è¯¾æ—¶åˆ†é…æ–¹æ¡ˆ"
        indexes = [
            models.Index(fields=["workflow", "allocation_status"]),
            models.Index(fields=["allocation_strategy", "created_at"]),
            models.Index(fields=["allocation_quality_score", "feasibility_score"]),
        ]
        ordering = ["-created_at"]

    def __str__(self):
        return f"è¯¾æ—¶åˆ†é…-{self.total_hours}è¯¾æ—¶-{self.get_allocation_strategy_display()}"

    def get_total_allocated_hours(self):
        """è·å–æ€»åˆ†é…è¯¾æ—¶"""
        total = 0
        for knowledge_point in self.hour_distribution.get('knowledge_points', []):
            total += knowledge_point.get('final_hours', 0)
        return total

    def get_allocation_efficiency(self):
        """è·å–åˆ†é…æ•ˆç‡"""
        allocated = self.get_total_allocated_hours()
        if self.total_hours == 0:
            return 0
        return (allocated / self.total_hours) * 100

    def add_manual_adjustment(self, knowledge_point_id, old_hours, new_hours, reason, adjuster):
        """æ·»åŠ äººå·¥è°ƒæ•´è®°å½•"""
        adjustment = {
            'knowledge_point_id': knowledge_point_id,
            'old_hours': old_hours,
            'new_hours': new_hours,
            'reason': reason,
            'adjuster_id': adjuster.id,
            'adjuster_name': adjuster.get_full_name(),
            'adjustment_time': timezone.now().isoformat()
        }
        self.manual_adjustments.append(adjustment)

        # æ›´æ–°åˆ†é…ç»“æœ
        for kp in self.hour_distribution.get('knowledge_points', []):
            if kp.get('id') == knowledge_point_id:
                kp['final_hours'] = new_hours
                kp['manually_adjusted'] = True
                break

        self.save()

    def calculate_variance_from_optimal(self):
        """è®¡ç®—ä¸æœ€ä¼˜åˆ†é…çš„æ–¹å·®"""
        variances = []
        for kp in self.hour_distribution.get('knowledge_points', []):
            optimal_hours = kp.get('optimal_hours', 0)
            final_hours = kp.get('final_hours', 0)
            if optimal_hours > 0:
                variance = abs(final_hours - optimal_hours) / optimal_hours
                variances.append(variance)

        return sum(variances) / len(variances) if variances else 0
```

## ğŸ”„ ç°æœ‰æ¨¡å‹æ‰©å±•

### æ‰©å±• EnhancedExamSyllabus æ¨¡å‹

```python
# åœ¨ç°æœ‰æ¨¡å‹åŸºç¡€ä¸Šæ·»åŠ å­—æ®µ
class EnhancedExamSyllabus(BaseModel, UserRelatedModel, StatusTrackingModel, JSONDataMixin):
    # ... ç°æœ‰å­—æ®µ ...

    # æ–°å¢ï¼šå¤šè½®åˆ†ææ”¯æŒ
    analysis_sessions_count = models.PositiveIntegerField(
        default=0,
        verbose_name="åˆ†æä¼šè¯æ•°é‡"
    )
    latest_analysis_session = models.ForeignKey(
        'IterativeAnalysisSession',
        on_delete=models.SET_NULL,
        null=True, blank=True,
        verbose_name="æœ€æ–°åˆ†æä¼šè¯",
        related_name="+"
    )

    # æ–°å¢ï¼šçŸ¥è¯†ç‚¹å±‚çº§å…³è”
    knowledge_hierarchy = models.OneToOneField(
        'KnowledgePointHierarchy',
        on_delete=models.SET_NULL,
        null=True, blank=True,
        verbose_name="çŸ¥è¯†ç‚¹å±‚çº§",
        related_name="source_syllabus"
    )

    # æ–°å¢ï¼šåˆ†æå†å²
    analysis_history = models.JSONField(
        default=list,
        verbose_name="åˆ†æå†å²",
        help_text="å†æ¬¡åˆ†æçš„æ‘˜è¦ä¿¡æ¯"
    )

    # æ–°å¢ï¼šç‰ˆæœ¬æ§åˆ¶
    is_current_version = models.BooleanField(
        default=True,
        verbose_name="æ˜¯å¦å½“å‰ç‰ˆæœ¬",
        db_index=True
    )
    previous_version = models.ForeignKey(
        'self',
        on_delete=models.SET_NULL,
        null=True, blank=True,
        verbose_name="å‰ä¸€ç‰ˆæœ¬",
        related_name="next_versions"
    )
```

### æ‰©å±• AIGeneratedSyllabus æ¨¡å‹

```python
# åœ¨ç°æœ‰æ¨¡å‹åŸºç¡€ä¸Šæ·»åŠ å­—æ®µ
class AIGeneratedSyllabus(UserRelatedModel, StatusTrackingModel):
    # ... ç°æœ‰å­—æ®µ ...

    # æ–°å¢ï¼šå·¥ä½œæµå…³è”
    preparation_workflow = models.OneToOneField(
        'TeachingPreparationWorkflow',
        on_delete=models.CASCADE,
        null=True, blank=True,
        verbose_name="å‡†å¤‡å·¥ä½œæµ",
        related_name="generated_syllabus"
    )

    # æ–°å¢ï¼šçŸ¥è¯†ç‚¹æ˜ å°„
    knowledge_mapping = models.JSONField(
        default=dict,
        verbose_name="çŸ¥è¯†ç‚¹æ˜ å°„",
        help_text="è€ƒçº²ä¸æ•™æçš„çŸ¥è¯†ç‚¹æ˜ å°„å…³ç³»"
    )

    # æ–°å¢ï¼šè¯¾æ—¶åˆ†é…å…³è”
    hour_allocation = models.OneToOneField(
        'CourseHourAllocation',
        on_delete=models.SET_NULL,
        null=True, blank=True,
        verbose_name="è¯¾æ—¶åˆ†é…",
        related_name="syllabus"
    )

    # æ–°å¢ï¼šç”Ÿæˆè´¨é‡è¯„ä¼°
    content_completeness_score = models.FloatField(
        default=0.0,
        verbose_name="å†…å®¹å®Œæ•´æ€§è¯„åˆ†",
        validators=[MinValueValidator(0.0), MaxValueValidator(10.0)]
    )
    practical_usability_score = models.FloatField(
        default=0.0,
        verbose_name="å®ç”¨æ€§è¯„åˆ†",
        validators=[MinValueValidator(0.0), MaxValueValidator(10.0)]
    )

    # æ–°å¢ï¼šä¸ªæ€§åŒ–é…ç½®
    personalization_config = models.JSONField(
        default=dict,
        verbose_name="ä¸ªæ€§åŒ–é…ç½®",
        help_text="ä¸ªæ€§åŒ–ç”Ÿæˆçš„é…ç½®å‚æ•°"
    )

    # æ–°å¢ï¼šä½¿ç”¨åé¦ˆ
    teacher_feedback = models.JSONField(
        default=dict,
        verbose_name="æ•™å¸ˆåé¦ˆ",
        help_text="æ•™å¸ˆå¯¹ç”Ÿæˆå¤§çº²çš„åé¦ˆ"
    )
    usage_statistics = models.JSONField(
        default=dict,
        verbose_name="ä½¿ç”¨ç»Ÿè®¡",
        help_text="å¤§çº²çš„ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯"
    )
```

## ğŸ“Š æ•°æ®å…³ç³»è®¾è®¡

### æ ¸å¿ƒå…³ç³»å›¾

```mermaid
erDiagram
    TeachingPreparationWorkflow ||--o{ IterativeAnalysisSession : "has many"
    TeachingPreparationWorkflow ||--o{ KnowledgePointHierarchy : "has many"
    TeachingPreparationWorkflow ||--|| CourseHourAllocation : "has one"
    TeachingPreparationWorkflow ||--|| AIGeneratedSyllabus : "generates"

    IterativeAnalysisSession ||--o{ AnalysisRoundResult : "has many"
    IterativeAnalysisSession ||--|| KnowledgePointHierarchy : "generates"

    KnowledgePointHierarchy ||--o{ CourseHourAllocation : "used by"
    CourseHourAllocation ||--|| AIGeneratedSyllabus : "used by"

    TeachingPreparationWorkflow }o--|| CourseAssignment : "belongs to"
    TeachingPreparationWorkflow }o--|| User : "created by"
```

### ç´¢å¼•ä¼˜åŒ–ç­–ç•¥

```python
# å¤åˆç´¢å¼•è®¾è®¡
class Meta:
    indexes = [
        # å·¥ä½œæµæŸ¥è¯¢ä¼˜åŒ–
        models.Index(fields=["user", "workflow_status", "current_stage"]),
        models.Index(fields=["course_assignment", "workflow_status"]),

        # åˆ†æä¼šè¯æŸ¥è¯¢ä¼˜åŒ–
        models.Index(fields=["workflow", "document_type", "session_status"]),
        models.Index(fields=["current_round", "max_rounds", "session_status"]),

        # æ—¶é—´èŒƒå›´æŸ¥è¯¢ä¼˜åŒ–
        models.Index(fields=["created_at", "workflow_status"]),
        models.Index(fields=["started_at", "completed_at"]),

        # è´¨é‡è¯„åˆ†æŸ¥è¯¢ä¼˜åŒ–
        models.Index(fields=["quality_score", "round_number"]),
        models.Index(fields=["allocation_quality_score", "feasibility_score"]),
    ]
```

## ğŸ—ƒï¸ æ•°æ®åº“è¿ç§»ç­–ç•¥

### è¿ç§»è®¡åˆ’

1. **ç¬¬ä¸€é˜¶æ®µï¼šæ ¸å¿ƒæ¨¡å‹åˆ›å»º**

   ```python
   # 0001_create_core_workflow_models.py
   - TeachingPreparationWorkflow
   - IterativeAnalysisSession
   - AnalysisRoundResult
   ```

2. **ç¬¬äºŒé˜¶æ®µï¼šçŸ¥è¯†ç‚¹å’Œåˆ†é…æ¨¡å‹**

   ```python
   # 0002_create_knowledge_allocation_models.py
   - KnowledgePointHierarchy
   - CourseHourAllocation
   ```

3. **ç¬¬ä¸‰é˜¶æ®µï¼šç°æœ‰æ¨¡å‹æ‰©å±•**
   ```python
   # 0003_extend_existing_models.py
   - æ‰©å±• EnhancedExamSyllabus
   - æ‰©å±• AIGeneratedSyllabus
   ```

### æ•°æ®è¿ç§»è„šæœ¬

```python
# data_migration_script.py
def migrate_existing_data():
    """è¿ç§»ç°æœ‰æ•°æ®åˆ°æ–°æ¨¡å‹"""

    # 1. ä¸ºç°æœ‰è¯¾ç¨‹åˆ†é…åˆ›å»ºå·¥ä½œæµ
    for assignment in CourseAssignment.objects.all():
        if not hasattr(assignment, 'preparation_workflow'):
            workflow = TeachingPreparationWorkflow.objects.create(
                course_assignment=assignment,
                user=assignment.teacher,
                workflow_status='created',
                current_stage='course_info'
            )

    # 2. è¿ç§»ç°æœ‰åˆ†æç»“æœ
    for syllabus in EnhancedExamSyllabus.objects.all():
        if syllabus.ai_analysis_result:
            # åˆ›å»ºåˆ†æä¼šè¯è®°å½•
            session = IterativeAnalysisSession.objects.create(
                workflow=syllabus.workflow,
                document_type='syllabus',
                session_status='completed',
                current_round=1,
                max_rounds=1
            )

            # åˆ›å»ºè½®æ¬¡ç»“æœ
            AnalysisRoundResult.objects.create(
                analysis_session=session,
                round_number=1,
                round_status='completed',
                analysis_focus='framework',
                extracted_content=syllabus.ai_analysis_result,
                quality_score=syllabus.content_quality_score / 10
            )
```

## ğŸ”§ æ•°æ®åº“ä¼˜åŒ–é…ç½®

### PostgreSQL ä¼˜åŒ–è®¾ç½®

```sql
-- é’ˆå¯¹å¤§é‡JSONæŸ¥è¯¢çš„ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_workflow_stage_results_gin
ON teaching_preparation_workflows USING GIN (stage_results);

CREATE INDEX CONCURRENTLY idx_analysis_extracted_content_gin
ON analysis_round_results USING GIN (extracted_content);

CREATE INDEX CONCURRENTLY idx_knowledge_hierarchy_data_gin
ON knowledge_point_hierarchies USING GIN (hierarchy_data);

-- é’ˆå¯¹æ—¶é—´èŒƒå›´æŸ¥è¯¢çš„ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_workflow_time_range
ON teaching_preparation_workflows (started_at, completed_at)
WHERE workflow_status IN ('in_progress', 'completed');

-- é’ˆå¯¹è´¨é‡è¯„åˆ†æŸ¥è¯¢çš„ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_quality_scores_range
ON analysis_round_results (quality_score DESC, created_at DESC)
WHERE quality_score > 0.8;
```

### ç¼“å­˜ç­–ç•¥

```python
# Redis ç¼“å­˜é”®è®¾è®¡
CACHE_KEYS = {
    'workflow_status': 'workflow:{workflow_id}:status',
    'analysis_progress': 'analysis:{session_id}:progress',
    'knowledge_hierarchy': 'knowledge:{hierarchy_id}:data',
    'hour_allocation': 'allocation:{allocation_id}:data',
}

# ç¼“å­˜è¿‡æœŸæ—¶é—´è®¾è®¡
CACHE_TIMEOUTS = {
    'workflow_status': 300,      # 5åˆ†é’Ÿ
    'analysis_progress': 60,     # 1åˆ†é’Ÿ
    'knowledge_hierarchy': 3600, # 1å°æ—¶
    'hour_allocation': 1800,     # 30åˆ†é’Ÿ
}
```

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [APIè®¾è®¡è§„èŒƒ](./teaching-syllabus-api-design.md)
- [æŠ€æœ¯å®ç°è¯¦ç»†è®¾è®¡](./teaching-syllabus-technical-implementation.md)
- [å‰ç«¯ç•Œé¢è®¾è®¡](./teaching-syllabus-frontend-design.md)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¥æœŸ**: 2025-01-22
**æœ€åæ›´æ–°**: 2025-01-22
