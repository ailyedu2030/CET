# è‹±è¯­å››çº§æ™ºèƒ½è®­ç»ƒç³»ç»Ÿç›‘æ§ä¼˜åŒ–æ–¹æ¡ˆ

## ğŸ“Š æ¦‚è¿°

æœ¬æ–‡æ¡£åŸºäºã€Šè‹±è¯­å››çº§æ™ºèƒ½è®­ç»ƒç³»ç»Ÿå…¨é¢æŠ€æœ¯æ¶æ„å®¡æŸ¥æŠ¥å‘Šã€‹å’Œã€Šè‹±è¯­å››çº§æ™ºèƒ½è®­ç»ƒç³»ç»Ÿæ·±åº¦ç¬¦åˆæ€§å®¡æŸ¥æŠ¥å‘Šã€‹çš„å‘ç°ï¼Œé’ˆå¯¹ç³»ç»Ÿç›‘æ§ä½“ç³»çš„ä¸è¶³ï¼Œæå‡ºå…¨é¢çš„ç›‘æ§ä¼˜åŒ–æ–¹æ¡ˆã€‚æ—¨åœ¨å»ºç«‹å®Œæ•´çš„ç³»ç»Ÿå¯è§‚æµ‹æ€§ï¼Œæå‡è¿ç»´æ•ˆç‡å’Œç³»ç»Ÿç¨³å®šæ€§ã€‚

---

## ğŸ¯ ä¼˜åŒ–ç›®æ ‡

### æ ¸å¿ƒç›®æ ‡

- **å…¨é¢å¯è§‚æµ‹æ€§**: å»ºç«‹å®Œæ•´çš„ç›‘æ§ã€æ—¥å¿—ã€é“¾è·¯è¿½è¸ªä½“ç³»
- **ä¸»åŠ¨è¿ç»´**: ä»è¢«åŠ¨å“åº”è½¬å‘ä¸»åŠ¨é¢„é˜²
- **æ™ºèƒ½å‘Šè­¦**: å‡å°‘å‘Šè­¦å™ªéŸ³ï¼Œæé«˜å‘Šè­¦å‡†ç¡®æ€§
- **æ€§èƒ½æ´å¯Ÿ**: æ·±å…¥äº†è§£ç³»ç»Ÿæ€§èƒ½ç“¶é¢ˆå’Œä¼˜åŒ–æœºä¼š
- **ä¸šåŠ¡ç›‘æ§**: å…³æ³¨ä¸šåŠ¡æŒ‡æ ‡å’Œç”¨æˆ·ä½“éªŒ

### é‡åŒ–æŒ‡æ ‡

- ç³»ç»Ÿå¯ç”¨æ€§: 99.9% â†’ 99.95%
- æ•…éšœå‘ç°æ—¶é—´: 30åˆ†é’Ÿ â†’ 5åˆ†é’Ÿ
- æ•…éšœæ¢å¤æ—¶é—´: 2å°æ—¶ â†’ 30åˆ†é’Ÿ
- å‘Šè­¦å‡†ç¡®ç‡: 60% â†’ 90%
- ç›‘æ§è¦†ç›–ç‡: 70% â†’ 95%

---

## ğŸ“ˆ å½“å‰ç›‘æ§ç°çŠ¶åˆ†æ

### ç°æœ‰ç›‘æ§èƒ½åŠ›

```yaml
åŸºç¡€è®¾æ–½ç›‘æ§:
  - æœåŠ¡å™¨èµ„æºç›‘æ§: âœ… å·²å®ç°
  - æ•°æ®åº“ç›‘æ§: âš ï¸ éƒ¨åˆ†å®ç°
  - ç½‘ç»œç›‘æ§: âŒ ç¼ºå¤±
  - å­˜å‚¨ç›‘æ§: âš ï¸ åŸºç¡€ç›‘æ§

åº”ç”¨ç›‘æ§:
  - APIæ€§èƒ½ç›‘æ§: âš ï¸ åŸºç¡€æŒ‡æ ‡
  - é”™è¯¯ç‡ç›‘æ§: âš ï¸ ç®€å•ç»Ÿè®¡
  - ç”¨æˆ·ä½“éªŒç›‘æ§: âŒ ç¼ºå¤±
  - ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§: âŒ ç¼ºå¤±

æ—¥å¿—ç®¡ç†:
  - æ—¥å¿—æ”¶é›†: âš ï¸ åˆ†æ•£å­˜å‚¨
  - æ—¥å¿—åˆ†æ: âŒ ç¼ºå¤±
  - æ—¥å¿—å‘Šè­¦: âŒ ç¼ºå¤±
  - æ—¥å¿—å½’æ¡£: âš ï¸ ç®€å•å¤‡ä»½

å‘Šè­¦ç³»ç»Ÿ:
  - å‘Šè­¦è§„åˆ™: âš ï¸ åŸºç¡€è§„åˆ™
  - å‘Šè­¦æ¸ é“: âš ï¸ å•ä¸€æ¸ é“
  - å‘Šè­¦å‡çº§: âŒ ç¼ºå¤±
  - å‘Šè­¦æŠ‘åˆ¶: âŒ ç¼ºå¤±
```

### ä¸»è¦é—®é¢˜

1. **ç›‘æ§å­¤å²›**: å„ç»„ä»¶ç›‘æ§ç‹¬ç«‹ï¼Œç¼ºä¹ç»Ÿä¸€è§†å›¾
2. **å‘Šè­¦é£æš´**: ç¼ºä¹æ™ºèƒ½å‘Šè­¦å’ŒæŠ‘åˆ¶æœºåˆ¶
3. **å¯è§‚æµ‹æ€§ä¸è¶³**: ç¼ºä¹é“¾è·¯è¿½è¸ªå’Œæ·±åº¦åˆ†æ
4. **ä¸šåŠ¡ç›‘æ§ç¼ºå¤±**: åªå…³æ³¨æŠ€æœ¯æŒ‡æ ‡ï¼Œå¿½è§†ä¸šåŠ¡æŒ‡æ ‡
5. **å“åº”æœºåˆ¶ä¸å®Œå–„**: ç¼ºä¹è‡ªåŠ¨åŒ–å“åº”å’Œæ•…éšœè‡ªæ„ˆ

---

## ğŸ—ï¸ ç›‘æ§æ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„

```mermaid
graph TB
    subgraph "æ•°æ®é‡‡é›†å±‚"
        A[Prometheus] --> B[Node Exporter]
        A --> C[Django Exporter]
        A --> D[PostgreSQL Exporter]
        A --> E[Redis Exporter]
        A --> F[Nginx Exporter]
        G[Filebeat] --> H[åº”ç”¨æ—¥å¿—]
        G --> I[ç³»ç»Ÿæ—¥å¿—]
        G --> J[è®¿é—®æ—¥å¿—]
        K[Jaeger Agent] --> L[é“¾è·¯è¿½è¸ª]
    end

    subgraph "æ•°æ®å­˜å‚¨å±‚"
        A --> M[Prometheus TSDB]
        G --> N[Elasticsearch]
        K --> O[Jaeger Collector]
    end

    subgraph "æ•°æ®å¤„ç†å±‚"
        M --> P[Grafana]
        N --> Q[Kibana]
        O --> R[Jaeger UI]
        M --> S[AlertManager]
    end

    subgraph "å‘Šè­¦é€šçŸ¥å±‚"
        S --> T[é’‰é’‰]
        S --> U[é‚®ä»¶]
        S --> V[çŸ­ä¿¡]
        S --> W[PagerDuty]
    end
```

### æŠ€æœ¯æ ˆé€‰æ‹©

```yaml
ç›‘æ§æŒ‡æ ‡:
  - æ—¶åºæ•°æ®åº“: Prometheus + VictoriaMetrics
  - å¯è§†åŒ–: Grafana
  - å‘Šè­¦: AlertManager
  - å¯¼å‡ºå™¨: å„ç±»Exporter

æ—¥å¿—ç®¡ç†:
  - æ”¶é›†: Filebeat + Fluentd
  - å­˜å‚¨: Elasticsearch
  - åˆ†æ: Kibana + Logstash
  - å‘Šè­¦: ElastAlert

é“¾è·¯è¿½è¸ª:
  - æ”¶é›†: Jaeger Agent
  - å­˜å‚¨: Jaeger Collector + Elasticsearch
  - åˆ†æ: Jaeger UI
  - SDK: OpenTelemetry

ä¸šåŠ¡ç›‘æ§:
  - è‡ªå®šä¹‰æŒ‡æ ‡: Prometheus Client
  - ç”¨æˆ·ä½“éªŒ: Real User Monitoring
  - ä¸šåŠ¡å¤§ç›˜: Grafana Dashboard
```

---

## ğŸ”§ æ ¸å¿ƒç›‘æ§ç»„ä»¶å®ç°

### 1. åº”ç”¨æ€§èƒ½ç›‘æ§(APM)

```python
# monitoring/apm.py
import time
import functools
from typing import Dict, Any, Optional
from django.conf import settings
from prometheus_client import Counter, Histogram, Gauge
import opentelemetry.trace as trace
from opentelemetry import trace
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

class APMMetrics:
    """åº”ç”¨æ€§èƒ½ç›‘æ§æŒ‡æ ‡"""

    def __init__(self):
        # HTTPè¯·æ±‚æŒ‡æ ‡
        self.http_requests_total = Counter(
            'http_requests_total',
            'Total HTTP requests',
            ['method', 'endpoint', 'status_code']
        )

        self.http_request_duration = Histogram(
            'http_request_duration_seconds',
            'HTTP request duration',
            ['method', 'endpoint']
        )

        # æ•°æ®åº“æŸ¥è¯¢æŒ‡æ ‡
        self.db_queries_total = Counter(
            'db_queries_total',
            'Total database queries',
            ['operation', 'table']
        )

        self.db_query_duration = Histogram(
            'db_query_duration_seconds',
            'Database query duration',
            ['operation', 'table']
        )

        # AIæœåŠ¡è°ƒç”¨æŒ‡æ ‡
        self.ai_requests_total = Counter(
            'ai_requests_total',
            'Total AI service requests',
            ['service', 'model', 'status']
        )

        self.ai_request_duration = Histogram(
            'ai_request_duration_seconds',
            'AI service request duration',
            ['service', 'model']
        )

        self.ai_token_usage = Counter(
            'ai_token_usage_total',
            'Total AI tokens used',
            ['service', 'model', 'type']
        )

        # ä¸šåŠ¡æŒ‡æ ‡
        self.active_users = Gauge(
            'active_users_total',
            'Number of active users',
            ['time_window']
        )

        self.learning_sessions = Counter(
            'learning_sessions_total',
            'Total learning sessions',
            ['user_type', 'subject']
        )

        self.exercise_completions = Counter(
            'exercise_completions_total',
            'Total exercise completions',
            ['exercise_type', 'difficulty', 'result']
        )

    def record_http_request(self, method: str, endpoint: str,
                          status_code: int, duration: float):
        """è®°å½•HTTPè¯·æ±‚æŒ‡æ ‡"""
        self.http_requests_total.labels(
            method=method,
            endpoint=endpoint,
            status_code=status_code
        ).inc()

        self.http_request_duration.labels(
            method=method,
            endpoint=endpoint
        ).observe(duration)

    def record_db_query(self, operation: str, table: str, duration: float):
        """è®°å½•æ•°æ®åº“æŸ¥è¯¢æŒ‡æ ‡"""
        self.db_queries_total.labels(
            operation=operation,
            table=table
        ).inc()

        self.db_query_duration.labels(
            operation=operation,
            table=table
        ).observe(duration)

    def record_ai_request(self, service: str, model: str,
                         status: str, duration: float,
                         input_tokens: int = 0, output_tokens: int = 0):
        """è®°å½•AIæœåŠ¡è°ƒç”¨æŒ‡æ ‡"""
        self.ai_requests_total.labels(
            service=service,
            model=model,
            status=status
        ).inc()

        self.ai_request_duration.labels(
            service=service,
            model=model
        ).observe(duration)

        if input_tokens > 0:
            self.ai_token_usage.labels(
                service=service,
                model=model,
                type='input'
            ).inc(input_tokens)

        if output_tokens > 0:
            self.ai_token_usage.labels(
                service=service,
                model=model,
                type='output'
            ).inc(output_tokens)

# å…¨å±€æŒ‡æ ‡å®ä¾‹
apm_metrics = APMMetrics()

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""

    @staticmethod
    def monitor_api(endpoint_name: Optional[str] = None):
        """APIæ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
        def decorator(func):
            @functools.wraps(func)
            def wrapper(request, *args, **kwargs):
                start_time = time.time()
                endpoint = endpoint_name or func.__name__

                try:
                    response = func(request, *args, **kwargs)
                    status_code = getattr(response, 'status_code', 200)

                    # è®°å½•æˆåŠŸè¯·æ±‚
                    apm_metrics.record_http_request(
                        method=request.method,
                        endpoint=endpoint,
                        status_code=status_code,
                        duration=time.time() - start_time
                    )

                    return response

                except Exception as e:
                    # è®°å½•å¤±è´¥è¯·æ±‚
                    apm_metrics.record_http_request(
                        method=request.method,
                        endpoint=endpoint,
                        status_code=500,
                        duration=time.time() - start_time
                    )
                    raise

            return wrapper
        return decorator

    @staticmethod
    def monitor_db_query(operation: str, table: str):
        """æ•°æ®åº“æŸ¥è¯¢ç›‘æ§è£…é¥°å™¨"""
        def decorator(func):
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                start_time = time.time()

                try:
                    result = func(*args, **kwargs)

                    # è®°å½•æŸ¥è¯¢æŒ‡æ ‡
                    apm_metrics.record_db_query(
                        operation=operation,
                        table=table,
                        duration=time.time() - start_time
                    )

                    return result

                except Exception as e:
                    # è®°å½•å¤±è´¥æŸ¥è¯¢
                    apm_metrics.record_db_query(
                        operation=f"{operation}_error",
                        table=table,
                        duration=time.time() - start_time
                    )
                    raise

            return wrapper
        return decorator

    @staticmethod
    def monitor_ai_service(service: str, model: str):
        """AIæœåŠ¡ç›‘æ§è£…é¥°å™¨"""
        def decorator(func):
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                start_time = time.time()

                try:
                    result = func(*args, **kwargs)

                    # æå–tokenä½¿ç”¨ä¿¡æ¯
                    input_tokens = getattr(result, 'input_tokens', 0)
                    output_tokens = getattr(result, 'output_tokens', 0)

                    # è®°å½•æˆåŠŸè°ƒç”¨
                    apm_metrics.record_ai_request(
                        service=service,
                        model=model,
                        status='success',
                        duration=time.time() - start_time,
                        input_tokens=input_tokens,
                        output_tokens=output_tokens
                    )

                    return result

                except Exception as e:
                    # è®°å½•å¤±è´¥è°ƒç”¨
                    apm_metrics.record_ai_request(
                        service=service,
                        model=model,
                        status='error',
                        duration=time.time() - start_time
                    )
                    raise

            return wrapper
        return decorator

class TracingManager:
    """é“¾è·¯è¿½è¸ªç®¡ç†å™¨"""

    def __init__(self):
        # é…ç½®Jaeger
        trace.set_tracer_provider(TracerProvider())

        jaeger_exporter = JaegerExporter(
            agent_host_name=settings.JAEGER_AGENT_HOST,
            agent_port=settings.JAEGER_AGENT_PORT,
        )

        span_processor = BatchSpanProcessor(jaeger_exporter)
        trace.get_tracer_provider().add_span_processor(span_processor)

        self.tracer = trace.get_tracer(__name__)

    def trace_function(self, operation_name: str, tags: Dict[str, Any] = None):
        """å‡½æ•°è¿½è¸ªè£…é¥°å™¨"""
        def decorator(func):
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                with self.tracer.start_as_current_span(operation_name) as span:
                    # æ·»åŠ æ ‡ç­¾
                    if tags:
                        for key, value in tags.items():
                            span.set_attribute(key, str(value))

                    # æ·»åŠ å‡½æ•°ä¿¡æ¯
                    span.set_attribute("function.name", func.__name__)
                    span.set_attribute("function.module", func.__module__)

                    try:
                        result = func(*args, **kwargs)
                        span.set_attribute("success", True)
                        return result
                    except Exception as e:
                        span.set_attribute("success", False)
                        span.set_attribute("error.message", str(e))
                        span.set_attribute("error.type", type(e).__name__)
                        raise

            return wrapper
        return decorator

# å…¨å±€è¿½è¸ªç®¡ç†å™¨
tracing_manager = TracingManager()
```

### 2. ä¸šåŠ¡ç›‘æ§ç³»ç»Ÿ

```python
# monitoring/business_metrics.py
from typing import Dict, List, Any
from datetime import datetime, timedelta
from django.db.models import Count, Avg, Sum
from django.contrib.auth import get_user_model
from django.utils import timezone
from prometheus_client import Gauge, Counter
import redis
import json

User = get_user_model()

class BusinessMetricsCollector:
    """ä¸šåŠ¡æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self):
        self.redis_client = redis.Redis(
            host=settings.REDIS_HOST,
            port=settings.REDIS_PORT,
            db=settings.REDIS_DB
        )

        # ä¸šåŠ¡æŒ‡æ ‡
        self.daily_active_users = Gauge(
            'daily_active_users',
            'Daily active users count'
        )

        self.monthly_active_users = Gauge(
            'monthly_active_users',
            'Monthly active users count'
        )

        self.learning_completion_rate = Gauge(
            'learning_completion_rate',
            'Learning completion rate',
            ['course_type', 'difficulty']
        )

        self.average_session_duration = Gauge(
            'average_session_duration_minutes',
            'Average learning session duration in minutes',
            ['user_type']
        )

        self.ai_service_cost = Counter(
            'ai_service_cost_total',
            'Total AI service cost',
            ['service', 'model']
        )

        self.user_satisfaction_score = Gauge(
            'user_satisfaction_score',
            'User satisfaction score',
            ['feature', 'user_type']
        )

    def collect_user_metrics(self):
        """æ”¶é›†ç”¨æˆ·ç›¸å…³æŒ‡æ ‡"""
        now = timezone.now()

        # æ—¥æ´»è·ƒç”¨æˆ·
        dau = User.objects.filter(
            last_login__gte=now - timedelta(days=1)
        ).count()
        self.daily_active_users.set(dau)

        # æœˆæ´»è·ƒç”¨æˆ·
        mau = User.objects.filter(
            last_login__gte=now - timedelta(days=30)
        ).count()
        self.monthly_active_users.set(mau)

        # ç¼“å­˜æŒ‡æ ‡
        self.redis_client.setex(
            'metrics:dau',
            3600,  # 1å°æ—¶è¿‡æœŸ
            json.dumps({
                'value': dau,
                'timestamp': now.isoformat()
            })
        )

    def collect_learning_metrics(self):
        """æ”¶é›†å­¦ä¹ ç›¸å…³æŒ‡æ ‡"""
        from learning.models import LearningSession, Exercise

        # å­¦ä¹ å®Œæˆç‡
        completion_stats = LearningSession.objects.filter(
            created_at__gte=timezone.now() - timedelta(days=7)
        ).values(
            'course__type',
            'course__difficulty'
        ).annotate(
            total_sessions=Count('id'),
            completed_sessions=Count('id', filter=models.Q(status='completed'))
        )

        for stat in completion_stats:
            completion_rate = (
                stat['completed_sessions'] / stat['total_sessions']
                if stat['total_sessions'] > 0 else 0
            )

            self.learning_completion_rate.labels(
                course_type=stat['course__type'],
                difficulty=stat['course__difficulty']
            ).set(completion_rate)

        # å¹³å‡å­¦ä¹ æ—¶é•¿
        session_duration_stats = LearningSession.objects.filter(
            created_at__gte=timezone.now() - timedelta(days=7),
            duration__isnull=False
        ).values(
            'user__user_type'
        ).annotate(
            avg_duration=Avg('duration')
        )

        for stat in session_duration_stats:
            avg_minutes = stat['avg_duration'].total_seconds() / 60
            self.average_session_duration.labels(
                user_type=stat['user__user_type']
            ).set(avg_minutes)

    def collect_ai_cost_metrics(self):
        """æ”¶é›†AIæœåŠ¡æˆæœ¬æŒ‡æ ‡"""
        from ai_services.models import AIServiceUsage

        # è·å–æœ€è¿‘24å°æ—¶çš„AIæœåŠ¡ä½¿ç”¨æˆæœ¬
        cost_stats = AIServiceUsage.objects.filter(
            created_at__gte=timezone.now() - timedelta(hours=24)
        ).values(
            'service_name',
            'model_name'
        ).annotate(
            total_cost=Sum('cost')
        )

        for stat in cost_stats:
            self.ai_service_cost.labels(
                service=stat['service_name'],
                model=stat['model_name']
            ).inc(float(stat['total_cost'] or 0))

    def collect_satisfaction_metrics(self):
        """æ”¶é›†ç”¨æˆ·æ»¡æ„åº¦æŒ‡æ ‡"""
        from feedback.models import UserFeedback

        # è·å–æœ€è¿‘7å¤©çš„ç”¨æˆ·åé¦ˆ
        satisfaction_stats = UserFeedback.objects.filter(
            created_at__gte=timezone.now() - timedelta(days=7),
            rating__isnull=False
        ).values(
            'feature',
            'user__user_type'
        ).annotate(
            avg_rating=Avg('rating')
        )

        for stat in satisfaction_stats:
            self.user_satisfaction_score.labels(
                feature=stat['feature'],
                user_type=stat['user__user_type']
            ).set(float(stat['avg_rating']))

    def collect_all_metrics(self):
        """æ”¶é›†æ‰€æœ‰ä¸šåŠ¡æŒ‡æ ‡"""
        try:
            self.collect_user_metrics()
            self.collect_learning_metrics()
            self.collect_ai_cost_metrics()
            self.collect_satisfaction_metrics()
        except Exception as e:
            print(f"ä¸šåŠ¡æŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")

class RealTimeMetrics:
    """å®æ—¶æŒ‡æ ‡ç›‘æ§"""

    def __init__(self):
        self.redis_client = redis.Redis(
            host=settings.REDIS_HOST,
            port=settings.REDIS_PORT,
            db=settings.REDIS_DB
        )

    def track_user_action(self, user_id: int, action: str,
                         metadata: Dict[str, Any] = None):
        """è¿½è¸ªç”¨æˆ·è¡Œä¸º"""
        event = {
            'user_id': user_id,
            'action': action,
            'timestamp': timezone.now().isoformat(),
            'metadata': metadata or {}
        }

        # å­˜å‚¨åˆ°Redisæµ
        self.redis_client.xadd(
            'user_actions',
            event,
            maxlen=10000  # ä¿ç•™æœ€è¿‘10000æ¡è®°å½•
        )

        # æ›´æ–°å®æ—¶è®¡æ•°å™¨
        key = f"action_count:{action}:{timezone.now().strftime('%Y%m%d%H')}"
        self.redis_client.incr(key)
        self.redis_client.expire(key, 86400)  # 24å°æ—¶è¿‡æœŸ

    def get_real_time_stats(self) -> Dict[str, Any]:
        """è·å–å®æ—¶ç»Ÿè®¡æ•°æ®"""
        now = timezone.now()
        current_hour = now.strftime('%Y%m%d%H')

        stats = {}

        # è·å–å½“å‰å°æ—¶çš„è¡Œä¸ºç»Ÿè®¡
        action_keys = self.redis_client.keys(f"action_count:*:{current_hour}")
        for key in action_keys:
            action = key.decode().split(':')[1]
            count = int(self.redis_client.get(key) or 0)
            stats[f"hourly_{action}_count"] = count

        # è·å–åœ¨çº¿ç”¨æˆ·æ•°
        online_users = self.redis_client.scard('online_users')
        stats['online_users'] = online_users

        return stats

    def update_online_users(self, user_id: int):
        """æ›´æ–°åœ¨çº¿ç”¨æˆ·"""
        self.redis_client.sadd('online_users', user_id)
        self.redis_client.expire('online_users', 300)  # 5åˆ†é’Ÿè¿‡æœŸ

# å…¨å±€ä¸šåŠ¡æŒ‡æ ‡æ”¶é›†å™¨
business_metrics = BusinessMetricsCollector()
real_time_metrics = RealTimeMetrics()
```

### 3. æ™ºèƒ½å‘Šè­¦ç³»ç»Ÿ

```python
# monitoring/alerting.py
import json
import requests
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from django.conf import settings
from django.core.mail import send_mail
from dataclasses import dataclass
from enum import Enum
import redis

class AlertSeverity(Enum):
    """å‘Šè­¦ä¸¥é‡ç¨‹åº¦"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"

class AlertStatus(Enum):
    """å‘Šè­¦çŠ¶æ€"""
    FIRING = "firing"
    RESOLVED = "resolved"
    SUPPRESSED = "suppressed"
    ACKNOWLEDGED = "acknowledged"

@dataclass
class Alert:
    """å‘Šè­¦ä¿¡æ¯"""
    id: str
    title: str
    description: str
    severity: AlertSeverity
    status: AlertStatus
    source: str
    timestamp: datetime
    labels: Dict[str, str]
    annotations: Dict[str, str]
    resolved_at: Optional[datetime] = None

class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""

    def __init__(self):
        self.redis_client = redis.Redis(
            host=settings.REDIS_HOST,
            port=settings.REDIS_PORT,
            db=settings.REDIS_DB
        )

        self.notification_channels = {
            'dingtalk': self._send_dingtalk_notification,
            'email': self._send_email_notification,
            'sms': self._send_sms_notification,
            'webhook': self._send_webhook_notification
        }

        # å‘Šè­¦æŠ‘åˆ¶è§„åˆ™
        self.suppression_rules = [
            {
                'name': 'maintenance_window',
                'condition': self._is_maintenance_window,
                'suppress_severities': [AlertSeverity.LOW, AlertSeverity.MEDIUM]
            },
            {
                'name': 'duplicate_alerts',
                'condition': self._is_duplicate_alert,
                'suppress_severities': [AlertSeverity.LOW]
            }
        ]

    def fire_alert(self, alert: Alert) -> bool:
        """è§¦å‘å‘Šè­¦"""
        try:
            # æ£€æŸ¥å‘Šè­¦æŠ‘åˆ¶
            if self._should_suppress_alert(alert):
                alert.status = AlertStatus.SUPPRESSED
                self._store_alert(alert)
                return False

            # å­˜å‚¨å‘Šè­¦
            alert.status = AlertStatus.FIRING
            self._store_alert(alert)

            # å‘é€é€šçŸ¥
            self._send_notifications(alert)

            # è®°å½•å‘Šè­¦æŒ‡æ ‡
            self._record_alert_metrics(alert)

            return True

        except Exception as e:
            print(f"å‘Šè­¦è§¦å‘å¤±è´¥: {e}")
            return False

    def resolve_alert(self, alert_id: str) -> bool:
        """è§£å†³å‘Šè­¦"""
        try:
            alert_data = self.redis_client.hget('alerts', alert_id)
            if not alert_data:
                return False

            alert_dict = json.loads(alert_data)
            alert = Alert(**alert_dict)

            alert.status = AlertStatus.RESOLVED
            alert.resolved_at = datetime.now()

            self._store_alert(alert)
            self._send_resolution_notification(alert)

            return True

        except Exception as e:
            print(f"å‘Šè­¦è§£å†³å¤±è´¥: {e}")
            return False

    def acknowledge_alert(self, alert_id: str, user: str) -> bool:
        """ç¡®è®¤å‘Šè­¦"""
        try:
            alert_data = self.redis_client.hget('alerts', alert_id)
            if not alert_data:
                return False

            alert_dict = json.loads(alert_data)
            alert = Alert(**alert_dict)

            alert.status = AlertStatus.ACKNOWLEDGED
            alert.annotations['acknowledged_by'] = user
            alert.annotations['acknowledged_at'] = datetime.now().isoformat()

            self._store_alert(alert)

            return True

        except Exception as e:
            print(f"å‘Šè­¦ç¡®è®¤å¤±è´¥: {e}")
            return False

    def _should_suppress_alert(self, alert: Alert) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æŠ‘åˆ¶å‘Šè­¦"""
        for rule in self.suppression_rules:
            if (alert.severity in rule['suppress_severities'] and
                rule['condition'](alert)):
                return True
        return False

    def _is_maintenance_window(self, alert: Alert) -> bool:
        """æ£€æŸ¥æ˜¯å¦åœ¨ç»´æŠ¤çª—å£"""
        # æ£€æŸ¥Redisä¸­çš„ç»´æŠ¤çª—å£é…ç½®
        maintenance_window = self.redis_client.get('maintenance_window')
        if not maintenance_window:
            return False

        window_data = json.loads(maintenance_window)
        start_time = datetime.fromisoformat(window_data['start'])
        end_time = datetime.fromisoformat(window_data['end'])

        return start_time <= datetime.now() <= end_time

    def _is_duplicate_alert(self, alert: Alert) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤å‘Šè­¦"""
        # æ£€æŸ¥æœ€è¿‘5åˆ†é’Ÿå†…æ˜¯å¦æœ‰ç›¸åŒçš„å‘Šè­¦
        recent_alerts = self._get_recent_alerts(minutes=5)

        for recent_alert in recent_alerts:
            if (recent_alert.title == alert.title and
                recent_alert.source == alert.source and
                recent_alert.status == AlertStatus.FIRING):
                return True

        return False

    def _get_recent_alerts(self, minutes: int = 60) -> List[Alert]:
        """è·å–æœ€è¿‘çš„å‘Šè­¦"""
        cutoff_time = datetime.now() - timedelta(minutes=minutes)
        alerts = []

        alert_ids = self.redis_client.hkeys('alerts')
        for alert_id in alert_ids:
            alert_data = self.redis_client.hget('alerts', alert_id)
            if alert_data:
                alert_dict = json.loads(alert_data)
                alert_time = datetime.fromisoformat(alert_dict['timestamp'])

                if alert_time >= cutoff_time:
                    alerts.append(Alert(**alert_dict))

        return sorted(alerts, key=lambda x: x.timestamp, reverse=True)

    def _store_alert(self, alert: Alert):
        """å­˜å‚¨å‘Šè­¦"""
        alert_dict = {
            'id': alert.id,
            'title': alert.title,
            'description': alert.description,
            'severity': alert.severity.value,
            'status': alert.status.value,
            'source': alert.source,
            'timestamp': alert.timestamp.isoformat(),
            'labels': alert.labels,
            'annotations': alert.annotations,
            'resolved_at': alert.resolved_at.isoformat() if alert.resolved_at else None
        }

        self.redis_client.hset('alerts', alert.id, json.dumps(alert_dict))

        # è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆ30å¤©ï¼‰
        self.redis_client.expire('alerts', 30 * 24 * 3600)

    def _send_notifications(self, alert: Alert):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        # æ ¹æ®ä¸¥é‡ç¨‹åº¦é€‰æ‹©é€šçŸ¥æ¸ é“
        channels = self._get_notification_channels(alert.severity)

        for channel in channels:
            if channel in self.notification_channels:
                try:
                    self.notification_channels[channel](alert)
                except Exception as e:
                    print(f"é€šçŸ¥å‘é€å¤±è´¥ ({channel}): {e}")

    def _get_notification_channels(self, severity: AlertSeverity) -> List[str]:
        """æ ¹æ®ä¸¥é‡ç¨‹åº¦è·å–é€šçŸ¥æ¸ é“"""
        channel_map = {
            AlertSeverity.CRITICAL: ['dingtalk', 'email', 'sms'],
            AlertSeverity.HIGH: ['dingtalk', 'email'],
            AlertSeverity.MEDIUM: ['dingtalk'],
            AlertSeverity.LOW: ['dingtalk'],
            AlertSeverity.INFO: []
        }

        return channel_map.get(severity, [])

    def _send_dingtalk_notification(self, alert: Alert):
        """å‘é€é’‰é’‰é€šçŸ¥"""
        webhook_url = settings.DINGTALK_WEBHOOK_URL

        severity_colors = {
            AlertSeverity.CRITICAL: '#FF0000',
            AlertSeverity.HIGH: '#FF8C00',
            AlertSeverity.MEDIUM: '#FFD700',
            AlertSeverity.LOW: '#32CD32',
            AlertSeverity.INFO: '#87CEEB'
        }

        message = {
            "msgtype": "markdown",
            "markdown": {
                "title": f"ğŸš¨ {alert.title}",
                "text": f"""
### ğŸš¨ ç³»ç»Ÿå‘Šè­¦

**å‘Šè­¦æ ‡é¢˜**: {alert.title}

**ä¸¥é‡ç¨‹åº¦**: <font color="{severity_colors[alert.severity]}">{alert.severity.value.upper()}</font>

**å‘Šè­¦æè¿°**: {alert.description}

**å‘Šè­¦æ¥æº**: {alert.source}

**è§¦å‘æ—¶é—´**: {alert.timestamp.strftime('%Y-%m-%d %H:%M:%S')}

**æ ‡ç­¾ä¿¡æ¯**:
{self._format_labels(alert.labels)}

---
è¯·åŠæ—¶å¤„ç†æ­¤å‘Šè­¦ï¼
                """
            }
        }

        response = requests.post(webhook_url, json=message, timeout=10)
        response.raise_for_status()

    def _send_email_notification(self, alert: Alert):
        """å‘é€é‚®ä»¶é€šçŸ¥"""
        subject = f"[{alert.severity.value.upper()}] {alert.title}"

        message = f"""
ç³»ç»Ÿå‘Šè­¦é€šçŸ¥

å‘Šè­¦æ ‡é¢˜: {alert.title}
ä¸¥é‡ç¨‹åº¦: {alert.severity.value.upper()}
å‘Šè­¦æè¿°: {alert.description}
å‘Šè­¦æ¥æº: {alert.source}
è§¦å‘æ—¶é—´: {alert.timestamp.strftime('%Y-%m-%d %H:%M:%S')}

æ ‡ç­¾ä¿¡æ¯:
{self._format_labels(alert.labels)}

è¯·åŠæ—¶ç™»å½•ç³»ç»ŸæŸ¥çœ‹è¯¦ç»†ä¿¡æ¯å¹¶å¤„ç†æ­¤å‘Šè­¦ã€‚
        """

        send_mail(
            subject=subject,
            message=message,
            from_email=settings.DEFAULT_FROM_EMAIL,
            recipient_list=settings.ALERT_EMAIL_RECIPIENTS,
            fail_silently=False
        )

    def _send_sms_notification(self, alert: Alert):
        """å‘é€çŸ­ä¿¡é€šçŸ¥"""
        # è¿™é‡Œéœ€è¦é›†æˆçŸ­ä¿¡æœåŠ¡æä¾›å•†çš„API
        message = f"[{alert.severity.value.upper()}] {alert.title} - {alert.timestamp.strftime('%H:%M')}"

        # ç¤ºä¾‹ï¼šé›†æˆé˜¿é‡Œäº‘çŸ­ä¿¡æœåŠ¡
        # å®é™…å®ç°éœ€è¦æ ¹æ®å…·ä½“çš„çŸ­ä¿¡æœåŠ¡å•†API
        pass

    def _send_webhook_notification(self, alert: Alert):
        """å‘é€Webhooké€šçŸ¥"""
        webhook_url = settings.ALERT_WEBHOOK_URL
        if not webhook_url:
            return

        payload = {
            'alert_id': alert.id,
            'title': alert.title,
            'description': alert.description,
            'severity': alert.severity.value,
            'status': alert.status.value,
            'source': alert.source,
            'timestamp': alert.timestamp.isoformat(),
            'labels': alert.labels,
            'annotations': alert.annotations
        }

        response = requests.post(webhook_url, json=payload, timeout=10)
        response.raise_for_status()

    def _send_resolution_notification(self, alert: Alert):
        """å‘é€å‘Šè­¦è§£å†³é€šçŸ¥"""
        # å‘é€é’‰é’‰è§£å†³é€šçŸ¥
        webhook_url = settings.DINGTALK_WEBHOOK_URL

        message = {
            "msgtype": "markdown",
            "markdown": {
                "title": f"âœ… å‘Šè­¦å·²è§£å†³: {alert.title}",
                "text": f"""
### âœ… å‘Šè­¦å·²è§£å†³

**å‘Šè­¦æ ‡é¢˜**: {alert.title}

**è§£å†³æ—¶é—´**: {alert.resolved_at.strftime('%Y-%m-%d %H:%M:%S')}

**æŒç»­æ—¶é•¿**: {self._calculate_duration(alert.timestamp, alert.resolved_at)}

---
å‘Šè­¦å·²è‡ªåŠ¨è§£å†³ã€‚
                """
            }
        }

        requests.post(webhook_url, json=message, timeout=10)

    def _format_labels(self, labels: Dict[str, str]) -> str:
        """æ ¼å¼åŒ–æ ‡ç­¾ä¿¡æ¯"""
        if not labels:
            return "æ— "

        return "\n".join([f"- {k}: {v}" for k, v in labels.items()])

    def _calculate_duration(self, start: datetime, end: datetime) -> str:
        """è®¡ç®—æŒç»­æ—¶é•¿"""
        duration = end - start

        hours = duration.seconds // 3600
        minutes = (duration.seconds % 3600) // 60
        seconds = duration.seconds % 60

        if hours > 0:
            return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"
        elif minutes > 0:
            return f"{minutes}åˆ†é’Ÿ{seconds}ç§’"
        else:
            return f"{seconds}ç§’"

    def _record_alert_metrics(self, alert: Alert):
        """è®°å½•å‘Šè­¦æŒ‡æ ‡"""
        from monitoring.apm import apm_metrics

        # è¿™é‡Œå¯ä»¥è®°å½•å‘Šè­¦ç›¸å…³çš„PrometheusæŒ‡æ ‡
        # ä¾‹å¦‚ï¼šå‘Šè­¦æ•°é‡ã€å‘Šè­¦é¢‘ç‡ç­‰
        pass

# å…¨å±€å‘Šè­¦ç®¡ç†å™¨
alert_manager = AlertManager()
```

---

## ğŸ“Š ç›‘æ§å¤§ç›˜é…ç½®

### 1. Grafanaä»ªè¡¨æ¿é…ç½®

```json
{
  "dashboard": {
    "id": null,
    "title": "è‹±è¯­å››çº§æ™ºèƒ½è®­ç»ƒç³»ç»Ÿ - ç³»ç»Ÿæ¦‚è§ˆ",
    "tags": ["english-training", "overview"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "ç³»ç»Ÿå¥åº·çŠ¶æ€",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=\"django-app\"}",
            "legendFormat": "åº”ç”¨çŠ¶æ€"
          },
          {
            "expr": "up{job=\"postgresql\"}",
            "legendFormat": "æ•°æ®åº“çŠ¶æ€"
          },
          {
            "expr": "up{job=\"redis\"}",
            "legendFormat": "ç¼“å­˜çŠ¶æ€"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                { "color": "red", "value": 0 },
                { "color": "green", "value": 1 }
              ]
            }
          }
        }
      },
      {
        "id": 2,
        "title": "APIè¯·æ±‚é‡",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ],
        "yAxes": [
          {
            "label": "è¯·æ±‚/ç§’",
            "min": 0
          }
        ]
      },
      {
        "id": 3,
        "title": "APIå“åº”æ—¶é—´",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          }
        ],
        "yAxes": [
          {
            "label": "å“åº”æ—¶é—´(ç§’)",
            "min": 0
          }
        ]
      },
      {
        "id": 4,
        "title": "é”™è¯¯ç‡",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(http_requests_total{status_code=~\"5..\"}[5m]) / rate(http_requests_total[5m]) * 100",
            "legendFormat": "5xxé”™è¯¯ç‡"
          },
          {
            "expr": "rate(http_requests_total{status_code=~\"4..\"}[5m]) / rate(http_requests_total[5m]) * 100",
            "legendFormat": "4xxé”™è¯¯ç‡"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "thresholds": {
              "steps": [
                { "color": "green", "value": 0 },
                { "color": "yellow", "value": 1 },
                { "color": "red", "value": 5 }
              ]
            }
          }
        }
      },
      {
        "id": 5,
        "title": "æ•°æ®åº“æ€§èƒ½",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(db_queries_total[5m])",
            "legendFormat": "æŸ¥è¯¢/ç§’"
          },
          {
            "expr": "histogram_quantile(0.95, rate(db_query_duration_seconds_bucket[5m]))",
            "legendFormat": "95thæŸ¥è¯¢æ—¶é—´"
          }
        ]
      },
      {
        "id": 6,
        "title": "AIæœåŠ¡ä½¿ç”¨æƒ…å†µ",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(ai_requests_total[5m])",
            "legendFormat": "{{service}} {{model}}"
          },
          {
            "expr": "rate(ai_token_usage_total[5m])",
            "legendFormat": "Tokenä½¿ç”¨ç‡"
          }
        ]
      },
      {
        "id": 7,
        "title": "ä¸šåŠ¡æŒ‡æ ‡",
        "type": "stat",
        "targets": [
          {
            "expr": "daily_active_users",
            "legendFormat": "æ—¥æ´»ç”¨æˆ·"
          },
          {
            "expr": "monthly_active_users",
            "legendFormat": "æœˆæ´»ç”¨æˆ·"
          },
          {
            "expr": "avg(learning_completion_rate)",
            "legendFormat": "å¹³å‡å®Œæˆç‡"
          }
        ]
      },
      {
        "id": 8,
        "title": "ç³»ç»Ÿèµ„æºä½¿ç”¨",
        "type": "graph",
        "targets": [
          {
            "expr": "(1 - rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100",
            "legendFormat": "CPUä½¿ç”¨ç‡"
          },
          {
            "expr": "(1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100",
            "legendFormat": "å†…å­˜ä½¿ç”¨ç‡"
          },
          {
            "expr": "(1 - node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100",
            "legendFormat": "ç£ç›˜ä½¿ç”¨ç‡"
          }
        ],
        "yAxes": [
          {
            "label": "ä½¿ç”¨ç‡(%)",
            "min": 0,
            "max": 100
          }
        ]
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "30s"
  }
}
```

### 2. å‘Šè­¦è§„åˆ™é…ç½®

```yaml
# alerting_rules.yml
groups:
  - name: system_alerts
    rules:
      - alert: HighCPUUsage
        expr: (1 - rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "CPUä½¿ç”¨ç‡è¿‡é«˜"
          description: "CPUä½¿ç”¨ç‡å·²è¶…è¿‡80%ï¼Œå½“å‰å€¼: {{ $value }}%"

      - alert: HighMemoryUsage
        expr: (1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 > 85
        for: 5m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "å†…å­˜ä½¿ç”¨ç‡å·²è¶…è¿‡85%ï¼Œå½“å‰å€¼: {{ $value }}%"

      - alert: DiskSpaceLow
        expr: (1 - node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 > 90
        for: 5m
        labels:
          severity: critical
          service: system
        annotations:
          summary: "ç£ç›˜ç©ºé—´ä¸è¶³"
          description: "ç£ç›˜ä½¿ç”¨ç‡å·²è¶…è¿‡90%ï¼Œå½“å‰å€¼: {{ $value }}%"

  - name: application_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status_code=~"5.."}[5m]) / rate(http_requests_total[5m]) * 100 > 5
        for: 2m
        labels:
          severity: critical
          service: application
        annotations:
          summary: "åº”ç”¨é”™è¯¯ç‡è¿‡é«˜"
          description: "5xxé”™è¯¯ç‡å·²è¶…è¿‡5%ï¼Œå½“å‰å€¼: {{ $value }}%"

      - alert: SlowAPIResponse
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
          service: application
        annotations:
          summary: "APIå“åº”æ—¶é—´è¿‡æ…¢"
          description: "95%çš„è¯·æ±‚å“åº”æ—¶é—´è¶…è¿‡2ç§’ï¼Œå½“å‰å€¼: {{ $value }}ç§’"

      - alert: DatabaseConnectionHigh
        expr: pg_stat_activity_count > 80
        for: 5m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "æ•°æ®åº“è¿æ¥æ•°è¿‡é«˜"
          description: "æ•°æ®åº“è¿æ¥æ•°å·²è¶…è¿‡80ï¼Œå½“å‰å€¼: {{ $value }}"

  - name: business_alerts
    rules:
      - alert: LowDailyActiveUsers
        expr: daily_active_users < 100
        for: 30m
        labels:
          severity: warning
          service: business
        annotations:
          summary: "æ—¥æ´»ç”¨æˆ·æ•°åä½"
          description: "æ—¥æ´»ç”¨æˆ·æ•°ä½äº100ï¼Œå½“å‰å€¼: {{ $value }}"

      - alert: HighAICost
        expr: increase(ai_service_cost_total[1h]) > 50
        for: 0m
        labels:
          severity: warning
          service: business
        annotations:
          summary: "AIæœåŠ¡æˆæœ¬è¿‡é«˜"
          description: "è¿‡å»1å°æ—¶AIæœåŠ¡æˆæœ¬è¶…è¿‡50å…ƒï¼Œå½“å‰å€¼: {{ $value }}å…ƒ"

      - alert: LowLearningCompletionRate
        expr: avg(learning_completion_rate) < 0.6
        for: 1h
        labels:
          severity: warning
          service: business
        annotations:
          summary: "å­¦ä¹ å®Œæˆç‡åä½"
          description: "å¹³å‡å­¦ä¹ å®Œæˆç‡ä½äº60%ï¼Œå½“å‰å€¼: {{ $value }}"
```

---

## ğŸ“… å®æ–½è®¡åˆ’

### é˜¶æ®µä¸€ï¼šåŸºç¡€ç›‘æ§æ­å»º (2å‘¨)

**ç›®æ ‡**: å»ºç«‹åŸºç¡€çš„ç›‘æ§å’Œå‘Šè­¦ä½“ç³»

| ä»»åŠ¡               | è´Ÿè´£äºº     | å·¥æœŸ | éªŒæ”¶æ ‡å‡†         |
| ------------------ | ---------- | ---- | ---------------- |
| Prometheuséƒ¨ç½²é…ç½® | è¿ç»´å·¥ç¨‹å¸ˆ | 2å¤©  | ç›‘æ§æ•°æ®æ­£å¸¸é‡‡é›† |
| Grafanaä»ªè¡¨æ¿æ­å»º  | è¿ç»´å·¥ç¨‹å¸ˆ | 3å¤©  | åŸºç¡€å¤§ç›˜å¯ç”¨     |
| AlertManageré…ç½®   | è¿ç»´å·¥ç¨‹å¸ˆ | 2å¤©  | å‘Šè­¦è§„åˆ™ç”Ÿæ•ˆ     |
| åº”ç”¨æŒ‡æ ‡é›†æˆ       | åç«¯å¼€å‘   | 4å¤©  | APMæŒ‡æ ‡æ­£å¸¸ä¸ŠæŠ¥  |
| åŸºç¡€å‘Šè­¦è§„åˆ™       | è¿ç»´å·¥ç¨‹å¸ˆ | 3å¤©  | å…³é”®å‘Šè­¦å¯è§¦å‘   |

### é˜¶æ®µäºŒï¼šæ—¥å¿—å’Œé“¾è·¯è¿½è¸ª (2å‘¨)

**ç›®æ ‡**: å®Œå–„æ—¥å¿—ç®¡ç†å’Œåˆ†å¸ƒå¼è¿½è¸ª

| ä»»åŠ¡           | è´Ÿè´£äºº     | å·¥æœŸ | éªŒæ”¶æ ‡å‡†           |
| -------------- | ---------- | ---- | ------------------ |
| ELK Stackéƒ¨ç½²  | è¿ç»´å·¥ç¨‹å¸ˆ | 3å¤©  | æ—¥å¿—æ­£å¸¸æ”¶é›†å’ŒæŸ¥è¯¢ |
| åº”ç”¨æ—¥å¿—é›†æˆ   | åç«¯å¼€å‘   | 3å¤©  | ç»“æ„åŒ–æ—¥å¿—è¾“å‡º     |
| Jaegeréƒ¨ç½²é…ç½® | è¿ç»´å·¥ç¨‹å¸ˆ | 2å¤©  | é“¾è·¯è¿½è¸ªæ­£å¸¸å·¥ä½œ   |
| é“¾è·¯è¿½è¸ªé›†æˆ   | åç«¯å¼€å‘   | 4å¤©  | å…³é”®æµç¨‹å¯è¿½è¸ª     |

### é˜¶æ®µä¸‰ï¼šä¸šåŠ¡ç›‘æ§å’Œæ™ºèƒ½å‘Šè­¦ (2å‘¨)

**ç›®æ ‡**: å»ºç«‹ä¸šåŠ¡ç›‘æ§å’Œæ™ºèƒ½å‘Šè­¦ç³»ç»Ÿ

| ä»»åŠ¡         | è´Ÿè´£äºº   | å·¥æœŸ | éªŒæ”¶æ ‡å‡†         |
| ------------ | -------- | ---- | ---------------- |
| ä¸šåŠ¡æŒ‡æ ‡å®šä¹‰ | äº§å“ç»ç† | 2å¤©  | ä¸šåŠ¡æŒ‡æ ‡æ¸…å•ç¡®å®š |
| ä¸šåŠ¡ç›‘æ§å¼€å‘ | åç«¯å¼€å‘ | 5å¤©  | ä¸šåŠ¡æŒ‡æ ‡æ­£å¸¸é‡‡é›† |
| æ™ºèƒ½å‘Šè­¦ç³»ç»Ÿ | åç«¯å¼€å‘ | 4å¤©  | å‘Šè­¦æŠ‘åˆ¶å’Œå‡çº§   |
| å‘Šè­¦é€šçŸ¥é›†æˆ | åç«¯å¼€å‘ | 3å¤©  | å¤šæ¸ é“é€šçŸ¥æ­£å¸¸   |

### é˜¶æ®µå››ï¼šä¼˜åŒ–å’Œè‡ªåŠ¨åŒ– (2å‘¨)

**ç›®æ ‡**: ä¼˜åŒ–ç›‘æ§æ€§èƒ½ï¼Œå®ç°è‡ªåŠ¨åŒ–è¿ç»´

| ä»»åŠ¡         | è´Ÿè´£äºº     | å·¥æœŸ | éªŒæ”¶æ ‡å‡†         |
| ------------ | ---------- | ---- | ---------------- |
| ç›‘æ§æ€§èƒ½ä¼˜åŒ– | è¿ç»´å·¥ç¨‹å¸ˆ | 3å¤©  | ç›‘æ§ç³»ç»Ÿç¨³å®šè¿è¡Œ |
| è‡ªåŠ¨åŒ–å“åº”   | DevOps     | 4å¤©  | è‡ªåŠ¨æ•…éšœå¤„ç†     |
| ç›‘æ§æ–‡æ¡£å®Œå–„ | æŠ€æœ¯å†™ä½œ   | 2å¤©  | å®Œæ•´æ“ä½œæ‰‹å†Œ     |
| å›¢é˜ŸåŸ¹è®­     | é¡¹ç›®ç»ç†   | 3å¤©  | å›¢é˜ŸæŒæ¡ç›‘æ§å·¥å…· |

---

## âœ… éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶

- [ ] **æŒ‡æ ‡é‡‡é›†**: ç³»ç»Ÿã€åº”ç”¨ã€ä¸šåŠ¡æŒ‡æ ‡æ­£å¸¸é‡‡é›†
- [ ] **å¯è§†åŒ–**: Grafanaä»ªè¡¨æ¿å®Œæ•´å±•ç¤º
- [ ] **å‘Šè­¦ç³»ç»Ÿ**: æ™ºèƒ½å‘Šè­¦å’Œå¤šæ¸ é“é€šçŸ¥
- [ ] **æ—¥å¿—ç®¡ç†**: ç»“æ„åŒ–æ—¥å¿—æ”¶é›†å’Œåˆ†æ
- [ ] **é“¾è·¯è¿½è¸ª**: å…³é”®ä¸šåŠ¡æµç¨‹å¯è¿½è¸ª
- [ ] **è‡ªåŠ¨åŒ–**: è‡ªåŠ¨æ•…éšœæ£€æµ‹å’Œå“åº”

### æ€§èƒ½éªŒæ”¶

- [ ] **ç›‘æ§å»¶è¿Ÿ**: æŒ‡æ ‡é‡‡é›†å»¶è¿Ÿ<30ç§’
- [ ] **æŸ¥è¯¢æ€§èƒ½**: GrafanaæŸ¥è¯¢å“åº”<3ç§’
- [ ] **å­˜å‚¨æ•ˆç‡**: ç›‘æ§æ•°æ®å‹ç¼©ç‡>70%
- [ ] **ç³»ç»Ÿå¼€é”€**: ç›‘æ§ç³»ç»Ÿèµ„æºæ¶ˆè€—<5%

### å¯ç”¨æ€§éªŒæ”¶

- [ ] **ç›‘æ§å¯ç”¨æ€§**: ç›‘æ§ç³»ç»Ÿå¯ç”¨æ€§>99.9%
- [ ] **å‘Šè­¦åŠæ—¶æ€§**: æ•…éšœå‘Šè­¦å»¶è¿Ÿ<5åˆ†é’Ÿ
- [ ] **å‘Šè­¦å‡†ç¡®æ€§**: å‘Šè­¦å‡†ç¡®ç‡>90%
- [ ] **æ•…éšœæ¢å¤**: ç›‘æ§ç³»ç»Ÿæ•…éšœè‡ªåŠ¨æ¢å¤

---

## ğŸ“Š æˆåŠŸæŒ‡æ ‡

### è¿ç»´æ•ˆç‡æŒ‡æ ‡

```yaml
æ•…éšœå¤„ç†:
  - æ•…éšœå‘ç°æ—¶é—´: 30åˆ†é’Ÿ â†’ 5åˆ†é’Ÿ
  - æ•…éšœå®šä½æ—¶é—´: 1å°æ—¶ â†’ 15åˆ†é’Ÿ
  - æ•…éšœæ¢å¤æ—¶é—´: 2å°æ—¶ â†’ 30åˆ†é’Ÿ
  - é‡å¤æ•…éšœç‡: 30% â†’ 10%

ç›‘æ§è´¨é‡:
  - ç›‘æ§è¦†ç›–ç‡: 70% â†’ 95%
  - å‘Šè­¦å‡†ç¡®ç‡: 60% â†’ 90%
  - è¯¯æŠ¥ç‡: 40% â†’ 10%
  - æ¼æŠ¥ç‡: 20% â†’ 5%

è¿ç»´è‡ªåŠ¨åŒ–:
  - è‡ªåŠ¨åŒ–å¤„ç†ç‡: 20% â†’ 70%
  - äººå·¥å¹²é¢„æ¬¡æ•°: å‡å°‘60%
  - è¿ç»´å“åº”æ—¶é—´: å‡å°‘50%
```

### ä¸šåŠ¡å½±å“æŒ‡æ ‡

```yaml
ç³»ç»Ÿç¨³å®šæ€§:
  - ç³»ç»Ÿå¯ç”¨æ€§: 99.9% â†’ 99.95%
  - å¹³å‡æ•…éšœæ—¶é—´: 2å°æ—¶ â†’ 30åˆ†é’Ÿ
  - ç”¨æˆ·ä½“éªŒè¯„åˆ†: 4.2 â†’ 4.6

æˆæœ¬æ•ˆç›Š:
  - è¿ç»´æˆæœ¬: é™ä½30%
  - æ•…éšœæŸå¤±: å‡å°‘70%
  - ç›‘æ§ROI: >300
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [æŠ€æœ¯æ¶æ„ä¼˜åŒ–æŒ‡å—](./01-æŠ€æœ¯æ¶æ„ä¼˜åŒ–æŒ‡å—.md)
- [æ€§èƒ½ä¼˜åŒ–å®æ–½æ–¹æ¡ˆ](./02-æ€§èƒ½ä¼˜åŒ–å®æ–½æ–¹æ¡ˆ.md)
- [ä»£ç è´¨é‡æå‡è®¡åˆ’](./03-ä»£ç è´¨é‡æå‡è®¡åˆ’.md)
- [å®‰å…¨æ€§å¢å¼ºæ–¹æ¡ˆ](./04-å®‰å…¨æ€§å¢å¼ºæ–¹æ¡ˆ.md)

---

**æ–‡æ¡£ç»´æŠ¤**: é¡¹ç›®ç»ç†  
**æŠ€æœ¯å®¡æ ¸**: è¿ç»´æ¶æ„å¸ˆ  
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ22æ—¥
