# 英语四级智能训练系统部署运维优化方案

## 📋 概述

本文档基于《英语四级智能训练系统全面技术架构审查报告》和《英语四级智能训练系统深度符合性审查报告》的发现，针对当前部署运维体系的不足，提出全面的DevOps优化方案。旨在建立自动化、标准化、可靠的部署运维体系，提升系统交付效率和运行稳定性。

---

## 🎯 优化目标

### 核心目标

- **自动化部署**: 实现从代码提交到生产部署的全自动化流程
- **环境一致性**: 确保开发、测试、生产环境的一致性
- **快速交付**: 缩短功能从开发到上线的周期
- **稳定运维**: 建立可靠的监控、备份、恢复机制
- **安全合规**: 确保部署过程的安全性和合规性

### 量化指标

- 部署频率: 每周1次 → 每日多次
- 部署时间: 2小时 → 15分钟
- 部署成功率: 80% → 99%
- 回滚时间: 30分钟 → 5分钟
- 环境搭建时间: 4小时 → 30分钟

---

## 📊 当前部署运维现状

### 现有能力评估

```yaml
代码管理:
  - 版本控制: ✅ Git + GitHub
  - 分支策略: ⚠️ 简单分支模型
  - 代码审查: ⚠️ 基础PR流程
  - 标签管理: ❌ 缺失

构建流程:
  - 自动构建: ⚠️ 基础CI配置
  - 测试集成: ⚠️ 部分自动化
  - 代码质量检查: ❌ 缺失
  - 安全扫描: ❌ 缺失

部署流程:
  - 自动部署: ❌ 手动部署
  - 环境管理: ⚠️ 基础容器化
  - 配置管理: ❌ 硬编码配置
  - 蓝绿部署: ❌ 缺失

运维监控:
  - 服务监控: ⚠️ 基础监控
  - 日志管理: ⚠️ 分散存储
  - 备份策略: ⚠️ 手动备份
  - 灾难恢复: ❌ 缺失
```

### 主要问题

1. **手动部署风险**: 依赖人工操作，容易出错
2. **环境不一致**: 开发、测试、生产环境差异大
3. **配置管理混乱**: 配置分散，难以管理
4. **缺乏回滚机制**: 部署失败后恢复困难
5. **监控不完善**: 缺乏全面的运维监控

---

## 🏗️ DevOps架构设计

### 整体架构

```mermaid
graph TB
    subgraph "开发阶段"
        A[开发者] --> B[Git仓库]
        B --> C[Feature分支]
        C --> D[Pull Request]
    end

    subgraph "CI/CD流水线"
        D --> E[代码检查]
        E --> F[单元测试]
        F --> G[构建镜像]
        G --> H[安全扫描]
        H --> I[集成测试]
    end

    subgraph "部署阶段"
        I --> J[测试环境部署]
        J --> K[自动化测试]
        K --> L[预生产部署]
        L --> M[生产环境部署]
    end

    subgraph "运维监控"
        M --> N[服务监控]
        N --> O[日志收集]
        O --> P[告警通知]
        P --> Q[自动恢复]
    end
```

### 技术栈选择

```yaml
容器化:
  - 容器运行时: Docker
  - 容器编排: Kubernetes
  - 镜像仓库: Harbor
  - 网络: Calico

CI/CD:
  - 持续集成: GitHub Actions
  - 部署工具: ArgoCD
  - 配置管理: Helm
  - 密钥管理: Vault

基础设施:
  - 云平台: 阿里云/AWS
  - 负载均衡: Nginx Ingress
  - 存储: NFS/云存储
  - 网络: VPC

监控运维:
  - 监控: Prometheus + Grafana
  - 日志: ELK Stack
  - 告警: AlertManager
  - 备份: Velero
```

---

## 🔧 核心组件实现

### 1. CI/CD流水线配置

```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

env:
  REGISTRY: harbor.company.com
  IMAGE_NAME: english-training-system

jobs:
  # 代码质量检查
  code-quality:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          pip install -r requirements-dev.txt

      - name: Run linting
        run: |
          flake8 backend/
          black --check backend/
          isort --check-only backend/

      - name: Run security scan
        run: |
          bandit -r backend/
          safety check

      - name: SonarQube Scan
        uses: sonarqube-quality-gate-action@master
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

  # 前端构建和测试
  frontend-build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "20"
          cache: "pnpm"

      - name: Install dependencies
        run: |
          cd frontend
          pnpm install

      - name: Run linting
        run: |
          cd frontend
          pnpm lint

      - name: Run type checking
        run: |
          cd frontend
          pnpm type-check

      - name: Run tests
        run: |
          cd frontend
          pnpm test

      - name: Build application
        run: |
          cd frontend
          pnpm build

      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: frontend-build
          path: frontend/.next

  # 后端测试
  backend-test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-test.txt

      - name: Run migrations
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
        run: |
          cd backend
          python manage.py migrate

      - name: Run tests
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
        run: |
          cd backend
          python -m pytest --cov=. --cov-report=xml

      - name: Upload coverage reports
        uses: codecov/codecov-action@v3
        with:
          file: ./backend/coverage.xml

  # 构建和推送镜像
  build-and-push:
    needs: [code-quality, frontend-build, backend-test]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Download frontend build
        uses: actions/download-artifact@v3
        with:
          name: frontend-build
          path: frontend/.next

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Login to Harbor
        uses: docker/login-action@v2
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ secrets.HARBOR_USERNAME }}
          password: ${{ secrets.HARBOR_PASSWORD }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v4
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-

      - name: Build and push backend image
        uses: docker/build-push-action@v4
        with:
          context: ./backend
          file: ./backend/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}-backend
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build and push frontend image
        uses: docker/build-push-action@v4
        with:
          context: ./frontend
          file: ./frontend/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}-frontend
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # 部署到测试环境
  deploy-staging:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    environment: staging

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: "v1.28.0"

      - name: Configure kubectl
        run: |
          echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > kubeconfig
          export KUBECONFIG=kubeconfig

      - name: Deploy to staging
        run: |
          export KUBECONFIG=kubeconfig
          helm upgrade --install english-training-staging ./k8s/helm \
            --namespace staging \
            --set image.tag=${{ github.sha }} \
            --set environment=staging \
            --values ./k8s/helm/values-staging.yaml

      - name: Wait for deployment
        run: |
          export KUBECONFIG=kubeconfig
          kubectl rollout status deployment/english-training-backend -n staging
          kubectl rollout status deployment/english-training-frontend -n staging

      - name: Run smoke tests
        run: |
          # 运行冒烟测试
          python scripts/smoke_tests.py --env staging

  # 部署到生产环境
  deploy-production:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: "v1.28.0"

      - name: Configure kubectl
        run: |
          echo "${{ secrets.KUBE_CONFIG_PRODUCTION }}" | base64 -d > kubeconfig
          export KUBECONFIG=kubeconfig

      - name: Deploy to production
        run: |
          export KUBECONFIG=kubeconfig
          helm upgrade --install english-training-prod ./k8s/helm \
            --namespace production \
            --set image.tag=${{ github.sha }} \
            --set environment=production \
            --values ./k8s/helm/values-production.yaml

      - name: Wait for deployment
        run: |
          export KUBECONFIG=kubeconfig
          kubectl rollout status deployment/english-training-backend -n production
          kubectl rollout status deployment/english-training-frontend -n production

      - name: Run health checks
        run: |
          # 运行健康检查
          python scripts/health_checks.py --env production

      - name: Notify deployment
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: "#deployments"
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

### 2. Kubernetes部署配置

```yaml
# k8s/helm/templates/backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "english-training.fullname" . }}-backend
  labels:
    {{- include "english-training.labels" . | nindent 4 }}
    component: backend
spec:
  replicas: {{ .Values.backend.replicaCount }}
  selector:
    matchLabels:
      {{- include "english-training.selectorLabels" . | nindent 6 }}
      component: backend
  template:
    metadata:
      annotations:
        checksum/config: {{ include (print $.Template.BasePath "/configmap.yaml") . | sha256sum }}
        checksum/secret: {{ include (print $.Template.BasePath "/secret.yaml") . | sha256sum }}
      labels:
        {{- include "english-training.selectorLabels" . | nindent 8 }}
        component: backend
    spec:
      serviceAccountName: {{ include "english-training.serviceAccountName" . }}
      securityContext:
        {{- toYaml .Values.backend.podSecurityContext | nindent 8 }}
      initContainers:
        - name: migrate
          image: "{{ .Values.backend.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          command: ["python", "manage.py", "migrate"]
          env:
            {{- include "english-training.env" . | nindent 12 }}
          volumeMounts:
            - name: config
              mountPath: /app/config
              readOnly: true
      containers:
        - name: backend
          securityContext:
            {{- toYaml .Values.backend.securityContext | nindent 12 }}
          image: "{{ .Values.backend.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.backend.image.pullPolicy }}
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /health/
              port: http
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /ready/
              port: http
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 3
          env:
            {{- include "english-training.env" . | nindent 12 }}
          resources:
            {{- toYaml .Values.backend.resources | nindent 12 }}
          volumeMounts:
            - name: config
              mountPath: /app/config
              readOnly: true
            - name: media
              mountPath: /app/media
      volumes:
        - name: config
          configMap:
            name: {{ include "english-training.fullname" . }}
        - name: media
          persistentVolumeClaim:
            claimName: {{ include "english-training.fullname" . }}-media
      {{- with .Values.backend.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.backend.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.backend.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}

---
# k8s/helm/templates/frontend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "english-training.fullname" . }}-frontend
  labels:
    {{- include "english-training.labels" . | nindent 4 }}
    component: frontend
spec:
  replicas: {{ .Values.frontend.replicaCount }}
  selector:
    matchLabels:
      {{- include "english-training.selectorLabels" . | nindent 6 }}
      component: frontend
  template:
    metadata:
      annotations:
        checksum/config: {{ include (print $.Template.BasePath "/configmap.yaml") . | sha256sum }}
      labels:
        {{- include "english-training.selectorLabels" . | nindent 8 }}
        component: frontend
    spec:
      serviceAccountName: {{ include "english-training.serviceAccountName" . }}
      securityContext:
        {{- toYaml .Values.frontend.podSecurityContext | nindent 8 }}
      containers:
        - name: frontend
          securityContext:
            {{- toYaml .Values.frontend.securityContext | nindent 12 }}
          image: "{{ .Values.frontend.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.frontend.image.pullPolicy }}
          ports:
            - name: http
              containerPort: 3000
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /api/health
              port: http
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /api/health
              port: http
            initialDelaySeconds: 5
            periodSeconds: 5
          env:
            - name: NEXT_PUBLIC_API_URL
              value: {{ .Values.frontend.apiUrl | quote }}
            - name: NODE_ENV
              value: {{ .Values.environment | quote }}
          resources:
            {{- toYaml .Values.frontend.resources | nindent 12 }}
      {{- with .Values.frontend.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.frontend.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.frontend.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}

---
# k8s/helm/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: {{ include "english-training.fullname" . }}
  labels:
    {{- include "english-training.labels" . | nindent 4 }}
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - {{ .Values.ingress.host }}
      secretName: {{ include "english-training.fullname" . }}-tls
  rules:
    - host: {{ .Values.ingress.host }}
      http:
        paths:
          - path: /api
            pathType: Prefix
            backend:
              service:
                name: {{ include "english-training.fullname" . }}-backend
                port:
                  number: 8000
          - path: /admin
            pathType: Prefix
            backend:
              service:
                name: {{ include "english-training.fullname" . }}-backend
                port:
                  number: 8000
          - path: /
            pathType: Prefix
            backend:
              service:
                name: {{ include "english-training.fullname" . }}-frontend
                port:
                  number: 3000
```

### 3. 配置管理系统

```python
# scripts/config_manager.py
import os
import yaml
import json
from typing import Dict, Any, Optional
from pathlib import Path
from dataclasses import dataclass
from enum import Enum

class Environment(Enum):
    """环境类型"""
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION = "production"

@dataclass
class ConfigTemplate:
    """配置模板"""
    name: str
    template_path: str
    output_path: str
    variables: Dict[str, Any]

class ConfigManager:
    """配置管理器"""

    def __init__(self, config_dir: str = "./config"):
        self.config_dir = Path(config_dir)
        self.templates_dir = self.config_dir / "templates"
        self.environments_dir = self.config_dir / "environments"

        # 确保目录存在
        self.config_dir.mkdir(exist_ok=True)
        self.templates_dir.mkdir(exist_ok=True)
        self.environments_dir.mkdir(exist_ok=True)

    def load_environment_config(self, env: Environment) -> Dict[str, Any]:
        """加载环境配置"""
        config_file = self.environments_dir / f"{env.value}.yaml"

        if not config_file.exists():
            raise FileNotFoundError(f"环境配置文件不存在: {config_file}")

        with open(config_file, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def generate_config(self, env: Environment, template_name: str) -> str:
        """生成配置文件"""
        # 加载环境变量
        env_config = self.load_environment_config(env)

        # 加载模板
        template_file = self.templates_dir / f"{template_name}.yaml.j2"
        if not template_file.exists():
            raise FileNotFoundError(f"配置模板不存在: {template_file}")

        with open(template_file, 'r', encoding='utf-8') as f:
            template_content = f.read()

        # 渲染模板
        from jinja2 import Template
        template = Template(template_content)

        # 合并环境变量和系统环境变量
        variables = {
            **env_config,
            **dict(os.environ),
            'environment': env.value
        }

        return template.render(**variables)

    def deploy_config(self, env: Environment, template_name: str,
                     output_path: Optional[str] = None) -> str:
        """部署配置文件"""
        config_content = self.generate_config(env, template_name)

        if output_path is None:
            output_path = f"{template_name}-{env.value}.yaml"

        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(config_content)

        return str(output_file)

    def validate_config(self, env: Environment) -> bool:
        """验证配置"""
        try:
            config = self.load_environment_config(env)

            # 检查必需的配置项
            required_keys = [
                'database.host',
                'database.name',
                'redis.host',
                'secret_key',
                'allowed_hosts'
            ]

            for key in required_keys:
                if not self._get_nested_value(config, key):
                    print(f"缺少必需的配置项: {key}")
                    return False

            # 验证数据库连接
            if not self._validate_database_config(config.get('database', {})):
                return False

            # 验证Redis连接
            if not self._validate_redis_config(config.get('redis', {})):
                return False

            return True

        except Exception as e:
            print(f"配置验证失败: {e}")
            return False

    def _get_nested_value(self, data: Dict[str, Any], key: str) -> Any:
        """获取嵌套字典的值"""
        keys = key.split('.')
        value = data

        for k in keys:
            if isinstance(value, dict) and k in value:
                value = value[k]
            else:
                return None

        return value

    def _validate_database_config(self, db_config: Dict[str, Any]) -> bool:
        """验证数据库配置"""
        try:
            import psycopg2

            conn = psycopg2.connect(
                host=db_config.get('host'),
                port=db_config.get('port', 5432),
                database=db_config.get('name'),
                user=db_config.get('user'),
                password=db_config.get('password')
            )
            conn.close()
            return True

        except Exception as e:
            print(f"数据库连接验证失败: {e}")
            return False

    def _validate_redis_config(self, redis_config: Dict[str, Any]) -> bool:
        """验证Redis配置"""
        try:
            import redis

            client = redis.Redis(
                host=redis_config.get('host'),
                port=redis_config.get('port', 6379),
                db=redis_config.get('db', 0),
                password=redis_config.get('password')
            )
            client.ping()
            return True

        except Exception as e:
            print(f"Redis连接验证失败: {e}")
            return False

    def backup_config(self, env: Environment) -> str:
        """备份配置"""
        from datetime import datetime

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_dir = self.config_dir / "backups" / timestamp
        backup_dir.mkdir(parents=True, exist_ok=True)

        # 备份环境配置
        env_config_file = self.environments_dir / f"{env.value}.yaml"
        if env_config_file.exists():
            backup_file = backup_dir / f"{env.value}.yaml"
            backup_file.write_text(env_config_file.read_text())

        return str(backup_dir)

    def rollback_config(self, env: Environment, backup_timestamp: str) -> bool:
        """回滚配置"""
        try:
            backup_dir = self.config_dir / "backups" / backup_timestamp
            backup_file = backup_dir / f"{env.value}.yaml"

            if not backup_file.exists():
                print(f"备份文件不存在: {backup_file}")
                return False

            # 恢复配置
            env_config_file = self.environments_dir / f"{env.value}.yaml"
            env_config_file.write_text(backup_file.read_text())

            return True

        except Exception as e:
            print(f"配置回滚失败: {e}")
            return False

class SecretManager:
    """密钥管理器"""

    def __init__(self, vault_url: str, vault_token: str):
        self.vault_url = vault_url
        self.vault_token = vault_token
        self.client = self._init_vault_client()

    def _init_vault_client(self):
        """初始化Vault客户端"""
        try:
            import hvac

            client = hvac.Client(
                url=self.vault_url,
                token=self.vault_token
            )

            if not client.is_authenticated():
                raise Exception("Vault认证失败")

            return client

        except ImportError:
            print("请安装hvac库: pip install hvac")
            return None
        except Exception as e:
            print(f"Vault客户端初始化失败: {e}")
            return None

    def get_secret(self, path: str, key: str) -> Optional[str]:
        """获取密钥"""
        if not self.client:
            return None

        try:
            response = self.client.secrets.kv.v2.read_secret_version(path=path)
            return response['data']['data'].get(key)

        except Exception as e:
            print(f"获取密钥失败 ({path}/{key}): {e}")
            return None

    def set_secret(self, path: str, secrets: Dict[str, str]) -> bool:
        """设置密钥"""
        if not self.client:
            return False

        try:
            self.client.secrets.kv.v2.create_or_update_secret(
                path=path,
                secret=secrets
            )
            return True

        except Exception as e:
            print(f"设置密钥失败 ({path}): {e}")
            return False

    def rotate_secret(self, path: str, key: str, new_value: str) -> bool:
        """轮换密钥"""
        if not self.client:
            return False

        try:
            # 获取现有密钥
            response = self.client.secrets.kv.v2.read_secret_version(path=path)
            current_secrets = response['data']['data']

            # 更新密钥
            current_secrets[key] = new_value

            # 保存更新后的密钥
            return self.set_secret(path, current_secrets)

        except Exception as e:
            print(f"轮换密钥失败 ({path}/{key}): {e}")
            return False

# 使用示例
if __name__ == "__main__":
    # 配置管理
    config_manager = ConfigManager()

    # 验证生产环境配置
    if config_manager.validate_config(Environment.PRODUCTION):
        print("生产环境配置验证通过")
    else:
        print("生产环境配置验证失败")

    # 生成Kubernetes配置
    k8s_config = config_manager.generate_config(
        Environment.PRODUCTION,
        "kubernetes"
    )
    print("Kubernetes配置已生成")

    # 密钥管理
    secret_manager = SecretManager(
        vault_url="https://vault.company.com",
        vault_token=os.getenv("VAULT_TOKEN")
    )

    # 获取数据库密码
    db_password = secret_manager.get_secret(
        "english-training/production",
        "database_password"
    )
```

### 4. 自动化运维脚本

```python
# scripts/deployment_manager.py
import subprocess
import time
import requests
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from enum import Enum
import yaml
import json

class DeploymentStrategy(Enum):
    """部署策略"""
    ROLLING_UPDATE = "rolling_update"
    BLUE_GREEN = "blue_green"
    CANARY = "canary"

class DeploymentStatus(Enum):
    """部署状态"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    SUCCESS = "success"
    FAILED = "failed"
    ROLLED_BACK = "rolled_back"

@dataclass
class DeploymentConfig:
    """部署配置"""
    environment: str
    namespace: str
    image_tag: str
    strategy: DeploymentStrategy
    replicas: int
    health_check_url: str
    rollback_on_failure: bool = True
    max_unavailable: str = "25%"
    max_surge: str = "25%"

class DeploymentManager:
    """部署管理器"""

    def __init__(self, kubeconfig_path: str):
        self.kubeconfig_path = kubeconfig_path
        self.deployment_history: List[Dict[str, Any]] = []

    def deploy(self, config: DeploymentConfig) -> bool:
        """执行部署"""
        deployment_id = self._generate_deployment_id()

        deployment_record = {
            'id': deployment_id,
            'config': config,
            'status': DeploymentStatus.PENDING,
            'start_time': time.time(),
            'logs': []
        }

        self.deployment_history.append(deployment_record)

        try:
            self._log(deployment_record, "开始部署")
            deployment_record['status'] = DeploymentStatus.IN_PROGRESS

            # 预部署检查
            if not self._pre_deployment_checks(config, deployment_record):
                raise Exception("预部署检查失败")

            # 执行部署策略
            if config.strategy == DeploymentStrategy.ROLLING_UPDATE:
                success = self._rolling_update_deployment(config, deployment_record)
            elif config.strategy == DeploymentStrategy.BLUE_GREEN:
                success = self._blue_green_deployment(config, deployment_record)
            elif config.strategy == DeploymentStrategy.CANARY:
                success = self._canary_deployment(config, deployment_record)
            else:
                raise Exception(f"不支持的部署策略: {config.strategy}")

            if success:
                # 部署后检查
                if self._post_deployment_checks(config, deployment_record):
                    deployment_record['status'] = DeploymentStatus.SUCCESS
                    self._log(deployment_record, "部署成功")
                    return True
                else:
                    raise Exception("部署后检查失败")
            else:
                raise Exception("部署执行失败")

        except Exception as e:
            self._log(deployment_record, f"部署失败: {e}")
            deployment_record['status'] = DeploymentStatus.FAILED

            # 自动回滚
            if config.rollback_on_failure:
                self._log(deployment_record, "开始自动回滚")
                if self.rollback(config.environment, config.namespace):
                    deployment_record['status'] = DeploymentStatus.ROLLED_BACK
                    self._log(deployment_record, "自动回滚成功")
                else:
                    self._log(deployment_record, "自动回滚失败")

            return False

        finally:
            deployment_record['end_time'] = time.time()
            deployment_record['duration'] = (
                deployment_record['end_time'] - deployment_record['start_time']
            )

    def _pre_deployment_checks(self, config: DeploymentConfig,
                              deployment_record: Dict[str, Any]) -> bool:
        """预部署检查"""
        self._log(deployment_record, "执行预部署检查")

        # 检查集群连接
        if not self._check_cluster_connection():
            self._log(deployment_record, "集群连接检查失败")
            return False

        # 检查命名空间
        if not self._check_namespace(config.namespace):
            self._log(deployment_record, f"命名空间检查失败: {config.namespace}")
            return False

        # 检查镜像存在性
        if not self._check_image_exists(config.image_tag):
            self._log(deployment_record, f"镜像检查失败: {config.image_tag}")
            return False

        # 检查资源配额
        if not self._check_resource_quota(config.namespace, config.replicas):
            self._log(deployment_record, "资源配额检查失败")
            return False

        self._log(deployment_record, "预部署检查通过")
        return True

    def _rolling_update_deployment(self, config: DeploymentConfig,
                                  deployment_record: Dict[str, Any]) -> bool:
        """滚动更新部署"""
        self._log(deployment_record, "执行滚动更新部署")

        try:
            # 更新Helm部署
            cmd = [
                "helm", "upgrade", "--install",
                f"english-training-{config.environment}",
                "./k8s/helm",
                "--namespace", config.namespace,
                "--set", f"image.tag={config.image_tag}",
                "--set", f"replicaCount={config.replicas}",
                "--set", f"strategy.type=RollingUpdate",
                "--set", f"strategy.rollingUpdate.maxUnavailable={config.max_unavailable}",
                "--set", f"strategy.rollingUpdate.maxSurge={config.max_surge}",
                "--values", f"./k8s/helm/values-{config.environment}.yaml",
                "--wait", "--timeout=600s"
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                env={**subprocess.os.environ, "KUBECONFIG": self.kubeconfig_path}
            )

            if result.returncode != 0:
                self._log(deployment_record, f"Helm部署失败: {result.stderr}")
                return False

            self._log(deployment_record, "Helm部署成功")

            # 等待部署完成
            if not self._wait_for_deployment(config, deployment_record):
                return False

            return True

        except Exception as e:
            self._log(deployment_record, f"滚动更新部署失败: {e}")
            return False

    def _blue_green_deployment(self, config: DeploymentConfig,
                              deployment_record: Dict[str, Any]) -> bool:
        """蓝绿部署"""
        self._log(deployment_record, "执行蓝绿部署")

        try:
            # 获取当前活跃环境
            current_env = self._get_active_environment(config.namespace)
            new_env = "blue" if current_env == "green" else "green"

            self._log(deployment_record, f"当前环境: {current_env}, 新环境: {new_env}")

            # 部署到新环境
            cmd = [
                "helm", "upgrade", "--install",
                f"english-training-{config.environment}-{new_env}",
                "./k8s/helm",
                "--namespace", config.namespace,
                "--set", f"image.tag={config.image_tag}",
                "--set", f"replicaCount={config.replicas}",
                "--set", f"nameOverride=english-training-{new_env}",
                "--values", f"./k8s/helm/values-{config.environment}.yaml",
                "--wait", "--timeout=600s"
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                env={**subprocess.os.environ, "KUBECONFIG": self.kubeconfig_path}
            )

            if result.returncode != 0:
                self._log(deployment_record, f"新环境部署失败: {result.stderr}")
                return False

            # 健康检查
            if not self._health_check_new_environment(config, new_env, deployment_record):
                return False

            # 切换流量
            if not self._switch_traffic(config.namespace, new_env, deployment_record):
                return False

            # 清理旧环境
            self._cleanup_old_environment(config.namespace, current_env, deployment_record)

            return True

        except Exception as e:
            self._log(deployment_record, f"蓝绿部署失败: {e}")
            return False

    def _canary_deployment(self, config: DeploymentConfig,
                          deployment_record: Dict[str, Any]) -> bool:
        """金丝雀部署"""
        self._log(deployment_record, "执行金丝雀部署")

        try:
            # 部署金丝雀版本（10%流量）
            canary_replicas = max(1, config.replicas // 10)

            cmd = [
                "helm", "upgrade", "--install",
                f"english-training-{config.environment}-canary",
                "./k8s/helm",
                "--namespace", config.namespace,
                "--set", f"image.tag={config.image_tag}",
                "--set", f"replicaCount={canary_replicas}",
                "--set", "nameOverride=english-training-canary",
                "--set", "service.weight=10",
                "--values", f"./k8s/helm/values-{config.environment}.yaml",
                "--wait", "--timeout=600s"
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                env={**subprocess.os.environ, "KUBECONFIG": self.kubeconfig_path}
            )

            if result.returncode != 0:
                self._log(deployment_record, f"金丝雀部署失败: {result.stderr}")
                return False

            # 监控金丝雀版本
            if not self._monitor_canary(config, deployment_record):
                return False

            # 逐步增加流量
            for weight in [25, 50, 75, 100]:
                self._log(deployment_record, f"增加金丝雀流量到 {weight}%")

                if not self._update_canary_weight(config.namespace, weight):
                    self._log(deployment_record, f"更新流量权重失败: {weight}%")
                    return False

                # 监控一段时间
                time.sleep(300)  # 5分钟

                if not self._check_canary_health(config, deployment_record):
                    return False

            # 完全切换到新版本
            if not self._promote_canary(config, deployment_record):
                return False

            return True

        except Exception as e:
            self._log(deployment_record, f"金丝雀部署失败: {e}")
            return False

    def _post_deployment_checks(self, config: DeploymentConfig,
                               deployment_record: Dict[str, Any]) -> bool:
        """部署后检查"""
        self._log(deployment_record, "执行部署后检查")

        # 健康检查
        if not self._health_check(config.health_check_url, deployment_record):
            return False

        # 功能测试
        if not self._run_smoke_tests(config, deployment_record):
            return False

        # 性能检查
        if not self._performance_check(config, deployment_record):
            return False

        self._log(deployment_record, "部署后检查通过")
        return True

    def _health_check(self, url: str, deployment_record: Dict[str, Any],
                     max_retries: int = 10, delay: int = 30) -> bool:
        """健康检查"""
        self._log(deployment_record, f"开始健康检查: {url}")

        for i in range(max_retries):
            try:
                response = requests.get(url, timeout=10)
                if response.status_code == 200:
                    self._log(deployment_record, "健康检查通过")
                    return True
                else:
                    self._log(deployment_record,
                             f"健康检查失败 (尝试 {i+1}/{max_retries}): HTTP {response.status_code}")
            except Exception as e:
                self._log(deployment_record,
                         f"健康检查异常 (尝试 {i+1}/{max_retries}): {e}")

            if i < max_retries - 1:
                time.sleep(delay)

        self._log(deployment_record, "健康检查最终失败")
        return False

    def rollback(self, environment: str, namespace: str) -> bool:
        """回滚部署"""
        try:
            # 获取上一个版本
            cmd = [
                "helm", "history",
                f"english-training-{environment}",
                "--namespace", namespace,
                "--max", "2",
                "--output", "json"
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                env={**subprocess.os.environ, "KUBECONFIG": self.kubeconfig_path}
            )

            if result.returncode != 0:
                print(f"获取部署历史失败: {result.stderr}")
                return False

            history = json.loads(result.stdout)
            if len(history) < 2:
                print("没有可回滚的版本")
                return False

            previous_revision = history[-2]['revision']

            # 执行回滚
            cmd = [
                "helm", "rollback",
                f"english-training-{environment}",
                str(previous_revision),
                "--namespace", namespace,
                "--wait", "--timeout=600s"
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                env={**subprocess.os.environ, "KUBECONFIG": self.kubeconfig_path}
            )

            if result.returncode != 0:
                print(f"回滚失败: {result.stderr}")
                return False

            print(f"回滚到版本 {previous_revision} 成功")
            return True

        except Exception as e:
            print(f"回滚异常: {e}")
            return False

    def _log(self, deployment_record: Dict[str, Any], message: str):
        """记录日志"""
        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
        log_entry = f"[{timestamp}] {message}"
        deployment_record['logs'].append(log_entry)
        print(log_entry)

    def _generate_deployment_id(self) -> str:
        """生成部署ID"""
        import uuid
        return str(uuid.uuid4())[:8]

    def _check_cluster_connection(self) -> bool:
        """检查集群连接"""
        try:
            cmd = ["kubectl", "cluster-info"]
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                env={**subprocess.os.environ, "KUBECONFIG": self.kubeconfig_path}
            )
            return result.returncode == 0
        except Exception:
            return False

    def _check_namespace(self, namespace: str) -> bool:
        """检查命名空间"""
        try:
            cmd = ["kubectl", "get", "namespace", namespace]
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                env={**subprocess.os.environ, "KUBECONFIG": self.kubeconfig_path}
            )
            return result.returncode == 0
        except Exception:
            return False

    def _check_image_exists(self, image_tag: str) -> bool:
        """检查镜像存在性"""
        # 这里可以集成Harbor API来检查镜像
        # 简化实现，假设镜像存在
        return True

    def _check_resource_quota(self, namespace: str, replicas: int) -> bool:
        """检查资源配额"""
        # 这里可以检查CPU、内存等资源配额
        # 简化实现，假设资源充足
        return True

    def _wait_for_deployment(self, config: DeploymentConfig,
                           deployment_record: Dict[str, Any]) -> bool:
        """等待部署完成"""
        self._log(deployment_record, "等待部署完成")

        try:
            cmd = [
                "kubectl", "rollout", "status",
                f"deployment/english-training-{config.environment}-backend",
                "--namespace", config.namespace,
                "--timeout=600s"
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                env={**subprocess.os.environ, "KUBECONFIG": self.kubeconfig_path}
            )

            return result.returncode == 0

        except Exception as e:
            self._log(deployment_record, f"等待部署完成失败: {e}")
            return False

    def _run_smoke_tests(self, config: DeploymentConfig,
                        deployment_record: Dict[str, Any]) -> bool:
        """运行冒烟测试"""
        self._log(deployment_record, "运行冒烟测试")

        try:
            # 运行冒烟测试脚本
            cmd = ["python", "scripts/smoke_tests.py", "--env", config.environment]
            result = subprocess.run(cmd, capture_output=True, text=True)

            if result.returncode == 0:
                self._log(deployment_record, "冒烟测试通过")
                return True
            else:
                self._log(deployment_record, f"冒烟测试失败: {result.stderr}")
                return False

        except Exception as e:
            self._log(deployment_record, f"冒烟测试异常: {e}")
            return False

    def _performance_check(self, config: DeploymentConfig,
                          deployment_record: Dict[str, Any]) -> bool:
        """性能检查"""
        self._log(deployment_record, "执行性能检查")

        # 这里可以集成性能测试工具
        # 简化实现，假设性能正常
        time.sleep(5)
        self._log(deployment_record, "性能检查通过")
        return True

# 使用示例
if __name__ == "__main__":
    deployment_manager = DeploymentManager("/path/to/kubeconfig")

    config = DeploymentConfig(
        environment="production",
        namespace="production",
        image_tag="v1.2.3",
        strategy=DeploymentStrategy.ROLLING_UPDATE,
        replicas=3,
        health_check_url="https://api.english-training.com/health"
    )

    success = deployment_manager.deploy(config)
    if success:
        print("部署成功")
    else:
        print("部署失败")
```

---

## 📅 实施计划

### 阶段一：基础设施准备 (2周)

**目标**: 搭建基础的容器化和CI/CD环境

| 任务               | 负责人       | 工期 | 验收标准     |
| ------------------ | ------------ | ---- | ------------ |
| Kubernetes集群搭建 | DevOps工程师 | 3天  | 集群正常运行 |
| Harbor镜像仓库部署 | DevOps工程师 | 2天  | 镜像推拉正常 |
| GitHub Actions配置 | DevOps工程师 | 3天  | CI流水线运行 |
| Helm Chart开发     | DevOps工程师 | 4天  | 应用可部署   |
| 基础监控搭建       | 运维工程师   | 2天  | 监控数据正常 |

### 阶段二：自动化部署 (2周)

**目标**: 实现自动化部署流程

| 任务         | 负责人       | 工期 | 验收标准       |
| ------------ | ------------ | ---- | -------------- |
| CD流水线开发 | DevOps工程师 | 4天  | 自动部署成功   |
| 配置管理系统 | DevOps工程师 | 3天  | 配置自动化     |
| 密钥管理集成 | 安全工程师   | 3天  | 密钥安全管理   |
| 部署脚本开发 | DevOps工程师 | 4天  | 部署自动化完成 |

### 阶段三：高级部署策略 (2周)

**目标**: 实现蓝绿部署和金丝雀部署

| 任务           | 负责人       | 工期 | 验收标准     |
| -------------- | ------------ | ---- | ------------ |
| 蓝绿部署实现   | DevOps工程师 | 4天  | 蓝绿切换正常 |
| 金丝雀部署实现 | DevOps工程师 | 4天  | 流量控制正常 |
| 自动回滚机制   | DevOps工程师 | 3天  | 回滚功能正常 |
| 部署监控完善   | 运维工程师   | 3天  | 监控告警正常 |

### 阶段四：运维优化 (2周)

**目标**: 完善运维监控和自动化

| 任务         | 负责人         | 工期 | 验收标准     |
| ------------ | -------------- | ---- | ------------ |
| 日志聚合系统 | 运维工程师     | 4天  | 日志集中管理 |
| 备份恢复系统 | 运维工程师     | 4天  | 备份恢复正常 |
| 告警系统优化 | 运维工程师     | 3天  | 告警及时准确 |
| 运维文档完善 | 技术文档工程师 | 3天  | 文档完整可用 |

---

## ✅ 验收标准

### 功能验收

```yaml
自动化部署:
  - ✅ 代码提交后自动触发CI/CD流水线
  - ✅ 自动化测试通过率 >95%
  - ✅ 自动化部署成功率 >99%
  - ✅ 部署时间 <15分钟

环境管理:
  - ✅ 开发、测试、生产环境一致性
  - ✅ 配置管理自动化
  - ✅ 密钥管理安全性
  - ✅ 环境快速搭建 <30分钟

部署策略:
  - ✅ 滚动更新部署正常
  - ✅ 蓝绿部署切换正常
  - ✅ 金丝雀部署流量控制正常
  - ✅ 自动回滚机制有效

监控运维:
  - ✅ 服务监控覆盖率 >95%
  - ✅ 日志聚合和查询正常
  - ✅ 告警及时性 <5分钟
  - ✅ 备份恢复功能正常
```

### 性能验收

```yaml
部署性能:
  - 部署频率: 每日多次
  - 部署时间: <15分钟
  - 部署成功率: >99%
  - 回滚时间: <5分钟

系统性能:
  - 服务可用性: >99.9%
  - 响应时间: <2秒
  - 并发处理: >1000 req/s
  - 资源利用率: 70-80%

运维效率:
  - 故障检测时间: <5分钟
  - 故障恢复时间: <30分钟
  - 运维自动化率: >80%
  - 人工干预次数: <5次/月
```

### 安全验收

```yaml
部署安全:
  - ✅ 镜像安全扫描通过
  - ✅ 密钥管理安全
  - ✅ 网络隔离正常
  - ✅ 访问控制有效

运维安全:
  - ✅ 审计日志完整
  - ✅ 权限控制严格
  - ✅ 数据备份加密
  - ✅ 合规性检查通过
```

---

## 📊 成功指标

### 运维效率指标

```typescript
interface DevOpsMetrics {
  // 部署指标
  deploymentFrequency: number; // 部署频率 (次/天)
  deploymentLeadTime: number; // 部署前置时间 (小时)
  deploymentSuccessRate: number; // 部署成功率 (%)
  rollbackFrequency: number; // 回滚频率 (次/月)

  // 质量指标
  changeFailureRate: number; // 变更失败率 (%)
  meanTimeToRecovery: number; // 平均恢复时间 (分钟)
  systemAvailability: number; // 系统可用性 (%)
  defectEscapeRate: number; // 缺陷逃逸率 (%)

  // 效率指标
  automationCoverage: number; // 自动化覆盖率 (%)
  manualInterventions: number; // 人工干预次数 (次/月)
  incidentResolutionTime: number; // 事件解决时间 (小时)
  teamProductivity: number; // 团队生产力指数
}
```

### 业务影响指标

```typescript
interface BusinessImpactMetrics {
  // 交付指标
  timeToMarket: number; // 上市时间 (天)
  featureDeliveryRate: number; // 功能交付率 (个/月)
  customerSatisfaction: number; // 客户满意度 (1-5)
  systemPerformance: number; // 系统性能指数

  // 成本指标
  infrastructureCost: number; // 基础设施成本 (元/月)
  operationalCost: number; // 运维成本 (元/月)
  developmentCost: number; // 开发成本 (元/月)
  totalCostOfOwnership: number; // 总拥有成本 (元/年)
}
```

---

## 🔄 持续改进

### 监控和度量

```python
# scripts/devops_metrics_collector.py
import time
import json
from typing import Dict, List, Any
from datetime import datetime, timedelta
from dataclasses import dataclass

@dataclass
class DeploymentMetric:
    """部署指标"""
    timestamp: datetime
    environment: str
    duration: float
    success: bool
    rollback: bool
    version: str

class DevOpsMetricsCollector:
    """DevOps指标收集器"""

    def __init__(self):
        self.deployment_history: List[DeploymentMetric] = []
        self.incident_history: List[Dict[str, Any]] = []

    def record_deployment(self, metric: DeploymentMetric):
        """记录部署指标"""
        self.deployment_history.append(metric)

    def calculate_deployment_frequency(self, days: int = 30) -> float:
        """计算部署频率"""
        cutoff_date = datetime.now() - timedelta(days=days)
        recent_deployments = [
            d for d in self.deployment_history
            if d.timestamp >= cutoff_date
        ]
        return len(recent_deployments) / days

    def calculate_deployment_success_rate(self, days: int = 30) -> float:
        """计算部署成功率"""
        cutoff_date = datetime.now() - timedelta(days=days)
        recent_deployments = [
            d for d in self.deployment_history
            if d.timestamp >= cutoff_date
        ]

        if not recent_deployments:
            return 0.0

        successful_deployments = [
            d for d in recent_deployments if d.success
        ]

        return len(successful_deployments) / len(recent_deployments) * 100

    def calculate_mean_deployment_time(self, days: int = 30) -> float:
        """计算平均部署时间"""
        cutoff_date = datetime.now() - timedelta(days=days)
        recent_deployments = [
            d for d in self.deployment_history
            if d.timestamp >= cutoff_date and d.success
        ]

        if not recent_deployments:
            return 0.0

        total_duration = sum(d.duration for d in recent_deployments)
        return total_duration / len(recent_deployments)

    def calculate_rollback_rate(self, days: int = 30) -> float:
        """计算回滚率"""
        cutoff_date = datetime.now() - timedelta(days=days)
        recent_deployments = [
            d for d in self.deployment_history
            if d.timestamp >= cutoff_date
        ]

        if not recent_deployments:
            return 0.0

        rollback_deployments = [
            d for d in recent_deployments if d.rollback
        ]

        return len(rollback_deployments) / len(recent_deployments) * 100

    def generate_report(self) -> Dict[str, Any]:
        """生成指标报告"""
        return {
            'deployment_frequency': self.calculate_deployment_frequency(),
            'deployment_success_rate': self.calculate_deployment_success_rate(),
            'mean_deployment_time': self.calculate_mean_deployment_time(),
            'rollback_rate': self.calculate_rollback_rate(),
            'total_deployments': len(self.deployment_history),
            'report_generated_at': datetime.now().isoformat()
        }
```

### 优化建议

1. **定期评审**: 每月进行DevOps流程评审
2. **工具升级**: 持续关注新技术和工具
3. **团队培训**: 定期进行DevOps技能培训
4. **流程优化**: 基于指标数据优化流程
5. **自动化扩展**: 持续扩大自动化覆盖范围

---

## 📚 相关文档

- [Kubernetes部署指南](./k8s-deployment-guide.md)
- [CI/CD流水线配置](./cicd-pipeline-config.md)
- [监控告警配置](./monitoring-alerting-config.md)
- [安全最佳实践](./security-best-practices.md)
- [故障排查手册](./troubleshooting-guide.md)
- [运维操作手册](./operations-manual.md)

---

**文档版本**: v1.0  
**创建日期**: 2025-01-22  
**最后更新**: 2025-01-22  
**维护人员**: DevOps团队
