# è‹±è¯­å››çº§æ™ºèƒ½è®­ç»ƒç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–å®æ–½æ–¹æ¡ˆ

## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025å¹´1æœˆ22æ—¥  
**åŸºäºæŠ¥å‘Š**: å…¨é¢æŠ€æœ¯æ¶æ„å®¡æŸ¥æŠ¥å‘Š + æ·±åº¦ç¬¦åˆæ€§å®¡æŸ¥æŠ¥å‘Š  
**ä¼˜åŒ–ç›®æ ‡**: å…¨é¢æå‡ç³»ç»Ÿæ€§èƒ½ï¼Œä¼˜åŒ–ç”¨æˆ·ä½“éªŒ  
**é¢„æœŸæ”¶ç›Š**: å“åº”æ—¶é—´å‡å°‘50%ï¼Œå¹¶å‘èƒ½åŠ›æå‡3å€  
**å®æ–½å‘¨æœŸ**: 4-6å‘¨

---

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–æ¦‚è¦

### å½“å‰æ€§èƒ½åŸºçº¿

åŸºäºå®¡æŸ¥æŠ¥å‘Šåˆ†æï¼Œç³»ç»Ÿå½“å‰æ€§èƒ½çŠ¶å†µï¼š

| æ€§èƒ½æŒ‡æ ‡         | å½“å‰çŠ¶æ€   | ç›®æ ‡çŠ¶æ€ | ä¼˜åŒ–ç©ºé—´ |
| ---------------- | ---------- | -------- | -------- |
| **APIå“åº”æ—¶é—´**  | 800-1200ms | <500ms   | 60%+     |
| **é¡µé¢åŠ è½½æ—¶é—´** | 3-5ç§’      | <2ç§’     | 50%+     |
| **å¹¶å‘ç”¨æˆ·æ•°**   | 100ç”¨æˆ·    | 500ç”¨æˆ·  | 400%     |
| **æ•°æ®åº“æŸ¥è¯¢**   | å¹³å‡200ms  | <100ms   | 50%      |
| **AIæœåŠ¡å“åº”**   | 5-10ç§’     | <5ç§’     | 50%      |
| **å†…å­˜ä½¿ç”¨ç‡**   | 70-80%     | <60%     | 20%      |

### æ ¸å¿ƒæ€§èƒ½ç“¶é¢ˆ

1. **ğŸ”´ æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–ä¸è¶³** - N+1æŸ¥è¯¢é—®é¢˜ä¸¥é‡
2. **ğŸ”´ ç¼“å­˜ç­–ç•¥ç¼ºå¤±** - é‡å¤è®¡ç®—å’ŒæŸ¥è¯¢è¿‡å¤š
3. **ğŸŸ¡ å‰ç«¯èµ„æºåŠ è½½** - é™æ€èµ„æºæœªä¼˜åŒ–
4. **ğŸŸ¡ AIæœåŠ¡è°ƒç”¨** - åŒæ­¥è°ƒç”¨é˜»å¡ç”¨æˆ·ä½“éªŒ
5. **ğŸŸ¡ å¹¶å‘å¤„ç†èƒ½åŠ›** - ç¼ºä¹æœ‰æ•ˆçš„è´Ÿè½½å‡è¡¡

---

## ğŸš€ æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–

### 1. æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥

#### é—®é¢˜åˆ†æ

å½“å‰ç³»ç»Ÿå­˜åœ¨å¤§é‡N+1æŸ¥è¯¢é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨è¯¾ç¨‹åˆ—è¡¨ã€å­¦ç”Ÿè¿›åº¦ç­‰åœºæ™¯ã€‚

#### è§£å†³æ–¹æ¡ˆ

**æ­¥éª¤1: æŸ¥è¯¢ä¼˜åŒ–å®ç°**

```python
# learning/models.py - ä¼˜åŒ–æ¨¡å‹æŸ¥è¯¢
from django.db import models
from django.db.models import Prefetch, Count, Avg

class CourseQuerySet(models.QuerySet):
    """è¯¾ç¨‹æŸ¥è¯¢é›†ä¼˜åŒ–"""

    def with_stats(self):
        """é¢„åŠ è½½ç»Ÿè®¡ä¿¡æ¯"""
        return self.annotate(
            student_count=Count('students'),
            avg_progress=Avg('enrollments__progress'),
            assignment_count=Count('assignments')
        )

    def with_related(self):
        """é¢„åŠ è½½å…³è”æ•°æ®"""
        return self.select_related(
            'teacher',
            'category'
        ).prefetch_related(
            'students',
            'assignments',
            Prefetch(
                'enrollments',
                queryset=Enrollment.objects.select_related('student')
            )
        )

    def for_teacher(self, teacher):
        """æ•™å¸ˆè¯¾ç¨‹æŸ¥è¯¢ä¼˜åŒ–"""
        return self.filter(
            teacher=teacher
        ).with_related().with_stats()

class Course(models.Model):
    name = models.CharField(max_length=200)
    teacher = models.ForeignKey('users.User', on_delete=models.CASCADE)
    students = models.ManyToManyField(
        'users.User',
        through='Enrollment',
        related_name='enrolled_courses'
    )

    objects = CourseQuerySet.as_manager()

    class Meta:
        indexes = [
            models.Index(fields=['teacher', 'created_at']),
            models.Index(fields=['status', 'created_at']),
            models.Index(fields=['category', 'level']),
        ]

# learning/services/course_service.py
class CourseService:
    """è¯¾ç¨‹æœåŠ¡ä¼˜åŒ–"""

    @staticmethod
    def get_teacher_courses(teacher_id: int, page: int = 1, page_size: int = 20):
        """è·å–æ•™å¸ˆè¯¾ç¨‹åˆ—è¡¨ - ä¼˜åŒ–ç‰ˆ"""
        from django.core.paginator import Paginator
        from django.core.cache import cache

        # ç¼“å­˜é”®
        cache_key = f'teacher_courses_{teacher_id}_{page}_{page_size}'

        # å°è¯•ä»ç¼“å­˜è·å–
        cached_result = cache.get(cache_key)
        if cached_result:
            return cached_result

        # ä¼˜åŒ–æŸ¥è¯¢
        courses = Course.objects.for_teacher_id(teacher_id)

        # åˆ†é¡µå¤„ç†
        paginator = Paginator(courses, page_size)
        page_obj = paginator.get_page(page)

        # åºåˆ—åŒ–æ•°æ®
        result = {
            'courses': [
                {
                    'id': course.id,
                    'name': course.name,
                    'student_count': course.student_count,
                    'avg_progress': course.avg_progress or 0,
                    'assignment_count': course.assignment_count,
                    'teacher_name': course.teacher.get_full_name(),
                }
                for course in page_obj
            ],
            'total_pages': paginator.num_pages,
            'current_page': page,
            'total_count': paginator.count
        }

        # ç¼“å­˜ç»“æœï¼ˆ5åˆ†é’Ÿï¼‰
        cache.set(cache_key, result, 300)

        return result
```

**æ­¥éª¤2: æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–**

```python
# learning/migrations/0002_add_performance_indexes.py
from django.db import migrations, models

class Migration(migrations.Migration):
    dependencies = [
        ('learning', '0001_initial'),
    ]

    operations = [
        # å¤åˆç´¢å¼•
        migrations.RunSQL(
            "CREATE INDEX CONCURRENTLY idx_course_teacher_status ON learning_course(teacher_id, status);",
            reverse_sql="DROP INDEX IF EXISTS idx_course_teacher_status;"
        ),

        # éƒ¨åˆ†ç´¢å¼•
        migrations.RunSQL(
            "CREATE INDEX CONCURRENTLY idx_active_enrollments ON learning_enrollment(course_id, student_id) WHERE status = 'active';",
            reverse_sql="DROP INDEX IF EXISTS idx_active_enrollments;"
        ),

        # è¡¨è¾¾å¼ç´¢å¼•
        migrations.RunSQL(
            "CREATE INDEX CONCURRENTLY idx_progress_range ON learning_progress(student_id) WHERE progress_percentage >= 80;",
            reverse_sql="DROP INDEX IF EXISTS idx_progress_range;"
        ),

        # å…¨æ–‡æœç´¢ç´¢å¼•
        migrations.RunSQL(
            "CREATE INDEX CONCURRENTLY idx_course_search ON learning_course USING gin(to_tsvector('english', name || ' ' || description));",
            reverse_sql="DROP INDEX IF EXISTS idx_course_search;"
        ),
    ]
```

**æ­¥éª¤3: æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–**

```python
# config/settings/production.py
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.getenv('DB_NAME'),
        'USER': os.getenv('DB_USER'),
        'PASSWORD': os.getenv('DB_PASSWORD'),
        'HOST': os.getenv('DB_HOST'),
        'PORT': os.getenv('DB_PORT'),
        'OPTIONS': {
            'MAX_CONNS': 20,  # æœ€å¤§è¿æ¥æ•°
            'MIN_CONNS': 5,   # æœ€å°è¿æ¥æ•°
            'connect_timeout': 10,
            'options': '-c default_transaction_isolation=read_committed'
        },
        'CONN_MAX_AGE': 600,  # è¿æ¥æœ€å¤§å­˜æ´»æ—¶é—´
        'CONN_HEALTH_CHECKS': True,  # è¿æ¥å¥åº·æ£€æŸ¥
    }
}

# è¯»å†™åˆ†ç¦»é…ç½®
DATABASE_ROUTERS = ['utils.db_router.DatabaseRouter']

DATABASES['replica'] = {
    'ENGINE': 'django.db.backends.postgresql',
    'NAME': os.getenv('DB_REPLICA_NAME'),
    'USER': os.getenv('DB_REPLICA_USER'),
    'PASSWORD': os.getenv('DB_REPLICA_PASSWORD'),
    'HOST': os.getenv('DB_REPLICA_HOST'),
    'PORT': os.getenv('DB_REPLICA_PORT'),
}
```

### 2. ç¼“å­˜ç­–ç•¥å®æ–½

#### Redisç¼“å­˜æ¶æ„

```python
# utils/cache.py
import json
import hashlib
from typing import Any, Optional, Union
from django.core.cache import cache
from django.core.serializers.json import DjangoJSONEncoder
from functools import wraps

class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""

    # ç¼“å­˜æ—¶é—´é…ç½®
    CACHE_TIMEOUTS = {
        'short': 300,      # 5åˆ†é’Ÿ
        'medium': 1800,    # 30åˆ†é’Ÿ
        'long': 3600,      # 1å°æ—¶
        'daily': 86400,    # 24å°æ—¶
    }

    @classmethod
    def get_cache_key(cls, prefix: str, *args, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # åˆ›å»ºå”¯ä¸€æ ‡è¯†
        key_data = {
            'args': args,
            'kwargs': sorted(kwargs.items())
        }
        key_string = json.dumps(key_data, cls=DjangoJSONEncoder, sort_keys=True)
        key_hash = hashlib.md5(key_string.encode()).hexdigest()[:8]

        return f"{prefix}:{key_hash}"

    @classmethod
    def cached_result(cls, timeout: Union[str, int] = 'medium', prefix: str = 'default'):
        """ç¼“å­˜ç»“æœè£…é¥°å™¨"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # ç”Ÿæˆç¼“å­˜é”®
                cache_key = cls.get_cache_key(
                    f"{prefix}:{func.__name__}",
                    *args, **kwargs
                )

                # å°è¯•ä»ç¼“å­˜è·å–
                result = cache.get(cache_key)
                if result is not None:
                    return result

                # æ‰§è¡Œå‡½æ•°
                result = func(*args, **kwargs)

                # è®¾ç½®ç¼“å­˜
                timeout_seconds = (
                    cls.CACHE_TIMEOUTS.get(timeout, timeout)
                    if isinstance(timeout, str)
                    else timeout
                )
                cache.set(cache_key, result, timeout_seconds)

                return result
            return wrapper
        return decorator

# åº”ç”¨ç¼“å­˜ç­–ç•¥
class CourseService:
    """è¯¾ç¨‹æœåŠ¡ - ç¼“å­˜ä¼˜åŒ–ç‰ˆ"""

    @CacheManager.cached_result(timeout='medium', prefix='course')
    def get_course_detail(self, course_id: int, user_id: int):
        """è·å–è¯¾ç¨‹è¯¦æƒ… - ç¼“å­˜ç‰ˆ"""
        course = Course.objects.with_related().get(id=course_id)

        # è·å–ç”¨æˆ·è¿›åº¦
        progress = self.get_user_progress(course_id, user_id)

        return {
            'course': course,
            'progress': progress,
            'assignments': course.assignments.all(),
            'classmates': course.students.all()[:10]  # é™åˆ¶æ•°é‡
        }

    @CacheManager.cached_result(timeout='short', prefix='progress')
    def get_user_progress(self, course_id: int, user_id: int):
        """è·å–ç”¨æˆ·è¿›åº¦ - ç¼“å­˜ç‰ˆ"""
        return Progress.objects.filter(
            course_id=course_id,
            student_id=user_id
        ).aggregate(
            total_progress=Avg('progress_percentage'),
            completed_assignments=Count(
                'assignment',
                filter=models.Q(status='completed')
            )
        )
```

---

## âš¡ å‰ç«¯æ€§èƒ½ä¼˜åŒ–

### 1. èµ„æºåŠ è½½ä¼˜åŒ–

#### Next.jsé…ç½®ä¼˜åŒ–

```javascript
// next.config.js
const nextConfig = {
  // å›¾ç‰‡ä¼˜åŒ–
  images: {
    domains: ["localhost", "your-cdn-domain.com"],
    formats: ["image/webp", "image/avif"],
    minimumCacheTTL: 60 * 60 * 24 * 30, // 30å¤©
  },

  // å‹ç¼©é…ç½®
  compress: true,

  // å®éªŒæ€§åŠŸèƒ½
  experimental: {
    optimizeCss: true,
    optimizePackageImports: ["@/components", "@/lib"],
  },

  // Webpackä¼˜åŒ–
  webpack: (config, { dev, isServer }) => {
    // ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–
    if (!dev && !isServer) {
      config.optimization.splitChunks = {
        chunks: "all",
        cacheGroups: {
          vendor: {
            test: /[\\/]node_modules[\\/]/,
            name: "vendors",
            chunks: "all",
          },
          common: {
            name: "common",
            minChunks: 2,
            chunks: "all",
            enforce: true,
          },
        },
      };
    }

    return config;
  },

  // å¤´éƒ¨ä¼˜åŒ–
  async headers() {
    return [
      {
        source: "/api/:path*",
        headers: [
          {
            key: "Cache-Control",
            value: "public, max-age=300, stale-while-revalidate=60",
          },
        ],
      },
      {
        source: "/_next/static/:path*",
        headers: [
          {
            key: "Cache-Control",
            value: "public, max-age=31536000, immutable",
          },
        ],
      },
    ];
  },
};

module.exports = nextConfig;
```

#### ç»„ä»¶æ‡’åŠ è½½ä¼˜åŒ–

```typescript
// components/LazyComponents.tsx
import dynamic from 'next/dynamic';
import { Suspense } from 'react';
import { Skeleton } from '@/components/ui/skeleton';

// æ‡’åŠ è½½é‡å‹ç»„ä»¶
export const WorkflowVisualization = dynamic(
  () => import('./workflow/WorkflowVisualization'),
  {
    loading: () => <Skeleton className="h-96 w-full" />,
    ssr: false, // å®¢æˆ·ç«¯æ¸²æŸ“
  }
);

export const IterationMonitor = dynamic(
  () => import('./workflow/IterationMonitor'),
  {
    loading: () => <Skeleton className="h-64 w-full" />,
    ssr: false,
  }
);

export const AIAnalysisChart = dynamic(
  () => import('./analytics/AIAnalysisChart'),
  {
    loading: () => <div className="animate-pulse bg-gray-200 h-48 rounded" />,
    ssr: false,
  }
);

// è·¯ç”±çº§åˆ«æ‡’åŠ è½½
export const TeacherDashboard = dynamic(
  () => import('../app/(teacher)/dashboard/page'),
  {
    loading: () => (
      <div className="space-y-4">
        <Skeleton className="h-8 w-64" />
        <Skeleton className="h-32 w-full" />
        <Skeleton className="h-48 w-full" />
      </div>
    ),
  }
);
```

### 2. çŠ¶æ€ç®¡ç†ä¼˜åŒ–

#### Zustandæ€§èƒ½ä¼˜åŒ–

```typescript
// lib/stores/optimized-store.ts
import { create } from 'zustand';
import { subscribeWithSelector } from 'zustand/middleware';
import { immer } from 'zustand/middleware/immer';
import { persist } from 'zustand/middleware';

// åˆ†ç‰‡çŠ¶æ€ç®¡ç†
interface CourseSlice {
  courses: Course[];
  selectedCourse: Course | null;
  loading: boolean;

  // ä¼˜åŒ–çš„actions
  setCourses: (courses: Course[]) => void;
  selectCourse: (courseId: string) => void;
  updateCourse: (courseId: string, updates: Partial<Course>) => void;
}

interface UserSlice {
  user: User | null;
  preferences: UserPreferences;

  setUser: (user: User) => void;
  updatePreferences: (preferences: Partial<UserPreferences>) => void;
}

// åˆ›å»ºä¼˜åŒ–çš„store
export const useAppStore = create<CourseSlice & UserSlice>()()
  subscribeWithSelector(
    immer(
      persist(
        (set, get) => ({
          // Course slice
          courses: [],
          selectedCourse: null,
          loading: false,

          setCourses: (courses) => {
            set((state) => {
              state.courses = courses;
              state.loading = false;
            });
          },

          selectCourse: (courseId) => {
            set((state) => {
              state.selectedCourse = state.courses.find(
                (course) => course.id === courseId
              ) || null;
            });
          },

          updateCourse: (courseId, updates) => {
            set((state) => {
              const courseIndex = state.courses.findIndex(
                (course) => course.id === courseId
              );
              if (courseIndex !== -1) {
                Object.assign(state.courses[courseIndex], updates);
              }

              // æ›´æ–°é€‰ä¸­è¯¾ç¨‹
              if (state.selectedCourse?.id === courseId) {
                Object.assign(state.selectedCourse, updates);
              }
            });
          },

          // User slice
          user: null,
          preferences: {
            theme: 'light',
            language: 'zh-CN',
            notifications: true,
          },

          setUser: (user) => {
            set((state) => {
              state.user = user;
            });
          },

          updatePreferences: (preferences) => {
            set((state) => {
              Object.assign(state.preferences, preferences);
            });
          },
        }),
        {
          name: 'app-store',
          partialize: (state) => ({
            user: state.user,
            preferences: state.preferences,
          }),
        }
      )
    )
  )
);

// é€‰æ‹©å™¨ä¼˜åŒ–
export const useCourses = () => useAppStore((state) => state.courses);
export const useSelectedCourse = () => useAppStore((state) => state.selectedCourse);
export const useUser = () => useAppStore((state) => state.user);

// è®¡ç®—å±æ€§é€‰æ‹©å™¨
export const useCoursesStats = () =>
  useAppStore((state) => ({
    totalCourses: state.courses.length,
    activeCourses: state.courses.filter(c => c.status === 'active').length,
    completedCourses: state.courses.filter(c => c.status === 'completed').length,
  }));
```

---

## ğŸ¤– AIæœåŠ¡æ€§èƒ½ä¼˜åŒ–

### 1. å¼‚æ­¥å¤„ç†ä¼˜åŒ–

#### AIä»»åŠ¡é˜Ÿåˆ—ç®¡ç†

```python
# ai_services/task_manager.py
import asyncio
from typing import List, Dict, Any
from celery import group, chain, chord
from .tasks import (
    analyze_syllabus_task,
    generate_questions_task,
    evaluate_answers_task
)

class AITaskManager:
    """AIä»»åŠ¡ç®¡ç†å™¨"""

    def __init__(self):
        self.max_concurrent_tasks = 10
        self.task_timeout = 300  # 5åˆ†é’Ÿ

    async def process_batch_analysis(self, analysis_requests: List[Dict[str, Any]]):
        """æ‰¹é‡AIåˆ†æå¤„ç†"""
        # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…APIé™åˆ¶
        batch_size = 5
        batches = [
            analysis_requests[i:i + batch_size]
            for i in range(0, len(analysis_requests), batch_size)
        ]

        results = []
        for batch in batches:
            # å¹¶è¡Œå¤„ç†æ‰¹æ¬¡å†…ä»»åŠ¡
            batch_tasks = group(
                analyze_syllabus_task.s(request)
                for request in batch
            )

            # æ‰§è¡Œå¹¶ç­‰å¾…ç»“æœ
            batch_result = batch_tasks.apply_async()
            batch_results = batch_result.get(timeout=self.task_timeout)

            results.extend(batch_results)

            # æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œé¿å…APIé™åˆ¶
            await asyncio.sleep(1)

        return results

    def create_teaching_workflow(self, course_data: Dict[str, Any]):
        """åˆ›å»ºæ•™å­¦å·¥ä½œæµ"""
        # ä½¿ç”¨Celeryé“¾å¼ä»»åŠ¡
        workflow = chain(
            # ç¬¬ä¸€æ­¥ï¼šåˆ†æè€ƒçº²
            analyze_syllabus_task.s(course_data['syllabus']),

            # ç¬¬äºŒæ­¥ï¼šç”Ÿæˆæ•™å­¦è®¡åˆ’
            generate_teaching_plan_task.s(course_data),

            # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆç»ƒä¹ é¢˜
            generate_questions_task.s(),

            # ç¬¬å››æ­¥ï¼šåˆ›å»ºè¯„ä¼°æ ‡å‡†
            create_evaluation_criteria_task.s()
        )

        return workflow.apply_async()

    def parallel_question_generation(self, topics: List[str], count_per_topic: int):
        """å¹¶è¡Œé¢˜ç›®ç”Ÿæˆ"""
        # ä½¿ç”¨Celeryç»„åˆä»»åŠ¡
        job = group(
            generate_questions_task.s(topic, count_per_topic)
            for topic in topics
        )

        return job.apply_async()
```

### 2. APIè°ƒç”¨ä¼˜åŒ–

#### è¿æ¥æ± å’Œé‡è¯•æœºåˆ¶

```python
# ai_services/optimized_client.py
import aiohttp
import asyncio
from typing import Optional, Dict, Any
from dataclasses import dataclass
from contextlib import asynccontextmanager

@dataclass
class APIConfig:
    base_url: str
    api_key: str
    timeout: int = 30
    max_retries: int = 3
    retry_delay: float = 1.0
    max_concurrent: int = 10

class OptimizedDeepSeekClient:
    """ä¼˜åŒ–çš„DeepSeek APIå®¢æˆ·ç«¯"""

    def __init__(self, config: APIConfig):
        self.config = config
        self.session: Optional[aiohttp.ClientSession] = None
        self.semaphore = asyncio.Semaphore(config.max_concurrent)

    @asynccontextmanager
    async def get_session(self):
        """è·å–HTTPä¼šè¯"""
        if self.session is None or self.session.closed:
            connector = aiohttp.TCPConnector(
                limit=50,  # æ€»è¿æ¥æ± å¤§å°
                limit_per_host=20,  # æ¯ä¸ªä¸»æœºçš„è¿æ¥æ•°
                ttl_dns_cache=300,  # DNSç¼“å­˜æ—¶é—´
                use_dns_cache=True,
                keepalive_timeout=30,
                enable_cleanup_closed=True
            )

            timeout = aiohttp.ClientTimeout(
                total=self.config.timeout,
                connect=10,
                sock_read=20
            )

            self.session = aiohttp.ClientSession(
                connector=connector,
                timeout=timeout,
                headers={
                    'Authorization': f'Bearer {self.config.api_key}',
                    'Content-Type': 'application/json',
                    'User-Agent': 'EducationSystem/1.0'
                }
            )

        yield self.session

    async def chat_completion_with_retry(
        self,
        messages: List[Dict[str, str]],
        model: str = 'deepseek-chat',
        **kwargs
    ) -> Dict[str, Any]:
        """å¸¦é‡è¯•çš„èŠå¤©å®Œæˆ"""
        async with self.semaphore:  # é™åˆ¶å¹¶å‘
            for attempt in range(self.config.max_retries + 1):
                try:
                    async with self.get_session() as session:
                        payload = {
                            'model': model,
                            'messages': messages,
                            'stream': False,
                            **kwargs
                        }

                        async with session.post(
                            f'{self.config.base_url}/chat/completions',
                            json=payload
                        ) as response:
                            if response.status == 200:
                                return await response.json()
                            elif response.status == 429:  # é€Ÿç‡é™åˆ¶
                                if attempt < self.config.max_retries:
                                    wait_time = self.config.retry_delay * (2 ** attempt)
                                    await asyncio.sleep(wait_time)
                                    continue
                            else:
                                response.raise_for_status()

                except aiohttp.ClientError as e:
                    if attempt < self.config.max_retries:
                        await asyncio.sleep(self.config.retry_delay)
                        continue
                    raise e

            raise Exception(f'Max retries ({self.config.max_retries}) exceeded')

    async def batch_completion(
        self,
        requests: List[Dict[str, Any]],
        batch_size: int = 5
    ) -> List[Dict[str, Any]]:
        """æ‰¹é‡å¤„ç†è¯·æ±‚"""
        results = []

        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(requests), batch_size):
            batch = requests[i:i + batch_size]

            # å¹¶è¡Œå¤„ç†æ‰¹æ¬¡
            tasks = [
                self.chat_completion_with_retry(**request)
                for request in batch
            ]

            batch_results = await asyncio.gather(*tasks, return_exceptions=True)
            results.extend(batch_results)

            # æ‰¹æ¬¡é—´å»¶è¿Ÿ
            if i + batch_size < len(requests):
                await asyncio.sleep(0.5)

        return results

    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        if self.session and not self.session.closed:
            await self.session.close()
```

---

## ğŸ“Š ç›‘æ§å’Œåº¦é‡

### 1. æ€§èƒ½ç›‘æ§æŒ‡æ ‡

```python
# monitoring/performance_metrics.py
from dataclasses import dataclass
from typing import Dict, List
from django.core.cache import cache
from django.db import connection
import time
import psutil

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""
    timestamp: float
    response_time: float
    cpu_usage: float
    memory_usage: float
    db_queries: int
    cache_hit_rate: float
    active_users: int

class PerformanceCollector:
    """æ€§èƒ½æ•°æ®æ”¶é›†å™¨"""

    def __init__(self):
        self.metrics_history: List[PerformanceMetrics] = []
        self.max_history = 1000

    def collect_current_metrics(self) -> PerformanceMetrics:
        """æ”¶é›†å½“å‰æ€§èƒ½æŒ‡æ ‡"""
        return PerformanceMetrics(
            timestamp=time.time(),
            response_time=self._get_avg_response_time(),
            cpu_usage=psutil.cpu_percent(),
            memory_usage=psutil.virtual_memory().percent,
            db_queries=len(connection.queries),
            cache_hit_rate=self._get_cache_hit_rate(),
            active_users=self._get_active_users()
        )

    def _get_avg_response_time(self) -> float:
        """è·å–å¹³å‡å“åº”æ—¶é—´"""
        cache_key = 'avg_response_time_5min'
        return cache.get(cache_key, 0.0)

    def _get_cache_hit_rate(self) -> float:
        """è·å–ç¼“å­˜å‘½ä¸­ç‡"""
        hits = cache.get('cache_hits', 0)
        misses = cache.get('cache_misses', 0)
        total = hits + misses
        return (hits / total * 100) if total > 0 else 0.0

    def _get_active_users(self) -> int:
        """è·å–æ´»è·ƒç”¨æˆ·æ•°"""
        return cache.get('active_users_count', 0)

    def add_metrics(self, metrics: PerformanceMetrics):
        """æ·»åŠ æ€§èƒ½æŒ‡æ ‡"""
        self.metrics_history.append(metrics)

        # ä¿æŒå†å²è®°å½•å¤§å°
        if len(self.metrics_history) > self.max_history:
            self.metrics_history = self.metrics_history[-self.max_history:]

    def get_performance_summary(self, minutes: int = 30) -> Dict[str, float]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        cutoff_time = time.time() - (minutes * 60)
        recent_metrics = [
            m for m in self.metrics_history
            if m.timestamp >= cutoff_time
        ]

        if not recent_metrics:
            return {}

        return {
            'avg_response_time': sum(m.response_time for m in recent_metrics) / len(recent_metrics),
            'max_response_time': max(m.response_time for m in recent_metrics),
            'avg_cpu_usage': sum(m.cpu_usage for m in recent_metrics) / len(recent_metrics),
            'avg_memory_usage': sum(m.memory_usage for m in recent_metrics) / len(recent_metrics),
            'avg_cache_hit_rate': sum(m.cache_hit_rate for m in recent_metrics) / len(recent_metrics),
            'peak_active_users': max(m.active_users for m in recent_metrics),
        }
```

### 2. æ€§èƒ½å‘Šè­¦ç³»ç»Ÿ

```python
# monitoring/alerts.py
from typing import List, Dict, Any
from dataclasses import dataclass
from enum import Enum
import logging

class AlertLevel(Enum):
    INFO = 'info'
    WARNING = 'warning'
    ERROR = 'error'
    CRITICAL = 'critical'

@dataclass
class Alert:
    level: AlertLevel
    message: str
    metric_name: str
    current_value: float
    threshold: float
    timestamp: float

class PerformanceAlertManager:
    """æ€§èƒ½å‘Šè­¦ç®¡ç†å™¨"""

    def __init__(self):
        self.thresholds = {
            'response_time': {'warning': 1.0, 'critical': 2.0},
            'cpu_usage': {'warning': 70.0, 'critical': 85.0},
            'memory_usage': {'warning': 75.0, 'critical': 90.0},
            'cache_hit_rate': {'warning': 80.0, 'critical': 70.0},  # ä½äºé˜ˆå€¼å‘Šè­¦
            'db_query_time': {'warning': 0.5, 'critical': 1.0},
        }

        self.logger = logging.getLogger('performance_alerts')

    def check_metrics(self, metrics: PerformanceMetrics) -> List[Alert]:
        """æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡å¹¶ç”Ÿæˆå‘Šè­¦"""
        alerts = []

        # å“åº”æ—¶é—´æ£€æŸ¥
        if metrics.response_time > self.thresholds['response_time']['critical']:
            alerts.append(Alert(
                level=AlertLevel.CRITICAL,
                message=f'Response time is critically high: {metrics.response_time:.2f}s',
                metric_name='response_time',
                current_value=metrics.response_time,
                threshold=self.thresholds['response_time']['critical'],
                timestamp=metrics.timestamp
            ))
        elif metrics.response_time > self.thresholds['response_time']['warning']:
            alerts.append(Alert(
                level=AlertLevel.WARNING,
                message=f'Response time is high: {metrics.response_time:.2f}s',
                metric_name='response_time',
                current_value=metrics.response_time,
                threshold=self.thresholds['response_time']['warning'],
                timestamp=metrics.timestamp
            ))

        # CPUä½¿ç”¨ç‡æ£€æŸ¥
        if metrics.cpu_usage > self.thresholds['cpu_usage']['critical']:
            alerts.append(Alert(
                level=AlertLevel.CRITICAL,
                message=f'CPU usage is critically high: {metrics.cpu_usage:.1f}%',
                metric_name='cpu_usage',
                current_value=metrics.cpu_usage,
                threshold=self.thresholds['cpu_usage']['critical'],
                timestamp=metrics.timestamp
            ))

        # å†…å­˜ä½¿ç”¨ç‡æ£€æŸ¥
        if metrics.memory_usage > self.thresholds['memory_usage']['critical']:
            alerts.append(Alert(
                level=AlertLevel.CRITICAL,
                message=f'Memory usage is critically high: {metrics.memory_usage:.1f}%',
                metric_name='memory_usage',
                current_value=metrics.memory_usage,
                threshold=self.thresholds['memory_usage']['critical'],
                timestamp=metrics.timestamp
            ))

        # ç¼“å­˜å‘½ä¸­ç‡æ£€æŸ¥ï¼ˆä½äºé˜ˆå€¼å‘Šè­¦ï¼‰
        if metrics.cache_hit_rate < self.thresholds['cache_hit_rate']['critical']:
            alerts.append(Alert(
                level=AlertLevel.WARNING,
                message=f'Cache hit rate is low: {metrics.cache_hit_rate:.1f}%',
                metric_name='cache_hit_rate',
                current_value=metrics.cache_hit_rate,
                threshold=self.thresholds['cache_hit_rate']['critical'],
                timestamp=metrics.timestamp
            ))

        return alerts

    def process_alerts(self, alerts: List[Alert]):
        """å¤„ç†å‘Šè­¦"""
        for alert in alerts:
            # è®°å½•æ—¥å¿—
            if alert.level == AlertLevel.CRITICAL:
                self.logger.critical(alert.message)
            elif alert.level == AlertLevel.WARNING:
                self.logger.warning(alert.message)

            # å‘é€é€šçŸ¥
            self._send_notification(alert)

    def _send_notification(self, alert: Alert):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        # å®ç°é‚®ä»¶ã€çŸ­ä¿¡ã€Slackç­‰é€šçŸ¥
        pass
```

---

## ğŸ¯ å®æ–½è®¡åˆ’å’ŒéªŒæ”¶æ ‡å‡†

### å®æ–½æ—¶é—´è¡¨

| é˜¶æ®µ      | ä»»åŠ¡           | æ—¶é—´ | è´Ÿè´£äºº   |
| --------- | -------------- | ---- | -------- |
| **ç¬¬1å‘¨** | æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ– | 5å¤©  | åç«¯å›¢é˜Ÿ |
| **ç¬¬2å‘¨** | ç¼“å­˜ç­–ç•¥å®æ–½   | 5å¤©  | åç«¯å›¢é˜Ÿ |
| **ç¬¬3å‘¨** | å‰ç«¯æ€§èƒ½ä¼˜åŒ–   | 5å¤©  | å‰ç«¯å›¢é˜Ÿ |
| **ç¬¬4å‘¨** | AIæœåŠ¡ä¼˜åŒ–     | 5å¤©  | AIå›¢é˜Ÿ   |
| **ç¬¬5å‘¨** | ç›‘æ§ç³»ç»Ÿå®Œå–„   | 5å¤©  | è¿ç»´å›¢é˜Ÿ |
| **ç¬¬6å‘¨** | æ€§èƒ½æµ‹è¯•éªŒè¯   | 5å¤©  | æµ‹è¯•å›¢é˜Ÿ |

### éªŒæ”¶æ ‡å‡†

#### æ€§èƒ½æŒ‡æ ‡

- [ ] APIå¹³å‡å“åº”æ—¶é—´ < 500ms
- [ ] é¡µé¢é¦–æ¬¡åŠ è½½æ—¶é—´ < 2ç§’
- [ ] æ•°æ®åº“æŸ¥è¯¢å¹³å‡æ—¶é—´ < 100ms
- [ ] ç¼“å­˜å‘½ä¸­ç‡ > 85%
- [ ] å¹¶å‘ç”¨æˆ·æ”¯æŒ > 500äºº

#### ç¨³å®šæ€§æŒ‡æ ‡

- [ ] ç³»ç»Ÿå¯ç”¨æ€§ > 99.5%
- [ ] é”™è¯¯ç‡ < 0.1%
- [ ] å†…å­˜ä½¿ç”¨ç‡ < 60%
- [ ] CPUä½¿ç”¨ç‡ < 70%

#### ç”¨æˆ·ä½“éªŒæŒ‡æ ‡

- [ ] é¡µé¢äº¤äº’å“åº”æ—¶é—´ < 200ms
- [ ] AIåˆ†æå“åº”æ—¶é—´ < 5ç§’
- [ ] æ–‡ä»¶ä¸Šä¼ æˆåŠŸç‡ > 99%
- [ ] æœç´¢å“åº”æ—¶é—´ < 1ç§’

---

**æ–‡æ¡£ç»´æŠ¤**: æœ¬æ–¹æ¡ˆå°†æ ¹æ®å®æ–½è¿›å±•å’Œæ€§èƒ½æµ‹è¯•ç»“æœæŒç»­æ›´æ–°ä¼˜åŒ–ã€‚
