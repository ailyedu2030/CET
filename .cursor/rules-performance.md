# æ€§èƒ½ä¼˜åŒ–å’Œç¼“å­˜ç­–ç•¥è§„èŒƒ

## âš¡ å®æ—¶å“åº”æ€§èƒ½è¦æ±‚

### å…³é”®æ€§èƒ½æŒ‡æ ‡

- **API å“åº”æ—¶é—´**ï¼šP95 < 800msï¼ŒP99 < 2s
- **æ•°æ®åº“æŸ¥è¯¢**ï¼šå•æ¬¡æŸ¥è¯¢ < 100msï¼Œå¤æ‚æŸ¥è¯¢ < 500ms
- **AI æœåŠ¡è°ƒç”¨**ï¼šæ‰¹æ”¹ < 3sï¼Œè¾…åŠ©åŠŸèƒ½ < 1sï¼Œé¢˜ç›®ç”Ÿæˆ < 2s
- **å‰ç«¯æ¸²æŸ“**ï¼šé¦–å±åŠ è½½ < 2sï¼Œé¡µé¢åˆ‡æ¢ < 500ms
- **å¹¶å‘æ”¯æŒ**ï¼š1000+å­¦ç”Ÿå¹¶å‘ï¼Œ500+æ•™å¸ˆå¹¶å‘

### æµå¼å¤„ç†æ€§èƒ½

- **æµå¼æ‰¹æ”¹**ï¼šé¦–å­—èŠ‚æ—¶é—´ < 500msï¼Œæµå¼é—´éš” < 200ms
- **å®æ—¶é€šä¿¡**ï¼šWebSocket æ¶ˆæ¯å»¶è¿Ÿ < 100ms
- **è¿›åº¦æ›´æ–°**ï¼šå­¦ä¹ è¿›åº¦å®æ—¶æ›´æ–°ï¼Œå»¶è¿Ÿ < 200ms
- **çŠ¶æ€åŒæ­¥**ï¼šè·¨æ¨¡å—çŠ¶æ€åŒæ­¥ < 500ms

## ğŸ—„ï¸ å¤šå±‚ç¼“å­˜ç­–ç•¥

### L1 æœ¬åœ°ç¼“å­˜ï¼ˆåº”ç”¨å±‚ï¼‰

- **ç¼“å­˜å†…å®¹**ï¼šçƒ­ç‚¹ API å“åº”ã€è®¡ç®—ç»“æœã€é…ç½®ä¿¡æ¯
- **ç¼“å­˜æ—¶é—´**ï¼š5-30 åˆ†é’Ÿï¼Œæ ¹æ®æ•°æ®æ›´æ–°é¢‘ç‡è°ƒæ•´
- **å‘½ä¸­ç‡ç›®æ ‡**ï¼š> 60%
- **å®ç°æ–¹å¼**ï¼šFastAPI-Cache è£…é¥°å™¨ã€å†…å­˜ç¼“å­˜

```python
# æœ¬åœ°ç¼“å­˜ç¤ºä¾‹
from functools import lru_cache
from fastapi_cache import cache

@cache(expire=300)  # 5åˆ†é’Ÿç¼“å­˜
async def get_user_profile(user_id: int):
    return await db.get_user(user_id)

@lru_cache(maxsize=1000)
def calculate_score(answers: tuple):
    # è®¡ç®—å¯†é›†å‹æ“ä½œç¼“å­˜
    return complex_calculation(answers)
```

### L2 Redis ç¼“å­˜ï¼ˆåˆ†å¸ƒå¼ï¼‰

- **ç¼“å­˜å†…å®¹**ï¼šç”¨æˆ·ä¼šè¯ã€API å“åº”ã€å‘é‡æ£€ç´¢ç»“æœã€AI æœåŠ¡ç»“æœ
- **ç¼“å­˜æ—¶é—´**ï¼š1 å°æ—¶-24 å°æ—¶ï¼Œæ ¹æ®ä¸šåŠ¡éœ€æ±‚
- **å‘½ä¸­ç‡ç›®æ ‡**ï¼š> 30%
- **é›†ç¾¤é…ç½®**ï¼šä¸»ä»æ¶æ„ï¼Œè¯»å†™åˆ†ç¦»

```python
# Redisç¼“å­˜é…ç½®
REDIS_CACHE_CONFIG = {
    "user_sessions": {"ttl": 7200, "prefix": "session:"},
    "ai_responses": {"ttl": 3600, "prefix": "ai:"},
    "vector_search": {"ttl": 1800, "prefix": "vector:"},
    "api_responses": {"ttl": 600, "prefix": "api:"}
}
```

### L3 æ•°æ®åº“ä¼˜åŒ–

- **ç´¢å¼•ä¼˜åŒ–**ï¼šä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µå»ºç«‹å¤åˆç´¢å¼•
- **æŸ¥è¯¢ä¼˜åŒ–**ï¼šä½¿ç”¨ SQLAlchemy æŸ¥è¯¢ä¼˜åŒ–ï¼Œé¿å… N+1 é—®é¢˜
- **è¿æ¥æ± **ï¼šPostgreSQL æœ€å° 10ï¼Œæœ€å¤§ 100 è¿æ¥
- **è¯»å†™åˆ†ç¦»**ï¼šè¯»æ“ä½œåˆ†æµ 70%åˆ°ä»åº“

## ğŸš€ å¼‚æ­¥å¤„ç†æ¶æ„

### å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—

- **Celery é…ç½®**ï¼šRedis ä½œä¸ºæ¶ˆæ¯é˜Ÿåˆ—å’Œç»“æœå­˜å‚¨
- **ä»»åŠ¡åˆ†ç±»**ï¼š
  - å®æ—¶ä»»åŠ¡ï¼ˆ<1sï¼‰ï¼šç”¨æˆ·è®¤è¯ã€ç®€å•æŸ¥è¯¢
  - å¿«é€Ÿä»»åŠ¡ï¼ˆ1-5sï¼‰ï¼šAI æ‰¹æ”¹ã€æ•°æ®åˆ†æ
  - æ…¢ä»»åŠ¡ï¼ˆ>5sï¼‰ï¼šæŠ¥å‘Šç”Ÿæˆã€æ‰¹é‡å¤„ç†
- **ä¼˜å…ˆçº§é˜Ÿåˆ—**ï¼šurgent > high > normal > low

```python
# Celeryä»»åŠ¡é…ç½®
from celery import Celery

app = Celery('cet4_learning')
app.conf.update(
    task_routes={
        'ai.tasks.grade_essay': {'queue': 'ai_fast'},
        'analytics.tasks.generate_report': {'queue': 'slow'},
        'notifications.tasks.send_email': {'queue': 'normal'},
    },
    task_annotations={
        'ai.tasks.grade_essay': {'rate_limit': '100/m'},
        'analytics.tasks.generate_report': {'rate_limit': '10/m'},
    }
)
```

### æ‰¹é‡å¤„ç†ä¼˜åŒ–

- **æ‰¹é‡å¤§å°**ï¼šAI è¯·æ±‚æ‰¹é‡ 10-50 ä¸ªï¼Œæ•°æ®åº“æ‰¹é‡ 100-1000 æ¡
- **æ‰¹é‡é—´éš”**ï¼šé«˜é¢‘æ“ä½œ 100msï¼Œä½é¢‘æ“ä½œ 1s
- **å¤„ç†æ•ˆç‡**ï¼šæ‰¹é‡å¤„ç†æ•ˆç‡æå‡>300%
- **é”™è¯¯å¤„ç†**ï¼šéƒ¨åˆ†å¤±è´¥ä¸å½±å“æ•´ä½“å¤„ç†

## ğŸ“Š é¢„è®¡ç®—å’Œé¢„åŠ è½½

### é¢„è®¡ç®—æœºåˆ¶

- **è¦†ç›–èŒƒå›´**ï¼š80%å¸¸ç”¨æŸ¥è¯¢ç»“æœæå‰è®¡ç®—
- **è®¡ç®—æ—¶æœº**ï¼šå¤œé—´æ‰¹é‡é¢„è®¡ç®—ï¼ˆå‡Œæ™¨ 2-6 ç‚¹ï¼‰
- **æ›´æ–°ç­–ç•¥**ï¼šå¢é‡æ›´æ–°ï¼Œé¿å…å…¨é‡é‡ç®—
- **å­˜å‚¨æ–¹å¼**ï¼šRedis å­˜å‚¨é¢„è®¡ç®—ç»“æœ

```python
# é¢„è®¡ç®—ä»»åŠ¡ç¤ºä¾‹
@app.task
def precompute_student_analytics():
    """é¢„è®¡ç®—å­¦ç”Ÿåˆ†ææ•°æ®"""
    students = get_active_students()
    for student in students:
        analytics_data = calculate_student_analytics(student.id)
        cache.set(f"analytics:{student.id}", analytics_data, ttl=86400)
```

### æ™ºèƒ½é¢„åŠ è½½

- **ç”¨æˆ·è¡Œä¸ºé¢„æµ‹**ï¼šåŸºäºå†å²è¡Œä¸ºé¢„åŠ è½½å¯èƒ½è®¿é—®çš„å†…å®¹
- **èµ„æºé¢„åŠ è½½**ï¼šå‰ç«¯èµ„æºæ‡’åŠ è½½å’Œé¢„åŠ è½½
- **æ•°æ®é¢„çƒ­**ï¼šç³»ç»Ÿå¯åŠ¨æ—¶é¢„çƒ­çƒ­ç‚¹æ•°æ®
- **CDN é…ç½®**ï¼šé™æ€èµ„æº CDN ç¼“å­˜ï¼Œå‘½ä¸­ç‡>90%

## ğŸ”§ æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–

### ç´¢å¼•ç­–ç•¥

```sql
-- ç”¨æˆ·æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_users_email_status ON users(email, status);
CREATE INDEX idx_users_created_at ON users(created_at DESC);

-- å­¦ä¹ è®°å½•ä¼˜åŒ–
CREATE INDEX idx_training_records_user_date ON training_records(user_id, created_at DESC);
CREATE INDEX idx_training_records_course ON training_records(course_id, status);

-- AIæœåŠ¡è°ƒç”¨ä¼˜åŒ–
CREATE INDEX idx_ai_calls_user_type ON ai_service_calls(user_id, call_type, created_at DESC);
```

### æŸ¥è¯¢ä¼˜åŒ–è§„èŒƒ

- **é¿å… SELECT \***ï¼šæ˜ç¡®æŒ‡å®šéœ€è¦çš„å­—æ®µ
- **ä½¿ç”¨ LIMIT**ï¼šåˆ†é¡µæŸ¥è¯¢å¿…é¡»ä½¿ç”¨ LIMIT
- **JOIN ä¼˜åŒ–**ï¼šé¿å…è¿‡å¤šè¡¨ JOINï¼Œè€ƒè™‘æ•°æ®å†—ä½™
- **å­æŸ¥è¯¢ä¼˜åŒ–**ï¼šå¤æ‚å­æŸ¥è¯¢æ”¹å†™ä¸º JOIN

```python
# SQLAlchemyæŸ¥è¯¢ä¼˜åŒ–ç¤ºä¾‹
# âŒ é”™è¯¯æ–¹å¼
users = session.query(User).all()
for user in users:
    profile = session.query(UserProfile).filter_by(user_id=user.id).first()

# âœ… æ­£ç¡®æ–¹å¼
users_with_profiles = session.query(User).options(
    joinedload(User.profile)
).filter(User.status == 'active').limit(100).all()
```

## ğŸŒ å‰ç«¯æ€§èƒ½ä¼˜åŒ–

### ä»£ç åˆ†å‰²å’Œæ‡’åŠ è½½

```typescript
// è·¯ç”±çº§åˆ«ä»£ç åˆ†å‰²
const LoginPage = lazy(() => import('@/pages/Auth/LoginPage'))
const Dashboard = lazy(() => import('@/pages/Dashboard/Dashboard'))

// ç»„ä»¶çº§åˆ«æ‡’åŠ è½½
const HeavyComponent = lazy(() => import('@/components/HeavyComponent'))

// åŠ¨æ€å¯¼å…¥
const loadAnalytics = () => import('@/utils/analytics')
```

### çŠ¶æ€ç®¡ç†ä¼˜åŒ–

```typescript
// ZustandçŠ¶æ€åˆ†ç‰‡
interface AppState {
  user: UserState
  courses: CoursesState
  training: TrainingState
}

// é¿å…ä¸å¿…è¦çš„é‡æ¸²æŸ“
const useUserStore = create<UserState>(set => ({
  user: null,
  setUser: user => set({ user }),
}))

// ä½¿ç”¨selectorä¼˜åŒ–
const userName = useUserStore(state => state.user?.name)
```

### ç½‘ç»œè¯·æ±‚ä¼˜åŒ–

```typescript
// TanStack Queryé…ç½®
const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      staleTime: 5 * 60 * 1000, // 5åˆ†é’Ÿ
      cacheTime: 10 * 60 * 1000, // 10åˆ†é’Ÿ
      retry: 1,
      refetchOnWindowFocus: false,
    },
  },
})

// è¯·æ±‚å»é‡å’Œç¼“å­˜
const useUserProfile = (userId: string) => {
  return useQuery({
    queryKey: ['user', userId],
    queryFn: () => fetchUserProfile(userId),
    enabled: !!userId,
  })
}
```

## ğŸ“ˆ æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–

### å…³é”®æŒ‡æ ‡ç›‘æ§

- **å“åº”æ—¶é—´**ï¼šAPI å“åº”æ—¶é—´åˆ†å¸ƒå’Œè¶‹åŠ¿
- **ååé‡**ï¼šæ¯ç§’è¯·æ±‚æ•°(RPS)å’Œå¹¶å‘ç”¨æˆ·æ•°
- **é”™è¯¯ç‡**ï¼šHTTP é”™è¯¯ç‡å’Œä¸šåŠ¡é”™è¯¯ç‡
- **èµ„æºä½¿ç”¨**ï¼šCPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œä½¿ç”¨ç‡

### æ€§èƒ½åˆ†æå·¥å…·

```python
# æ€§èƒ½åˆ†æè£…é¥°å™¨
import time
from functools import wraps

def performance_monitor(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            return result
        finally:
            duration = time.time() - start_time
            logger.info(f"{func.__name__} took {duration:.3f}s")
    return wrapper

# æ•°æ®åº“æŸ¥è¯¢ç›‘æ§
from sqlalchemy import event
from sqlalchemy.engine import Engine

@event.listens_for(Engine, "before_cursor_execute")
def receive_before_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    context._query_start_time = time.time()

@event.listens_for(Engine, "after_cursor_execute")
def receive_after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    total = time.time() - context._query_start_time
    if total > 0.1:  # è®°å½•æ…¢æŸ¥è¯¢
        logger.warning(f"Slow query: {total:.3f}s - {statement[:100]}")
```

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–æ£€æŸ¥æ¸…å•

### å¼€å‘é˜¶æ®µ

- [ ] API å“åº”æ—¶é—´æ˜¯å¦<800ms
- [ ] æ•°æ®åº“æŸ¥è¯¢æ˜¯å¦æœ‰é€‚å½“ç´¢å¼•
- [ ] æ˜¯å¦ä½¿ç”¨äº†é€‚å½“çš„ç¼“å­˜ç­–ç•¥
- [ ] å¼‚æ­¥ä»»åŠ¡æ˜¯å¦æ­£ç¡®é…ç½®
- [ ] å‰ç«¯æ˜¯å¦å®ç°ä»£ç åˆ†å‰²

### æµ‹è¯•é˜¶æ®µ

- [ ] è´Ÿè½½æµ‹è¯•æ˜¯å¦é€šè¿‡
- [ ] ç¼“å­˜å‘½ä¸­ç‡æ˜¯å¦è¾¾æ ‡
- [ ] å¹¶å‘æµ‹è¯•æ˜¯å¦æ»¡è¶³è¦æ±‚
- [ ] å†…å­˜æ³„æ¼æ£€æŸ¥
- [ ] æ€§èƒ½å›å½’æµ‹è¯•

### ç”Ÿäº§é˜¶æ®µ

- [ ] ç›‘æ§æŒ‡æ ‡æ˜¯å¦é…ç½®
- [ ] å‘Šè­¦é˜ˆå€¼æ˜¯å¦åˆç†
- [ ] æ€§èƒ½åŸºçº¿æ˜¯å¦å»ºç«‹
- [ ] ä¼˜åŒ–è®¡åˆ’æ˜¯å¦åˆ¶å®š
- [ ] æ‰©å®¹ç­–ç•¥æ˜¯å¦å‡†å¤‡
