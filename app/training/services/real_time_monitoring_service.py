"""å®æ—¶æ€§èƒ½ç›‘æ§æœåŠ¡ - ğŸ”¥éœ€æ±‚21ç¬¬ä¸‰é˜¶æ®µæ ¸å¿ƒå®ç°.

å®æ—¶æ•°æ®é‡‡é›†åŠŸèƒ½ï¼š
- ç­”é¢˜é€Ÿåº¦å®æ—¶ç›‘æ§
- æ­£ç¡®ç‡å®æ—¶è®¡ç®—
- å­¦ä¹ è¿›åº¦å®æ—¶è·Ÿè¸ª
- å…³é”®æŒ‡æ ‡å®æ—¶é‡‡é›†
- æ€§èƒ½æ•°æ®å®æ—¶ç¼“å­˜
"""

import json
import logging
from datetime import datetime, timedelta
from typing import Any, TypedDict

import redis.asyncio as redis
from sqlalchemy import and_, desc, func, select
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.config import settings
from app.shared.models.enums import DifficultyLevel
from app.training.models.training_models import (
    TrainingRecord,
    TrainingSession,
)

logger = logging.getLogger(__name__)


class AlertThresholds(TypedDict):
    """é¢„è­¦é˜ˆå€¼é…ç½®ç±»å‹."""

    accuracy_drop: float
    speed_drop: float
    consecutive_errors: int
    session_timeout: int


class MetricsRetention(TypedDict):
    """æŒ‡æ ‡ä¿ç•™é…ç½®ç±»å‹."""

    real_time: int
    hourly: int
    daily: int


class MonitoringConfig(TypedDict):
    """å®æ—¶ç›‘æ§é…ç½®ç±»å‹."""

    data_collection_interval: int
    cache_ttl: int
    performance_window: int
    alert_thresholds: AlertThresholds
    metrics_retention: MetricsRetention


class RealTimeMonitoringService:
    """å®æ—¶æ€§èƒ½ç›‘æ§æœåŠ¡ - è®­ç»ƒè¿‡ç¨‹å®æ—¶æ•°æ®é‡‡é›†å’Œç›‘æ§."""

    def __init__(self, db: AsyncSession) -> None:
        self.db = db
        self.redis_client: redis.Redis | None = None

        # å®æ—¶ç›‘æ§é…ç½®
        self.monitoring_config: MonitoringConfig = {
            "data_collection_interval": 1,  # 1ç§’é‡‡é›†é—´éš”
            "cache_ttl": 300,  # 5åˆ†é’Ÿç¼“å­˜TTL
            "performance_window": 60,  # 60ç§’æ€§èƒ½çª—å£
            "alert_thresholds": {
                "accuracy_drop": 0.2,  # æ­£ç¡®ç‡ä¸‹é™20%è§¦å‘é¢„è­¦
                "speed_drop": 0.3,  # ç­”é¢˜é€Ÿåº¦ä¸‹é™30%è§¦å‘é¢„è­¦
                "consecutive_errors": 5,  # è¿ç»­5æ¬¡é”™è¯¯è§¦å‘é¢„è­¦
                "session_timeout": 1800,  # 30åˆ†é’Ÿæ— æ´»åŠ¨è¶…æ—¶
            },
            "metrics_retention": {
                "real_time": 3600,  # å®æ—¶æ•°æ®ä¿ç•™1å°æ—¶
                "hourly": 86400 * 7,  # å°æ—¶æ•°æ®ä¿ç•™7å¤©
                "daily": 86400 * 30,  # æ—¥æ•°æ®ä¿ç•™30å¤©
            },
        }

    async def initialize_redis(self) -> None:
        """åˆå§‹åŒ–Redisè¿æ¥."""
        try:
            self.redis_client = redis.from_url(  # type: ignore[no-untyped-call]
                f"redis://{settings.REDIS_HOST}:{settings.REDIS_PORT}/{settings.REDIS_DB}",
                encoding="utf-8",
                decode_responses=True,
            )
            if self.redis_client:
                await self.redis_client.ping()
            logger.info("Redisè¿æ¥åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"Redisè¿æ¥åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.redis_client = None

    async def start_real_time_monitoring(self, student_id: int, session_id: int) -> dict[str, Any]:
        """å¼€å§‹å®æ—¶ç›‘æ§è®­ç»ƒä¼šè¯."""
        try:
            logger.info(f"å¼€å§‹å®æ—¶ç›‘æ§: å­¦ç”Ÿ{student_id}, ä¼šè¯{session_id}")

            # åˆå§‹åŒ–ç›‘æ§ä¼šè¯
            monitoring_session = await self._initialize_monitoring_session(student_id, session_id)

            # å¯åŠ¨æ•°æ®é‡‡é›†ä»»åŠ¡
            await self._start_data_collection_task(student_id, session_id)

            # åˆå§‹åŒ–æ€§èƒ½åŸºçº¿
            baseline_metrics = await self._establish_performance_baseline(student_id, session_id)

            return {
                "monitoring_started": True,
                "session_id": session_id,
                "student_id": student_id,
                "monitoring_session": monitoring_session,
                "baseline_metrics": baseline_metrics,
                "collection_interval": self.monitoring_config["data_collection_interval"],
                "start_time": datetime.now(),
            }

        except Exception as e:
            logger.error(f"å¯åŠ¨å®æ—¶ç›‘æ§å¤±è´¥: {str(e)}")
            raise RuntimeError(f"å¯åŠ¨å®æ—¶ç›‘æ§å¤±è´¥: {str(e)}") from e

    async def collect_real_time_metrics(self, student_id: int, session_id: int) -> dict[str, Any]:
        """é‡‡é›†å®æ—¶æ€§èƒ½æŒ‡æ ‡."""
        try:
            current_time = datetime.now()

            # è·å–å½“å‰ä¼šè¯ä¿¡æ¯
            session_info = await self._get_session_info(session_id)
            if not session_info:
                return {"error": "ä¼šè¯ä¸å­˜åœ¨"}

            # é‡‡é›†æ ¸å¿ƒæŒ‡æ ‡
            metrics = {
                "timestamp": current_time,
                "session_id": session_id,
                "student_id": student_id,
                # ç­”é¢˜é€Ÿåº¦æŒ‡æ ‡
                "answer_speed": await self._calculate_real_time_answer_speed(
                    student_id, session_id
                ),
                # æ­£ç¡®ç‡æŒ‡æ ‡
                "accuracy_metrics": await self._calculate_real_time_accuracy(
                    student_id, session_id
                ),
                # å­¦ä¹ è¿›åº¦æŒ‡æ ‡
                "progress_metrics": await self._calculate_learning_progress(student_id, session_id),
                # å‚ä¸åº¦æŒ‡æ ‡
                "engagement_metrics": await self._calculate_engagement_metrics(
                    student_id, session_id
                ),
                # éš¾åº¦é€‚åº”æ€§æŒ‡æ ‡
                "difficulty_adaptation": await self._calculate_difficulty_adaptation(
                    student_id, session_id
                ),
            }

            # ç¼“å­˜å®æ—¶æ•°æ®
            await self._cache_real_time_metrics(student_id, session_id, metrics)

            # æ£€æŸ¥é¢„è­¦æ¡ä»¶
            alerts = await self._check_alert_conditions(student_id, session_id, metrics)
            if alerts:
                metrics["alerts"] = alerts

            logger.debug(f"å®æ—¶æŒ‡æ ‡é‡‡é›†å®Œæˆ: å­¦ç”Ÿ{student_id}, ä¼šè¯{session_id}")
            return metrics

        except Exception as e:
            logger.error(f"å®æ—¶æŒ‡æ ‡é‡‡é›†å¤±è´¥: {str(e)}")
            return {"error": str(e), "timestamp": datetime.now()}

    async def _initialize_monitoring_session(
        self, student_id: int, session_id: int
    ) -> dict[str, Any]:
        """åˆå§‹åŒ–ç›‘æ§ä¼šè¯."""
        session_key = f"monitoring:session:{student_id}:{session_id}"

        session_data = {
            "student_id": student_id,
            "session_id": session_id,
            "start_time": datetime.now().isoformat(),
            "status": "active",
            "metrics_collected": 0,
            "alerts_triggered": 0,
        }

        if self.redis_client:
            await self.redis_client.hset(session_key, mapping=session_data)
            await self.redis_client.expire(session_key, self.monitoring_config["cache_ttl"])

        return session_data

    async def _start_data_collection_task(self, student_id: int, session_id: int) -> None:
        """å¯åŠ¨æ•°æ®é‡‡é›†ä»»åŠ¡."""
        # è¿™é‡Œå¯ä»¥å¯åŠ¨åå°ä»»åŠ¡è¿›è¡Œå®šæœŸæ•°æ®é‡‡é›†
        # æš‚æ—¶è®°å½•å¯åŠ¨ä¿¡æ¯
        logger.info(f"æ•°æ®é‡‡é›†ä»»åŠ¡å·²å¯åŠ¨: å­¦ç”Ÿ{student_id}, ä¼šè¯{session_id}")

    async def _establish_performance_baseline(
        self, student_id: int, session_id: int
    ) -> dict[str, Any]:
        """å»ºç«‹æ€§èƒ½åŸºçº¿."""
        try:
            # è·å–å­¦ç”Ÿå†å²è¡¨ç°æ•°æ®
            historical_performance = await self._get_historical_performance(student_id)

            # è®¡ç®—åŸºçº¿æŒ‡æ ‡
            baseline = {
                "average_answer_time": historical_performance.get("avg_answer_time", 60.0),
                "average_accuracy": historical_performance.get("avg_accuracy", 0.7),
                "typical_session_duration": historical_performance.get(
                    "avg_session_duration", 1800
                ),
                "preferred_difficulty": historical_performance.get(
                    "preferred_difficulty", DifficultyLevel.ELEMENTARY
                ),
                "baseline_established_at": datetime.now(),
            }

            # ç¼“å­˜åŸºçº¿æ•°æ®
            if self.redis_client:
                baseline_key = f"baseline:{student_id}"
                await self.redis_client.hset(
                    baseline_key,
                    mapping={k: json.dumps(v, default=str) for k, v in baseline.items()},
                )
                await self.redis_client.expire(baseline_key, 86400)  # 24å°æ—¶

            return baseline

        except Exception as e:
            logger.error(f"å»ºç«‹æ€§èƒ½åŸºçº¿å¤±è´¥: {str(e)}")
            return {}

    async def _get_session_info(self, session_id: int) -> dict[str, Any] | None:
        """è·å–ä¼šè¯ä¿¡æ¯."""
        stmt = select(TrainingSession).where(TrainingSession.id == session_id)
        result = await self.db.execute(stmt)
        session = result.scalar_one_or_none()

        if session:
            return {
                "id": session.id,
                "student_id": session.student_id,
                "session_type": session.session_type,
                "difficulty_level": session.difficulty_level,
                "question_count": session.question_count,
                "created_at": session.created_at,
            }
        return None

    async def _calculate_real_time_answer_speed(
        self, student_id: int, session_id: int
    ) -> dict[str, Any]:
        """è®¡ç®—å®æ—¶ç­”é¢˜é€Ÿåº¦."""
        try:
            # è·å–æœ€è¿‘çš„ç­”é¢˜è®°å½•
            recent_window = datetime.now() - timedelta(
                seconds=self.monitoring_config["performance_window"]
            )

            stmt = (
                select(TrainingRecord)
                .join(TrainingSession, TrainingRecord.session_id == TrainingSession.id)
                .where(
                    and_(
                        TrainingSession.student_id == student_id,
                        TrainingRecord.session_id == session_id,
                        TrainingRecord.created_at >= recent_window,
                    )
                )
                .order_by(desc(TrainingRecord.created_at))
                .limit(10)
            )

            result = await self.db.execute(stmt)
            recent_records = result.scalars().all()

            if not recent_records:
                return {"average_time": 0, "trend": "no_data", "sample_size": 0}

            # è®¡ç®—å¹³å‡ç­”é¢˜æ—¶é—´
            times = [record.time_spent for record in recent_records if record.time_spent]
            if not times:
                return {"average_time": 0, "trend": "no_data", "sample_size": 0}

            avg_time = sum(times) / len(times)

            # åˆ†æè¶‹åŠ¿
            if len(times) >= 5:
                recent_half = times[: len(times) // 2]
                earlier_half = times[len(times) // 2 :]

                recent_avg = sum(recent_half) / len(recent_half)
                earlier_avg = sum(earlier_half) / len(earlier_half)

                if recent_avg < earlier_avg * 0.9:
                    trend = "accelerating"
                elif recent_avg > earlier_avg * 1.1:
                    trend = "decelerating"
                else:
                    trend = "stable"
            else:
                trend = "insufficient_data"

            return {
                "average_time": avg_time,
                "trend": trend,
                "sample_size": len(times),
                "min_time": min(times),
                "max_time": max(times),
                "last_answer_time": times[0] if times else 0,
            }

        except Exception as e:
            logger.error(f"è®¡ç®—å®æ—¶ç­”é¢˜é€Ÿåº¦å¤±è´¥: {str(e)}")
            return {"error": str(e)}

    async def _calculate_real_time_accuracy(
        self, student_id: int, session_id: int
    ) -> dict[str, Any]:
        """è®¡ç®—å®æ—¶æ­£ç¡®ç‡."""
        try:
            # è·å–å½“å‰ä¼šè¯çš„æ‰€æœ‰ç­”é¢˜è®°å½•
            stmt = (
                select(TrainingRecord)
                .where(TrainingRecord.session_id == session_id)
                .order_by(desc(TrainingRecord.created_at))
            )

            result = await self.db.execute(stmt)
            all_records = result.scalars().all()

            if not all_records:
                return {"current_accuracy": 0, "trend": "no_data", "total_attempts": 0}

            # è®¡ç®—æ€»ä½“æ­£ç¡®ç‡
            correct_count = sum(1 for record in all_records if record.is_correct)
            total_count = len(all_records)
            current_accuracy = correct_count / total_count

            # è®¡ç®—æœ€è¿‘10é¢˜çš„æ­£ç¡®ç‡
            recent_10 = all_records[:10]
            recent_correct = sum(1 for record in recent_10 if record.is_correct)
            recent_accuracy = recent_correct / len(recent_10) if recent_10 else 0

            # åˆ†æè¶‹åŠ¿
            if len(all_records) >= 20:
                first_half = all_records[10:20]
                first_half_accuracy = sum(1 for r in first_half if r.is_correct) / len(first_half)

                if recent_accuracy > first_half_accuracy + 0.1:
                    trend = "improving"
                elif recent_accuracy < first_half_accuracy - 0.1:
                    trend = "declining"
                else:
                    trend = "stable"
            else:
                trend = "insufficient_data"

            # è¿ç»­é”™è¯¯æ£€æŸ¥
            consecutive_errors = 0
            for record in all_records:
                if not record.is_correct:
                    consecutive_errors += 1
                else:
                    break

            return {
                "current_accuracy": current_accuracy,
                "recent_10_accuracy": recent_accuracy,
                "trend": trend,
                "total_attempts": total_count,
                "correct_attempts": correct_count,
                "consecutive_errors": consecutive_errors,
                "accuracy_change": (
                    recent_accuracy - (current_accuracy - recent_accuracy)
                    if len(all_records) >= 20
                    else 0
                ),
            }

        except Exception as e:
            logger.error(f"è®¡ç®—å®æ—¶æ­£ç¡®ç‡å¤±è´¥: {str(e)}")
            return {"error": str(e)}

    async def _calculate_learning_progress(
        self, student_id: int, session_id: int
    ) -> dict[str, Any]:
        """è®¡ç®—å­¦ä¹ è¿›åº¦."""
        try:
            # è·å–ä¼šè¯ä¿¡æ¯
            session_info = await self._get_session_info(session_id)
            if not session_info:
                return {"error": "ä¼šè¯ä¸å­˜åœ¨"}

            # è®¡ç®—å®Œæˆè¿›åº¦
            stmt = select(func.count(TrainingRecord.id)).where(
                TrainingRecord.session_id == session_id
            )
            result = await self.db.execute(stmt)
            completed_questions = result.scalar() or 0

            target_questions = session_info["question_count"]
            completion_rate = completed_questions / target_questions if target_questions > 0 else 0

            # è®¡ç®—æ—¶é—´è¿›åº¦
            session_start = session_info["created_at"]
            elapsed_time = (datetime.now() - session_start).total_seconds()

            # ä¼°ç®—å‰©ä½™æ—¶é—´
            if completed_questions > 0:
                avg_time_per_question = elapsed_time / completed_questions
                estimated_remaining_time = (
                    target_questions - completed_questions
                ) * avg_time_per_question
            else:
                estimated_remaining_time = 0

            return {
                "completion_rate": completion_rate,
                "completed_questions": completed_questions,
                "target_questions": target_questions,
                "remaining_questions": target_questions - completed_questions,
                "elapsed_time": elapsed_time,
                "estimated_remaining_time": estimated_remaining_time,
                "estimated_total_time": elapsed_time + estimated_remaining_time,
                "pace": (
                    "ahead"
                    if completion_rate > elapsed_time / 1800
                    else ("behind" if completion_rate < elapsed_time / 2400 else "on_track")
                ),
            }

        except Exception as e:
            logger.error(f"è®¡ç®—å­¦ä¹ è¿›åº¦å¤±è´¥: {str(e)}")
            return {"error": str(e)}

    async def _calculate_engagement_metrics(
        self, student_id: int, session_id: int
    ) -> dict[str, Any]:
        """è®¡ç®—å‚ä¸åº¦æŒ‡æ ‡."""
        try:
            # è·å–æœ€è¿‘çš„æ´»åŠ¨è®°å½•
            recent_window = datetime.now() - timedelta(minutes=10)

            stmt = (
                select(TrainingRecord)
                .where(
                    and_(
                        TrainingRecord.session_id == session_id,
                        TrainingRecord.created_at >= recent_window,
                    )
                )
                .order_by(desc(TrainingRecord.created_at))
            )

            result = await self.db.execute(stmt)
            recent_records = result.scalars().all()

            if not recent_records:
                return {
                    "engagement_level": "low",
                    "activity_score": 0,
                    "last_activity": None,
                }

            # è®¡ç®—æ´»åŠ¨é¢‘ç‡
            activity_count = len(recent_records)
            time_span = (datetime.now() - recent_records[-1].created_at).total_seconds()
            activity_rate = activity_count / max(time_span / 60, 1)  # æ¯åˆ†é’Ÿæ´»åŠ¨æ¬¡æ•°

            # è®¡ç®—å‚ä¸åº¦åˆ†æ•°
            if activity_rate >= 2:
                engagement_level = "high"
                activity_score = min(1.0, activity_rate / 3)
            elif activity_rate >= 1:
                engagement_level = "medium"
                activity_score = activity_rate / 2
            else:
                engagement_level = "low"
                activity_score = activity_rate

            # æ£€æŸ¥è¿ç»­æ´»åŠ¨æ—¶é—´
            last_activity = recent_records[0].created_at if recent_records else None
            time_since_last = (
                (datetime.now() - last_activity).total_seconds() if last_activity else float("inf")
            )

            return {
                "engagement_level": engagement_level,
                "activity_score": activity_score,
                "activity_rate": activity_rate,
                "recent_activity_count": activity_count,
                "last_activity": last_activity,
                "time_since_last_activity": time_since_last,
                "is_active": time_since_last < 300,  # 5åˆ†é’Ÿå†…æœ‰æ´»åŠ¨
            }

        except Exception as e:
            logger.error(f"è®¡ç®—å‚ä¸åº¦æŒ‡æ ‡å¤±è´¥: {str(e)}")
            return {"error": str(e)}

    async def _calculate_difficulty_adaptation(
        self, student_id: int, session_id: int
    ) -> dict[str, Any]:
        """è®¡ç®—éš¾åº¦é€‚åº”æ€§æŒ‡æ ‡."""
        try:
            # è·å–å½“å‰ä¼šè¯çš„éš¾åº¦ç­‰çº§
            session_info = await self._get_session_info(session_id)
            if not session_info:
                return {"error": "ä¼šè¯ä¸å­˜åœ¨"}

            current_difficulty = session_info["difficulty_level"]

            # è·å–å½“å‰éš¾åº¦ä¸‹çš„è¡¨ç°
            stmt = (
                select(TrainingRecord)
                .join(TrainingSession, TrainingRecord.session_id == TrainingSession.id)
                .where(
                    and_(
                        TrainingSession.student_id == student_id,
                        TrainingSession.difficulty_level == current_difficulty,
                        TrainingRecord.created_at >= datetime.now() - timedelta(hours=1),
                    )
                )
                .order_by(desc(TrainingRecord.created_at))
                .limit(20)
            )

            result = await self.db.execute(stmt)
            difficulty_records = result.scalars().all()

            if not difficulty_records:
                return {"adaptation_status": "unknown", "difficulty_match": 0.5}

            # è®¡ç®—å½“å‰éš¾åº¦ä¸‹çš„è¡¨ç°
            correct_count = sum(1 for record in difficulty_records if record.is_correct)
            accuracy = correct_count / len(difficulty_records)

            avg_time = sum(
                record.time_spent for record in difficulty_records if record.time_spent
            ) / len(difficulty_records)

            # è¯„ä¼°éš¾åº¦é€‚åº”æ€§
            if accuracy >= 0.85 and avg_time <= 90:
                adaptation_status = "too_easy"
                difficulty_match = 0.3
                suggestion = "increase_difficulty"
            elif accuracy <= 0.6 or avg_time >= 180:
                adaptation_status = "too_hard"
                difficulty_match = 0.3
                suggestion = "decrease_difficulty"
            else:
                adaptation_status = "appropriate"
                difficulty_match = 0.8 + (0.2 * (1 - abs(accuracy - 0.75) / 0.25))
                suggestion = "maintain_difficulty"

            return {
                "adaptation_status": adaptation_status,
                "difficulty_match": difficulty_match,
                "current_difficulty": current_difficulty.name,
                "accuracy_at_difficulty": accuracy,
                "avg_time_at_difficulty": avg_time,
                "suggestion": suggestion,
                "sample_size": len(difficulty_records),
            }

        except Exception as e:
            logger.error(f"è®¡ç®—éš¾åº¦é€‚åº”æ€§å¤±è´¥: {str(e)}")
            return {"error": str(e)}

    async def _cache_real_time_metrics(
        self, student_id: int, session_id: int, metrics: dict[str, Any]
    ) -> None:
        """ç¼“å­˜å®æ—¶æŒ‡æ ‡æ•°æ®."""
        if not self.redis_client:
            return

        try:
            # ç¼“å­˜å½“å‰æŒ‡æ ‡
            current_key = f"metrics:current:{student_id}:{session_id}"
            await self.redis_client.set(
                current_key,
                json.dumps(metrics, default=str),
                ex=self.monitoring_config["cache_ttl"],
            )

            # æ·»åŠ åˆ°æ—¶é—´åºåˆ—
            timestamp = int(datetime.now().timestamp())
            timeseries_key = f"metrics:timeseries:{student_id}:{session_id}"

            await self.redis_client.zadd(
                timeseries_key, {json.dumps(metrics, default=str): timestamp}
            )

            # æ¸…ç†è¿‡æœŸæ•°æ®
            cutoff = timestamp - self.monitoring_config["metrics_retention"]["real_time"]
            await self.redis_client.zremrangebyscore(timeseries_key, 0, cutoff)

        except Exception as e:
            logger.error(f"ç¼“å­˜å®æ—¶æŒ‡æ ‡å¤±è´¥: {str(e)}")

    async def _check_alert_conditions(
        self, student_id: int, session_id: int, metrics: dict[str, Any]
    ) -> list[dict[str, Any]]:
        """æ£€æŸ¥é¢„è­¦æ¡ä»¶."""
        alerts = []
        thresholds = self.monitoring_config["alert_thresholds"]

        try:
            # æ£€æŸ¥æ­£ç¡®ç‡ä¸‹é™
            accuracy_metrics = metrics.get("accuracy_metrics", {})
            if accuracy_metrics.get("accuracy_change", 0) < -thresholds["accuracy_drop"]:
                alerts.append(
                    {
                        "type": "accuracy_drop",
                        "severity": "warning",
                        "message": f"æ­£ç¡®ç‡ä¸‹é™è¶…è¿‡{thresholds['accuracy_drop']:.0%}",
                        "current_value": accuracy_metrics.get("current_accuracy", 0),
                        "threshold": thresholds["accuracy_drop"],
                        "timestamp": datetime.now(),
                    }
                )

            # æ£€æŸ¥è¿ç»­é”™è¯¯
            consecutive_errors = accuracy_metrics.get("consecutive_errors", 0)
            if consecutive_errors >= thresholds["consecutive_errors"]:
                alerts.append(
                    {
                        "type": "consecutive_errors",
                        "severity": "critical",
                        "message": f"è¿ç»­{consecutive_errors}æ¬¡ç­”é”™",
                        "current_value": consecutive_errors,
                        "threshold": thresholds["consecutive_errors"],
                        "timestamp": datetime.now(),
                    }
                )

            # æ£€æŸ¥ç­”é¢˜é€Ÿåº¦ä¸‹é™
            speed_metrics = metrics.get("answer_speed", {})
            if speed_metrics.get("trend") == "decelerating":
                alerts.append(
                    {
                        "type": "speed_decline",
                        "severity": "info",
                        "message": "ç­”é¢˜é€Ÿåº¦æ˜æ˜¾ä¸‹é™",
                        "current_value": speed_metrics.get("average_time", 0),
                        "timestamp": datetime.now(),
                    }
                )

            # æ£€æŸ¥å‚ä¸åº¦ä¸‹é™
            engagement_metrics = metrics.get("engagement_metrics", {})
            if engagement_metrics.get("engagement_level") == "low":
                alerts.append(
                    {
                        "type": "low_engagement",
                        "severity": "warning",
                        "message": "å­¦ä¹ å‚ä¸åº¦è¾ƒä½",
                        "current_value": engagement_metrics.get("activity_score", 0),
                        "timestamp": datetime.now(),
                    }
                )

            # ç¼“å­˜é¢„è­¦ä¿¡æ¯
            if alerts:
                await self._cache_alerts(student_id, session_id, alerts)

            return alerts

        except Exception as e:
            logger.error(f"æ£€æŸ¥é¢„è­¦æ¡ä»¶å¤±è´¥: {str(e)}")
            return []

    async def _cache_alerts(
        self, student_id: int, session_id: int, alerts: list[dict[str, Any]]
    ) -> None:
        """ç¼“å­˜é¢„è­¦ä¿¡æ¯."""
        if not self.redis_client:
            return

        try:
            alerts_key = f"alerts:{student_id}:{session_id}"
            timestamp = int(datetime.now().timestamp())

            for alert in alerts:
                await self.redis_client.zadd(
                    alerts_key, {json.dumps(alert, default=str): timestamp}
                )

            # è®¾ç½®è¿‡æœŸæ—¶é—´
            await self.redis_client.expire(alerts_key, 86400)  # 24å°æ—¶

        except Exception as e:
            logger.error(f"ç¼“å­˜é¢„è­¦ä¿¡æ¯å¤±è´¥: {str(e)}")

    async def _get_historical_performance(self, student_id: int) -> dict[str, Any]:
        """è·å–å­¦ç”Ÿå†å²è¡¨ç°æ•°æ®."""
        try:
            # è·å–æœ€è¿‘30å¤©çš„è®­ç»ƒè®°å½•
            cutoff_date = datetime.now() - timedelta(days=30)

            stmt = (
                select(TrainingRecord, TrainingSession)
                .join(TrainingSession, TrainingRecord.session_id == TrainingSession.id)
                .where(
                    and_(
                        TrainingSession.student_id == student_id,
                        TrainingRecord.created_at >= cutoff_date,
                    )
                )
                .order_by(desc(TrainingRecord.created_at))
                .limit(200)
            )

            result = await self.db.execute(stmt)
            records = result.all()

            if not records:
                return {}

            # è®¡ç®—å†å²æŒ‡æ ‡
            training_records = [record[0] for record in records]
            sessions = [record[1] for record in records]

            # å¹³å‡ç­”é¢˜æ—¶é—´
            times = [r.time_spent for r in training_records if r.time_spent]
            avg_answer_time = sum(times) / len(times) if times else 60.0

            # å¹³å‡æ­£ç¡®ç‡
            correct_count = sum(1 for r in training_records if r.is_correct)
            avg_accuracy = correct_count / len(training_records)

            # å¹³å‡ä¼šè¯æ—¶é•¿
            session_durations = []
            for session in set(sessions):
                session_records = [r for r in training_records if r.session_id == session.id]
                if session_records:
                    duration = (
                        max(r.created_at for r in session_records)
                        - min(r.created_at for r in session_records)
                    ).total_seconds()
                    session_durations.append(duration)

            avg_session_duration = (
                sum(session_durations) / len(session_durations) if session_durations else 1800
            )

            # åå¥½éš¾åº¦
            difficulty_counts: dict[DifficultyLevel, int] = {}
            for session in sessions:
                difficulty = session.difficulty_level
                difficulty_counts[difficulty] = difficulty_counts.get(difficulty, 0) + 1

            preferred_difficulty = (
                max(difficulty_counts.keys(), key=lambda x: difficulty_counts[x])
                if difficulty_counts
                else DifficultyLevel.ELEMENTARY
            )

            return {
                "avg_answer_time": avg_answer_time,
                "avg_accuracy": avg_accuracy,
                "avg_session_duration": avg_session_duration,
                "preferred_difficulty": preferred_difficulty,
                "total_records": len(training_records),
                "analysis_period_days": 30,
            }

        except Exception as e:
            logger.error(f"è·å–å†å²è¡¨ç°æ•°æ®å¤±è´¥: {str(e)}")
            return {}

    async def stop_real_time_monitoring(self, student_id: int, session_id: int) -> dict[str, Any]:
        """åœæ­¢å®æ—¶ç›‘æ§."""
        try:
            logger.info(f"åœæ­¢å®æ—¶ç›‘æ§: å­¦ç”Ÿ{student_id}, ä¼šè¯{session_id}")

            # è·å–æœ€ç»ˆæŒ‡æ ‡
            final_metrics = await self.collect_real_time_metrics(student_id, session_id)

            # æ›´æ–°ç›‘æ§ä¼šè¯çŠ¶æ€
            if self.redis_client:
                session_key = f"monitoring:session:{student_id}:{session_id}"
                await self.redis_client.hset(session_key, "status", "completed")
                await self.redis_client.hset(session_key, "end_time", datetime.now().isoformat())

            return {
                "monitoring_stopped": True,
                "session_id": session_id,
                "student_id": student_id,
                "final_metrics": final_metrics,
                "stop_time": datetime.now(),
            }

        except Exception as e:
            logger.error(f"åœæ­¢å®æ—¶ç›‘æ§å¤±è´¥: {str(e)}")
            raise RuntimeError(f"åœæ­¢å®æ—¶ç›‘æ§å¤±è´¥: {str(e)}") from e

    async def get_cached_metrics(self, student_id: int, session_id: int) -> dict[str, Any] | None:
        """è·å–ç¼“å­˜çš„å®æ—¶æŒ‡æ ‡."""
        if not self.redis_client:
            return None

        try:
            current_key = f"metrics:current:{student_id}:{session_id}"
            cached_data = await self.redis_client.get(current_key)

            if cached_data:
                return json.loads(cached_data)  # type: ignore[no-any-return]
            return None

        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜æŒ‡æ ‡å¤±è´¥: {str(e)}")
            return None
