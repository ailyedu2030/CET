"""æ™ºèƒ½è®­ç»ƒé—­ç¯æœåŠ¡ - ğŸ”¥éœ€æ±‚21æ ¸å¿ƒå®ç°.

å®ç°å®Œæ•´çš„æ•°æ®é‡‡é›†â†’AIåˆ†æâ†’ç­–ç•¥è°ƒæ•´â†’æ•ˆæœéªŒè¯é—­ç¯æµç¨‹ã€‚
"""

import json
import logging
from datetime import datetime, timedelta
from typing import Any

from sqlalchemy import and_, desc, select
from sqlalchemy.ext.asyncio import AsyncSession

from app.ai.services.deepseek_service import DeepSeekService
from app.shared.models.enums import TrainingType
from app.training.models.training_models import (
    Question,
    TrainingRecord,
    TrainingSession,
)
from app.training.services.adaptive_service import AdaptiveLearningService
from app.training.services.analytics_service import AnalyticsService
from app.training.services.intelligent_training_loop_helpers import (
    IntelligentTrainingLoopHelpers,
)

logger = logging.getLogger(__name__)


class IntelligentTrainingLoopService:
    """æ™ºèƒ½è®­ç»ƒé—­ç¯æœåŠ¡ - ç³»ç»Ÿæ ¸å¿ƒ."""

    def __init__(self, db: AsyncSession) -> None:
        """åˆå§‹åŒ–æ™ºèƒ½è®­ç»ƒé—­ç¯æœåŠ¡."""
        self.db = db
        self.deepseek_service = DeepSeekService()
        self.adaptive_service = AdaptiveLearningService(db)
        self.analytics_service = AnalyticsService(db)
        self.helpers = IntelligentTrainingLoopHelpers(db)

        # é—­ç¯é…ç½®å‚æ•°
        self.loop_config = {
            "data_collection": {
                "min_records_for_analysis": 10,  # æœ€å°‘è®°å½•æ•°
                "analysis_window_days": 7,  # åˆ†æçª—å£
                "real_time_threshold_minutes": 5,  # å®æ—¶é˜ˆå€¼
            },
            "ai_analysis": {
                "accuracy_threshold": 0.9,  # AIåˆ†æå‡†ç¡®ç‡é˜ˆå€¼>90%
                "confidence_threshold": 0.85,  # ç½®ä¿¡åº¦é˜ˆå€¼
                "analysis_depth": "comprehensive",  # åˆ†ææ·±åº¦
            },
            "strategy_adjustment": {
                "adjustment_sensitivity": 0.1,  # è°ƒæ•´æ•æ„Ÿåº¦
                "max_adjustment_per_cycle": 2,  # æ¯å‘¨æœŸæœ€å¤§è°ƒæ•´å¹…åº¦
                "stability_period_hours": 24,  # ç¨³å®šæœŸ
            },
            "effect_verification": {
                "verification_period_days": 7,  # 7å¤©æ•ˆæœéªŒè¯å‘¨æœŸ
                "improvement_threshold": 0.05,  # æ”¹è¿›é˜ˆå€¼
                "success_criteria": 0.8,  # æˆåŠŸæ ‡å‡†
            },
        }

    # ==================== æ™ºèƒ½è®­ç»ƒé—­ç¯ä¸»æµç¨‹ ====================

    async def execute_training_loop(
        self, student_id: int, training_type: TrainingType
    ) -> dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„æ™ºèƒ½è®­ç»ƒé—­ç¯æµç¨‹."""
        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œæ™ºèƒ½è®­ç»ƒé—­ç¯: å­¦ç”Ÿ{student_id}, è®­ç»ƒç±»å‹{training_type}")

            # ç¬¬ä¸€æ­¥ï¼šæ•°æ®é‡‡é›†
            collected_data = await self._data_collection_phase(student_id, training_type)

            # ç¬¬äºŒæ­¥ï¼šAIåˆ†æ
            analysis_result = await self._ai_analysis_phase(collected_data)

            # ç¬¬ä¸‰æ­¥ï¼šç­–ç•¥è°ƒæ•´
            adjustment_result = await self._strategy_adjustment_phase(
                student_id, training_type, analysis_result
            )

            # ç¬¬å››æ­¥ï¼šæ•ˆæœéªŒè¯
            verification_result = await self._effect_verification_phase(
                student_id, training_type, adjustment_result
            )

            # æ„å»ºé—­ç¯ç»“æœ
            loop_result = {
                "student_id": student_id,
                "training_type": training_type.value,
                "execution_time": datetime.now(),
                "phases": {
                    "data_collection": collected_data,
                    "ai_analysis": analysis_result,
                    "strategy_adjustment": adjustment_result,
                    "effect_verification": verification_result,
                },
                "loop_success": self._evaluate_loop_success(
                    analysis_result, adjustment_result, verification_result
                ),
                "next_execution_time": datetime.now()
                + timedelta(
                    days=self.loop_config["effect_verification"]["verification_period_days"]  # type: ignore
                ),
            }

            # è®°å½•é—­ç¯æ‰§è¡Œç»“æœ
            await self._record_loop_execution(loop_result)

            logger.info(
                f"æ™ºèƒ½è®­ç»ƒé—­ç¯æ‰§è¡Œå®Œæˆ: å­¦ç”Ÿ{student_id}, æˆåŠŸ={loop_result['loop_success']}"
            )
            return loop_result

        except Exception as e:
            logger.error(f"æ™ºèƒ½è®­ç»ƒé—­ç¯æ‰§è¡Œå¤±è´¥: å­¦ç”Ÿ{student_id}, é”™è¯¯: {str(e)}")
            raise

    # ==================== ç¬¬ä¸€æ­¥ï¼šæ•°æ®é‡‡é›†é˜¶æ®µ ====================

    async def _data_collection_phase(
        self, student_id: int, training_type: TrainingType
    ) -> dict[str, Any]:
        """æ•°æ®é‡‡é›†é˜¶æ®µ - å®æ—¶è®°å½•å­¦ç”Ÿç­”é¢˜æ•°æ®."""
        try:
            collection_config = self.loop_config["data_collection"]
            analysis_window = timedelta(days=collection_config["analysis_window_days"])  # type: ignore
            cutoff_date = datetime.now() - analysis_window

            # æ”¶é›†è®­ç»ƒè®°å½•
            training_records = await self._collect_training_records(
                student_id, training_type, cutoff_date
            )

            # æ”¶é›†å­¦ä¹ è·¯å¾„æ•°æ®
            learning_path_data = await self._collect_learning_path_data(
                student_id, training_type, cutoff_date
            )

            # æ”¶é›†ç­”é¢˜è¡Œä¸ºæ•°æ®
            behavior_data = await self._collect_behavior_data(
                student_id, training_type, cutoff_date
            )

            # æ•°æ®è´¨é‡æ£€æŸ¥
            data_quality = await self._assess_data_quality(
                training_records, learning_path_data, behavior_data
            )

            collected_data = {
                "collection_time": datetime.now(),
                "data_window_days": collection_config["analysis_window_days"],  # type: ignore
                "training_records": training_records,
                "learning_path_data": learning_path_data,
                "behavior_data": behavior_data,
                "data_quality": data_quality,
                "total_records": len(training_records),
                "collection_success": data_quality["overall_quality"] >= 0.8,
            }

            logger.info(
                f"æ•°æ®é‡‡é›†å®Œæˆ: å­¦ç”Ÿ{student_id}, è®°å½•æ•°{len(training_records)}, "
                f"è´¨é‡{data_quality['overall_quality']:.2f}"
            )
            return collected_data

        except Exception as e:
            logger.error(f"æ•°æ®é‡‡é›†å¤±è´¥: å­¦ç”Ÿ{student_id}, é”™è¯¯: {str(e)}")
            raise

    async def _collect_training_records(
        self, student_id: int, training_type: TrainingType, cutoff_date: datetime
    ) -> list[dict[str, Any]]:
        """æ”¶é›†è®­ç»ƒè®°å½•æ•°æ®."""
        stmt = (
            select(TrainingRecord, Question)
            .join(Question, TrainingRecord.question_id == Question.id)
            .join(TrainingSession, TrainingRecord.session_id == TrainingSession.id)
            .where(
                and_(
                    TrainingRecord.student_id == student_id,
                    TrainingSession.session_type == training_type,
                    TrainingRecord.created_at >= cutoff_date,
                )
            )
            .order_by(desc(TrainingRecord.created_at))
        )

        result = await self.db.execute(stmt)
        records = result.all()

        training_data = []
        for record, question in records:
            training_data.append(
                {
                    "record_id": record.id,
                    "session_id": record.session_id,
                    "question_id": record.question_id,
                    "is_correct": record.is_correct,
                    "score": record.score,
                    "time_spent": record.time_spent,
                    "difficulty_level": question.difficulty_level.value,
                    "knowledge_points": record.knowledge_points_mastered
                    + record.knowledge_points_weak,
                    "ai_confidence": record.ai_confidence,
                    "created_at": record.created_at,
                }
            )

        return training_data

    async def _collect_learning_path_data(
        self, student_id: int, training_type: TrainingType, cutoff_date: datetime
    ) -> dict[str, Any]:
        """æ”¶é›†å­¦ä¹ è·¯å¾„æ•°æ®."""
        # è·å–å­¦ä¹ ä¼šè¯åºåˆ—
        stmt = (
            select(TrainingSession)
            .where(
                and_(
                    TrainingSession.student_id == student_id,
                    TrainingSession.session_type == training_type,
                    TrainingSession.started_at >= cutoff_date,
                )
            )
            .order_by(TrainingSession.started_at)
        )

        result = await self.db.execute(stmt)
        sessions = list(result.scalars().all())

        learning_path = {
            "session_sequence": [
                {
                    "session_id": session.id,
                    "difficulty_level": session.difficulty_level.value,
                    "question_count": session.question_count,
                    "accuracy_rate": (
                        (session.correct_answers / session.total_questions)
                        if session.total_questions > 0
                        else 0
                    ),
                    "time_spent": session.time_spent,
                    "started_at": session.started_at,
                }
                for session in sessions
            ],
            "difficulty_progression": self._analyze_difficulty_progression(sessions),
            "learning_velocity": self._calculate_learning_velocity(sessions),
        }

        return learning_path

    async def _collect_behavior_data(
        self, student_id: int, training_type: TrainingType, cutoff_date: datetime
    ) -> dict[str, Any]:
        """æ”¶é›†ç­”é¢˜è¡Œä¸ºæ•°æ®."""
        # åˆ†æç­”é¢˜æ¨¡å¼
        stmt = (
            select(TrainingRecord)
            .join(TrainingSession, TrainingRecord.session_id == TrainingSession.id)
            .where(
                and_(
                    TrainingRecord.student_id == student_id,
                    TrainingSession.session_type == training_type,
                    TrainingRecord.created_at >= cutoff_date,
                )
            )
            .order_by(TrainingRecord.created_at)
        )

        result = await self.db.execute(stmt)
        records = list(result.scalars().all())

        behavior_data = {
            "answer_patterns": self._analyze_answer_patterns(records),
            "time_patterns": self._analyze_time_patterns(records),
            "error_patterns": self._analyze_error_patterns(records),
            "engagement_metrics": self._calculate_engagement_metrics(records),
        }

        return behavior_data

    # ==================== ç¬¬äºŒæ­¥ï¼šAIåˆ†æé˜¶æ®µ ====================

    async def _ai_analysis_phase(self, collected_data: dict[str, Any]) -> dict[str, Any]:
        """AIåˆ†æé˜¶æ®µ - æ™ºèƒ½åˆ†æçŸ¥è¯†ç‚¹æŒæ¡åº¦å’Œè–„å¼±ç¯èŠ‚."""
        try:
            analysis_config = self.loop_config["ai_analysis"]

            # æ£€æŸ¥æ•°æ®è´¨é‡
            if not collected_data["collection_success"]:
                return {
                    "analysis_success": False,
                    "error": "æ•°æ®è´¨é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡ŒAIåˆ†æ",
                    "accuracy": 0.0,
                }

            # æ„å»ºAIåˆ†æprompt
            analysis_prompt = await self._build_ai_analysis_prompt(collected_data)

            # è°ƒç”¨DeepSeekè¿›è¡Œåˆ†æ
            success, ai_response, error_msg = await self.deepseek_service.generate_completion(
                prompt=analysis_prompt,
                temperature=0.2,  # ä½æ¸©åº¦ç¡®ä¿åˆ†æå‡†ç¡®æ€§
                max_tokens=2000,
            )

            if not success or not ai_response:
                raise ValueError(f"AIåˆ†æå¤±è´¥: {error_msg}")

            # è§£æAIåˆ†æç»“æœ
            analysis_result = await self._parse_ai_analysis_result(ai_response)

            # éªŒè¯AIåˆ†æå‡†ç¡®ç‡
            accuracy_verification = await self._verify_ai_analysis_accuracy(
                analysis_result, collected_data
            )

            # æ„å»ºåˆ†æç»“æœ
            final_analysis = {
                "analysis_time": datetime.now(),
                "ai_analysis": analysis_result,
                "accuracy_verification": accuracy_verification,
                "analysis_accuracy": accuracy_verification["accuracy_score"],
                "analysis_success": accuracy_verification["accuracy_score"]
                >= analysis_config["accuracy_threshold"],  # type: ignore
                "confidence_score": analysis_result.get("confidence", 0.0),
                "knowledge_mastery": analysis_result.get("knowledge_mastery", {}),
                "weak_areas": analysis_result.get("weak_areas", []),
                "improvement_suggestions": analysis_result.get("improvement_suggestions", []),
            }

            logger.info(
                f"AIåˆ†æå®Œæˆ: å‡†ç¡®ç‡{accuracy_verification['accuracy_score']:.2f}, "
                f"æˆåŠŸ={final_analysis['analysis_success']}"
            )
            return final_analysis

        except Exception as e:
            logger.error(f"AIåˆ†æå¤±è´¥: é”™è¯¯: {str(e)}")
            return {
                "analysis_success": False,
                "error": str(e),
                "accuracy": 0.0,
            }

    async def _build_ai_analysis_prompt(self, collected_data: dict[str, Any]) -> str:
        """æ„å»ºAIåˆ†æprompt."""
        training_records = collected_data["training_records"]
        learning_path = collected_data["learning_path_data"]
        behavior_data = collected_data["behavior_data"]

        # è®¡ç®—åŸºç¡€ç»Ÿè®¡
        total_questions = len(training_records)
        correct_answers = sum(1 for r in training_records if r["is_correct"])
        accuracy_rate = correct_answers / total_questions if total_questions > 0 else 0

        # çŸ¥è¯†ç‚¹ç»Ÿè®¡
        all_knowledge_points = []
        for record in training_records:
            all_knowledge_points.extend(record["knowledge_points"])

        knowledge_stats = {}
        for kp in set(all_knowledge_points):
            kp_records = [r for r in training_records if kp in r["knowledge_points"]]
            kp_correct = sum(1 for r in kp_records if r["is_correct"])
            knowledge_stats[kp] = {
                "total": len(kp_records),
                "correct": kp_correct,
                "accuracy": kp_correct / len(kp_records) if kp_records else 0,
            }

        prompt = f"""
è¯·åˆ†æä»¥ä¸‹å­¦ç”Ÿçš„è‹±è¯­å››çº§è®­ç»ƒæ•°æ®ï¼Œæä¾›å‡†ç¡®çš„å­¦ä¹ åˆ†ææŠ¥å‘Šã€‚

## è®­ç»ƒæ•°æ®æ¦‚è§ˆ
- åˆ†ææ—¶é—´çª—å£: {collected_data["data_window_days"]}å¤©
- æ€»é¢˜ç›®æ•°: {total_questions}
- æ­£ç¡®ç­”æ¡ˆæ•°: {correct_answers}
- æ•´ä½“å‡†ç¡®ç‡: {accuracy_rate:.2%}

## çŸ¥è¯†ç‚¹æŒæ¡æƒ…å†µ
{json.dumps(knowledge_stats, ensure_ascii=False, indent=2)}

## å­¦ä¹ è·¯å¾„åˆ†æ
- éš¾åº¦è¿›å±•: {learning_path.get("difficulty_progression", {})}
- å­¦ä¹ é€Ÿåº¦: {learning_path.get("learning_velocity", {})}

## ç­”é¢˜è¡Œä¸ºåˆ†æ
- ç­”é¢˜æ¨¡å¼: {behavior_data.get("answer_patterns", {})}
- æ—¶é—´æ¨¡å¼: {behavior_data.get("time_patterns", {})}
- é”™è¯¯æ¨¡å¼: {behavior_data.get("error_patterns", {})}

## åˆ†æè¦æ±‚
è¯·åŸºäºä»¥ä¸Šæ•°æ®è¿›è¡Œæ·±åº¦åˆ†æï¼Œè¿”å›JSONæ ¼å¼ç»“æœï¼š

{{
    "knowledge_mastery": {{
        "å¼ºé¡¹çŸ¥è¯†ç‚¹": ["çŸ¥è¯†ç‚¹1", "çŸ¥è¯†ç‚¹2"],
        "æŒæ¡ä¸­çŸ¥è¯†ç‚¹": ["çŸ¥è¯†ç‚¹3", "çŸ¥è¯†ç‚¹4"],
        "è–„å¼±çŸ¥è¯†ç‚¹": ["çŸ¥è¯†ç‚¹5", "çŸ¥è¯†ç‚¹6"]
    }},
    "weak_areas": [
        {{
            "area": "è–„å¼±ç¯èŠ‚åç§°",
            "severity": "high/medium/low",
            "evidence": "æ”¯æ’‘è¯æ®",
            "impact_score": 0.8
        }}
    ],
    "learning_patterns": {{
        "å­¦ä¹ é£æ ¼": "visual/auditory/kinesthetic",
        "å­¦ä¹ åå¥½": "çŸ­æ—¶é«˜é¢‘/é•¿æ—¶ä½é¢‘",
        "æœ€ä½³å­¦ä¹ æ—¶é—´": "morning/afternoon/evening"
    }},
    "improvement_suggestions": [
        {{
            "suggestion": "å…·ä½“å»ºè®®",
            "priority": "high/medium/low",
            "expected_improvement": 0.15,
            "implementation_difficulty": "easy/medium/hard"
        }}
    ],
    "confidence": 0.95,
    "analysis_quality": "high/medium/low"
}}

è¯·ç¡®ä¿åˆ†æçš„å‡†ç¡®æ€§å’Œå®ç”¨æ€§ï¼Œç½®ä¿¡åº¦åº”åŸºäºæ•°æ®è´¨é‡å’Œåˆ†ææ·±åº¦ã€‚
"""
        return prompt

    async def _parse_ai_analysis_result(self, ai_response: dict[str, Any]) -> dict[str, Any]:
        """è§£æAIåˆ†æç»“æœ."""
        try:
            # æå–AIå“åº”å†…å®¹
            content = ai_response.get("choices", [{}])[0].get("message", {}).get("content", "")

            # è§£æJSONç»“æœ
            analysis_data: dict[str, Any] = json.loads(content)

            # éªŒè¯å¿…è¦å­—æ®µ
            required_fields = [
                "knowledge_mastery",
                "weak_areas",
                "improvement_suggestions",
                "confidence",
            ]
            for field in required_fields:
                if field not in analysis_data:
                    analysis_data[field] = {} if field == "knowledge_mastery" else []

            return analysis_data

        except json.JSONDecodeError as e:
            logger.error(f"AIåˆ†æç»“æœè§£æå¤±è´¥: {str(e)}")
            return {
                "knowledge_mastery": {},
                "weak_areas": [],
                "improvement_suggestions": [],
                "confidence": 0.5,
                "parse_error": str(e),
            }

    async def _verify_ai_analysis_accuracy(
        self, analysis_result: dict[str, Any], collected_data: dict[str, Any]
    ) -> dict[str, Any]:
        """éªŒè¯AIåˆ†æå‡†ç¡®ç‡ - ç¡®ä¿>90%å‡†ç¡®ç‡."""
        try:
            training_records = collected_data["training_records"]

            # éªŒè¯çŸ¥è¯†ç‚¹åˆ†æå‡†ç¡®æ€§
            knowledge_accuracy = await self.helpers.verify_knowledge_analysis(
                analysis_result.get("knowledge_mastery", {}), training_records
            )

            # éªŒè¯è–„å¼±ç¯èŠ‚è¯†åˆ«å‡†ç¡®æ€§
            weak_areas_accuracy = await self.helpers.verify_weak_areas_analysis(
                analysis_result.get("weak_areas", []), training_records
            )

            # éªŒè¯æ”¹è¿›å»ºè®®çš„åˆç†æ€§
            suggestions_accuracy = await self.helpers.verify_improvement_suggestions(
                analysis_result.get("improvement_suggestions", []), training_records
            )

            # è®¡ç®—ç»¼åˆå‡†ç¡®ç‡
            overall_accuracy = (
                knowledge_accuracy * 0.4 + weak_areas_accuracy * 0.4 + suggestions_accuracy * 0.2
            )

            verification_result = {
                "accuracy_score": overall_accuracy,
                "knowledge_accuracy": knowledge_accuracy,
                "weak_areas_accuracy": weak_areas_accuracy,
                "suggestions_accuracy": suggestions_accuracy,
                "verification_time": datetime.now(),
                "meets_threshold": overall_accuracy
                >= self.loop_config["ai_analysis"]["accuracy_threshold"],  # type: ignore
            }

            logger.info(f"AIåˆ†æå‡†ç¡®ç‡éªŒè¯: {overall_accuracy:.2f}")
            return verification_result

        except Exception as e:
            logger.error(f"AIåˆ†æå‡†ç¡®ç‡éªŒè¯å¤±è´¥: {str(e)}")
            return {
                "accuracy_score": 0.0,
                "error": str(e),
                "meets_threshold": False,
            }

    # ==================== ç¬¬ä¸‰æ­¥ï¼šç­–ç•¥è°ƒæ•´é˜¶æ®µ ====================

    async def _strategy_adjustment_phase(
        self,
        student_id: int,
        training_type: TrainingType,
        analysis_result: dict[str, Any],
    ) -> dict[str, Any]:
        """ç­–ç•¥è°ƒæ•´é˜¶æ®µ - åŸºäºAIåˆ†æç»“æœè‡ªåŠ¨è°ƒæ•´è®­ç»ƒç­–ç•¥."""
        try:
            # æ£€æŸ¥AIåˆ†ææ˜¯å¦æˆåŠŸ
            if not analysis_result.get("analysis_success", False):
                return {
                    "adjustment_success": False,
                    "error": "AIåˆ†æå¤±è´¥ï¼Œæ— æ³•è¿›è¡Œç­–ç•¥è°ƒæ•´",
                }

            # ç”Ÿæˆè°ƒæ•´ç­–ç•¥
            adjustment_strategy = await self._generate_adjustment_strategy(
                student_id, training_type, analysis_result
            )

            # åº”ç”¨ç­–ç•¥è°ƒæ•´
            applied_adjustments = await self._apply_strategy_adjustments(
                student_id, training_type, adjustment_strategy
            )

            # è®°å½•è°ƒæ•´å†å²
            await self._record_strategy_adjustment(
                student_id, training_type, adjustment_strategy, applied_adjustments
            )

            adjustment_result = {
                "adjustment_time": datetime.now(),
                "adjustment_strategy": adjustment_strategy,
                "applied_adjustments": applied_adjustments,
                "adjustment_success": applied_adjustments["success"],
                "next_verification_time": datetime.now()
                + timedelta(
                    days=self.loop_config["effect_verification"]["verification_period_days"]  # type: ignore
                ),
            }

            logger.info(
                f"ç­–ç•¥è°ƒæ•´å®Œæˆ: å­¦ç”Ÿ{student_id}, æˆåŠŸ={adjustment_result['adjustment_success']}"
            )
            return adjustment_result

        except Exception as e:
            logger.error(f"ç­–ç•¥è°ƒæ•´å¤±è´¥: å­¦ç”Ÿ{student_id}, é”™è¯¯: {str(e)}")
            return {
                "adjustment_success": False,
                "error": str(e),
            }

    async def _generate_adjustment_strategy(
        self,
        student_id: int,
        training_type: TrainingType,
        analysis_result: dict[str, Any],
    ) -> dict[str, Any]:
        """ç”Ÿæˆè°ƒæ•´ç­–ç•¥."""
        weak_areas = analysis_result.get("weak_areas", [])
        knowledge_mastery = analysis_result.get("knowledge_mastery", {})
        improvement_suggestions = analysis_result.get("improvement_suggestions", [])

        # éš¾åº¦è°ƒæ•´ç­–ç•¥
        difficulty_adjustment = await self.helpers.calculate_difficulty_adjustment_strategy(
            student_id, training_type, analysis_result
        )

        # å†…å®¹è°ƒæ•´ç­–ç•¥
        content_adjustment = await self.helpers.calculate_content_adjustment_strategy(
            weak_areas, knowledge_mastery
        )

        # é¢‘ç‡è°ƒæ•´ç­–ç•¥
        frequency_adjustment = await self.helpers.calculate_frequency_adjustment_strategy(
            student_id, training_type, analysis_result
        )

        strategy = {
            "difficulty_adjustment": difficulty_adjustment,
            "content_adjustment": content_adjustment,
            "frequency_adjustment": frequency_adjustment,
            "priority_focus": (weak_areas[:3] if weak_areas else []),  # é‡ç‚¹å…³æ³¨å‰3ä¸ªè–„å¼±ç¯èŠ‚
            "implementation_timeline": "immediate",  # ç«‹å³å®æ–½
            "expected_improvement": (
                sum(s.get("expected_improvement", 0) for s in improvement_suggestions)
                / len(improvement_suggestions)
                if improvement_suggestions
                else 0.1
            ),
        }

        return strategy

    async def _apply_strategy_adjustments(
        self, student_id: int, training_type: TrainingType, strategy: dict[str, Any]
    ) -> dict[str, Any]:
        """åº”ç”¨ç­–ç•¥è°ƒæ•´."""
        try:
            applied_changes: list[dict[str, Any]] = []

            # åº”ç”¨éš¾åº¦è°ƒæ•´
            if strategy["difficulty_adjustment"]["should_adjust"]:
                difficulty_result = await self.adaptive_service.update_adaptive_config(
                    student_id=student_id,
                    training_type=training_type,
                    session_results=strategy["difficulty_adjustment"]["adjustment_data"],
                )
                applied_changes.append(
                    {
                        "type": "difficulty",
                        "result": difficulty_result,
                        "success": difficulty_result is not None,
                    }
                )

            # åº”ç”¨å†…å®¹è°ƒæ•´
            content_result = await self._apply_content_adjustments(
                student_id, training_type, strategy["content_adjustment"]
            )
            applied_changes.append(
                {
                    "type": "content",
                    "result": content_result,
                    "success": content_result.get("success", False),
                }
            )

            # åº”ç”¨é¢‘ç‡è°ƒæ•´
            frequency_result = await self._apply_frequency_adjustments(
                student_id, training_type, strategy["frequency_adjustment"]
            )
            applied_changes.append(
                {
                    "type": "frequency",
                    "result": frequency_result,
                    "success": frequency_result.get("success", False),
                }
            )

            return {
                "success": all(change["success"] for change in applied_changes),
                "applied_changes": applied_changes,
                "total_adjustments": len(applied_changes),
            }

        except Exception as e:
            logger.error(f"åº”ç”¨ç­–ç•¥è°ƒæ•´å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "applied_changes": [],
            }

    # ==================== ç¬¬å››æ­¥ï¼šæ•ˆæœéªŒè¯é˜¶æ®µ ====================

    async def _effect_verification_phase(
        self,
        student_id: int,
        training_type: TrainingType,
        adjustment_result: dict[str, Any],
    ) -> dict[str, Any]:
        """æ•ˆæœéªŒè¯é˜¶æ®µ - 7å¤©è°ƒæ•´æ•ˆæœè¯„ä¼°å‘¨æœŸ."""
        try:
            verification_config = self.loop_config["effect_verification"]

            # æ£€æŸ¥ç­–ç•¥è°ƒæ•´æ˜¯å¦æˆåŠŸ
            if not adjustment_result.get("adjustment_success", False):
                return {
                    "verification_success": False,
                    "error": "ç­–ç•¥è°ƒæ•´å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œæ•ˆæœéªŒè¯",
                }

            # è·å–è°ƒæ•´å‰çš„åŸºçº¿æ•°æ®
            baseline_data = await self.helpers.get_baseline_performance(
                student_id,
                training_type,
                verification_config["verification_period_days"],  # type: ignore
            )

            # è·å–è°ƒæ•´åçš„è¡¨ç°æ•°æ®
            current_data = await self.helpers.get_current_performance(
                student_id,
                training_type,
                days=3,  # è·å–æœ€è¿‘3å¤©çš„æ•°æ®
            )

            # è®¡ç®—æ”¹è¿›æ•ˆæœ
            improvement_analysis = await self.helpers.calculate_improvement_effect(
                baseline_data, current_data, adjustment_result
            )

            # éªŒè¯æ˜¯å¦è¾¾åˆ°æˆåŠŸæ ‡å‡†
            success_verification = await self.helpers.verify_success_criteria(
                improvement_analysis,
                dict(verification_config),  # type: ignore
            )

            verification_result = {
                "verification_time": datetime.now(),
                "baseline_data": baseline_data,
                "current_data": current_data,
                "improvement_analysis": improvement_analysis,
                "success_verification": success_verification,
                "verification_success": success_verification["meets_criteria"],
                "next_loop_recommended": success_verification["next_loop_recommended"],
            }

            logger.info(
                f"æ•ˆæœéªŒè¯å®Œæˆ: å­¦ç”Ÿ{student_id}, æˆåŠŸ={verification_result['verification_success']}"
            )
            return verification_result

        except Exception as e:
            logger.error(f"æ•ˆæœéªŒè¯å¤±è´¥: å­¦ç”Ÿ{student_id}, é”™è¯¯: {str(e)}")
            return {
                "verification_success": False,
                "error": str(e),
            }

    # ==================== è¾…åŠ©æ–¹æ³•å®ç° ====================

    def _evaluate_loop_success(
        self,
        analysis_result: dict[str, Any],
        adjustment_result: dict[str, Any],
        verification_result: dict[str, Any],
    ) -> bool:
        """è¯„ä¼°é—­ç¯æ˜¯å¦æˆåŠŸ."""
        return bool(
            analysis_result.get("analysis_success", False)
            and adjustment_result.get("adjustment_success", False)
            and verification_result.get("verification_success", False)
        )

    async def _record_loop_execution(self, loop_result: dict[str, Any]) -> None:
        """è®°å½•é—­ç¯æ‰§è¡Œç»“æœ."""
        try:
            from app.training.models.training_models import IntelligentTrainingLoop

            loop_record = IntelligentTrainingLoop(
                student_id=loop_result["student_id"],
                training_type=TrainingType(loop_result["training_type"]),
                execution_time=loop_result["execution_time"],
                next_execution_time=loop_result["next_execution_time"],
                data_collection_result=loop_result["phases"]["data_collection"],
                ai_analysis_result=loop_result["phases"]["ai_analysis"],
                strategy_adjustment_result=loop_result["phases"]["strategy_adjustment"],
                effect_verification_result=loop_result["phases"]["effect_verification"],
                loop_success=loop_result["loop_success"],
                ai_analysis_accuracy=loop_result["phases"]["ai_analysis"].get(
                    "analysis_accuracy", 0.0
                ),
                improvement_rate=loop_result["phases"]["effect_verification"]
                .get("improvement_analysis", {})
                .get("improvement_rate", 0.0),
            )

            self.db.add(loop_record)
            await self.db.commit()

        except Exception as e:
            logger.error(f"è®°å½•é—­ç¯æ‰§è¡Œç»“æœå¤±è´¥: {str(e)}")
            await self.db.rollback()

    async def _assess_data_quality(
        self,
        training_records: list[dict[str, Any]],
        learning_path_data: dict[str, Any],
        behavior_data: dict[str, Any],
    ) -> dict[str, Any]:
        """è¯„ä¼°æ•°æ®è´¨é‡."""
        # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        completeness_score = 0.0
        if training_records:
            completeness_score += 0.4
        if learning_path_data.get("session_sequence"):
            completeness_score += 0.3
        if behavior_data.get("answer_patterns"):
            completeness_score += 0.3

        # æ•°æ®é‡æ£€æŸ¥
        volume_score = min(len(training_records) / 50, 1.0)  # 50é¢˜ä¸ºæ»¡åˆ†

        # æ•°æ®æ—¶æ•ˆæ€§æ£€æŸ¥
        if training_records:
            latest_record = max(training_records, key=lambda x: x["created_at"])
            time_diff = datetime.now() - latest_record["created_at"]
            freshness_score = max(0, 1 - time_diff.days / 7)  # 7å¤©å†…ä¸ºæ»¡åˆ†
        else:
            freshness_score = 0.0

        overall_quality = completeness_score * 0.4 + volume_score * 0.4 + freshness_score * 0.2

        return {
            "completeness_score": completeness_score,
            "volume_score": volume_score,
            "freshness_score": freshness_score,
            "overall_quality": overall_quality,
        }

    def _analyze_difficulty_progression(self, sessions: list[TrainingSession]) -> dict[str, Any]:
        """åˆ†æéš¾åº¦è¿›å±•."""
        if not sessions:
            return {"trend": "no_data", "progression_rate": 0.0}

        difficulty_levels = [session.difficulty_level.value for session in sessions]

        # è®¡ç®—éš¾åº¦è¶‹åŠ¿
        if len(difficulty_levels) < 2:
            return {"trend": "insufficient_data", "progression_rate": 0.0}

        # ç®€å•çš„çº¿æ€§è¶‹åŠ¿åˆ†æ
        trend_score = 0
        for i in range(1, len(difficulty_levels)):
            if difficulty_levels[i] > difficulty_levels[i - 1]:
                trend_score += 1
            elif difficulty_levels[i] < difficulty_levels[i - 1]:
                trend_score -= 1

        progression_rate = (
            trend_score / (len(difficulty_levels) - 1) if len(difficulty_levels) > 1 else 0
        )

        return {
            "trend": (
                "increasing"
                if progression_rate > 0.2
                else "decreasing"
                if progression_rate < -0.2
                else "stable"
            ),
            "progression_rate": progression_rate,
            "difficulty_range": [min(difficulty_levels), max(difficulty_levels)],
        }

    def _calculate_learning_velocity(self, sessions: list[TrainingSession]) -> dict[str, Any]:
        """è®¡ç®—å­¦ä¹ é€Ÿåº¦."""
        if not sessions:
            return {"velocity": 0.0, "trend": "no_data"}

        # è®¡ç®—æ¯ä¸ªä¼šè¯çš„æ•ˆç‡
        velocities = []
        for session in sessions:
            if session.time_spent and session.time_spent > 0:
                velocity = session.correct_answers / (session.time_spent / 60)  # æ¯åˆ†é’Ÿæ­£ç¡®ç­”é¢˜æ•°
                velocities.append(velocity)

        if not velocities:
            return {"velocity": 0.0, "trend": "no_data"}

        avg_velocity = sum(velocities) / len(velocities)

        # åˆ†æè¶‹åŠ¿
        if len(velocities) >= 3:
            recent_avg = sum(velocities[-3:]) / 3
            early_avg = sum(velocities[:3]) / 3
            trend = (
                "improving"
                if recent_avg > early_avg * 1.1
                else "declining"
                if recent_avg < early_avg * 0.9
                else "stable"
            )
        else:
            trend = "insufficient_data"

        return {
            "velocity": avg_velocity,
            "trend": trend,
            "velocity_range": [min(velocities), max(velocities)],
        }

    def _analyze_answer_patterns(self, records: list[TrainingRecord]) -> dict[str, Any]:
        """åˆ†æç­”é¢˜æ¨¡å¼."""
        if not records:
            return {"pattern": "no_data"}

        correct_count = sum(1 for r in records if r.is_correct)
        accuracy_rate = correct_count / len(records)

        # åˆ†æè¿ç»­æ­£ç¡®/é”™è¯¯æ¨¡å¼
        max_correct_streak = 0
        max_incorrect_streak = 0
        current_correct_streak = 0
        current_incorrect_streak = 0

        for record in records:
            if record.is_correct:
                current_correct_streak += 1
                current_incorrect_streak = 0
                max_correct_streak = max(max_correct_streak, current_correct_streak)
            else:
                current_incorrect_streak += 1
                current_correct_streak = 0
                max_incorrect_streak = max(max_incorrect_streak, current_incorrect_streak)

        return {
            "accuracy_rate": accuracy_rate,
            "max_correct_streak": max_correct_streak,
            "max_incorrect_streak": max_incorrect_streak,
            "pattern": (
                "consistent"
                if accuracy_rate > 0.8
                else "inconsistent"
                if accuracy_rate < 0.6
                else "moderate"
            ),
        }

    def _analyze_time_patterns(self, records: list[TrainingRecord]) -> dict[str, Any]:
        """åˆ†ææ—¶é—´æ¨¡å¼."""
        if not records:
            return {"pattern": "no_data"}

        time_spent_list = [r.time_spent for r in records if r.time_spent]
        if not time_spent_list:
            return {"pattern": "no_time_data"}

        avg_time = sum(time_spent_list) / len(time_spent_list)

        return {
            "average_time": avg_time,
            "time_range": [min(time_spent_list), max(time_spent_list)],
            "pattern": ("fast" if avg_time < 30 else "slow" if avg_time > 120 else "normal"),
        }

    def _analyze_error_patterns(self, records: list[TrainingRecord]) -> dict[str, Any]:
        """åˆ†æé”™è¯¯æ¨¡å¼."""
        incorrect_records = [r for r in records if not r.is_correct]
        if not incorrect_records:
            return {"pattern": "no_errors"}

        # åˆ†æé”™è¯¯çš„çŸ¥è¯†ç‚¹åˆ†å¸ƒ
        error_knowledge_points = []
        for record in incorrect_records:
            error_knowledge_points.extend(record.knowledge_points_weak)

        from collections import Counter

        error_distribution = Counter(error_knowledge_points)

        return {
            "error_count": len(incorrect_records),
            "error_rate": len(incorrect_records) / len(records),
            "top_error_areas": dict(error_distribution.most_common(5)),
            "pattern": "concentrated" if len(error_distribution) <= 3 else "scattered",
        }

    def _calculate_engagement_metrics(self, records: list[TrainingRecord]) -> dict[str, Any]:
        """è®¡ç®—å‚ä¸åº¦æŒ‡æ ‡."""
        if not records:
            return {"engagement": "no_data"}

        # åŸºäºç­”é¢˜æ—¶é—´å’ŒAIç½®ä¿¡åº¦è®¡ç®—å‚ä¸åº¦
        engagement_scores = []
        for record in records:
            score = 0.5  # åŸºç¡€åˆ†

            # æ—¶é—´å› ç´ 
            if record.time_spent:
                if 30 <= record.time_spent <= 120:  # åˆç†æ—¶é—´èŒƒå›´
                    score += 0.3
                elif record.time_spent < 10:  # è¿‡å¿«å¯èƒ½ä¸è®¤çœŸ
                    score -= 0.2

            # AIç½®ä¿¡åº¦å› ç´ 
            if record.ai_confidence and record.ai_confidence > 0.8:
                score += 0.2

            engagement_scores.append(max(0, min(1, score)))

        avg_engagement = sum(engagement_scores) / len(engagement_scores)

        return {
            "engagement_score": avg_engagement,
            "engagement_level": (
                "high" if avg_engagement > 0.7 else "low" if avg_engagement < 0.4 else "medium"
            ),
        }

    # ==================== ç­–ç•¥åº”ç”¨æ–¹æ³• ====================

    async def _apply_content_adjustments(
        self,
        student_id: int,
        training_type: TrainingType,
        content_adjustment: dict[str, Any],
    ) -> dict[str, Any]:
        """åº”ç”¨å†…å®¹è°ƒæ•´."""
        try:
            adjustments = content_adjustment.get("adjustments", [])
            applied_count = 0

            for adjustment in adjustments:
                # è¿™é‡Œå¯ä»¥è°ƒç”¨è‡ªé€‚åº”æœåŠ¡æ¥åº”ç”¨å…·ä½“çš„å†…å®¹è°ƒæ•´
                # æš‚æ—¶è®°å½•è°ƒæ•´æ„å›¾
                logger.info(f"åº”ç”¨å†…å®¹è°ƒæ•´: {adjustment}")
                applied_count += 1

            return {
                "success": True,
                "applied_adjustments": applied_count,
                "total_adjustments": len(adjustments),
            }

        except Exception as e:
            logger.error(f"åº”ç”¨å†…å®¹è°ƒæ•´å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
            }

    async def _apply_frequency_adjustments(
        self,
        student_id: int,
        training_type: TrainingType,
        frequency_adjustment: dict[str, Any],
    ) -> dict[str, Any]:
        """åº”ç”¨é¢‘ç‡è°ƒæ•´."""
        try:
            adjustments = frequency_adjustment.get("frequency_adjustments", {})
            applied_changes = []

            for key, value in adjustments.items():
                if key != "reason":
                    # è¿™é‡Œå¯ä»¥è°ƒç”¨ç›¸å…³æœåŠ¡æ¥åº”ç”¨é¢‘ç‡è°ƒæ•´
                    logger.info(f"åº”ç”¨é¢‘ç‡è°ƒæ•´: {key} -> {value}")
                    applied_changes.append(f"{key}: {value}")

            return {
                "success": True,
                "applied_changes": applied_changes,
                "total_changes": len(applied_changes),
            }

        except Exception as e:
            logger.error(f"åº”ç”¨é¢‘ç‡è°ƒæ•´å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
            }

    async def _record_strategy_adjustment(
        self,
        student_id: int,
        training_type: TrainingType,
        strategy: dict[str, Any],
        applied_adjustments: dict[str, Any],
    ) -> None:
        """è®°å½•ç­–ç•¥è°ƒæ•´å†å²."""
        try:
            # è¿™é‡Œå¯ä»¥åˆ›å»ºä¸“é—¨çš„ç­–ç•¥è°ƒæ•´è®°å½•è¡¨
            # æš‚æ—¶ä½¿ç”¨æ—¥å¿—è®°å½•
            logger.info(
                f"ç­–ç•¥è°ƒæ•´è®°å½•: å­¦ç”Ÿ{student_id}, è®­ç»ƒç±»å‹{training_type}, "
                f"ç­–ç•¥{strategy}, åº”ç”¨ç»“æœ{applied_adjustments}"
            )

        except Exception as e:
            logger.error(f"è®°å½•ç­–ç•¥è°ƒæ•´å¤±è´¥: {str(e)}")
