"""æ™ºèƒ½é¢„è­¦æœåŠ¡ - ğŸ”¥éœ€æ±‚21ç¬¬ä¸‰é˜¶æ®µæ™ºèƒ½é¢„è­¦æ ¸å¿ƒå®ç°.

æ™ºèƒ½é¢„è­¦åŠŸèƒ½ï¼š
- å­¦ä¹ æ•ˆæœä¸‹é™è‡ªåŠ¨é¢„è­¦
- å¼‚å¸¸å­¦ä¹ æ¨¡å¼è¯†åˆ«
- å¯é…ç½®é¢„è­¦é˜ˆå€¼å’Œè§„åˆ™
- å¤šçº§é¢„è­¦æœºåˆ¶
- é¢„è­¦å†å²è®°å½•å’Œåˆ†æ
"""

import json
import logging
from datetime import datetime, timedelta
from typing import Any, TypedDict

import redis.asyncio as redis
from sqlalchemy import and_, desc, select
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.config import settings
from app.training.models.training_models import TrainingRecord, TrainingSession

logger = logging.getLogger(__name__)


class AlertThresholds(TypedDict):
    """é¢„è­¦é˜ˆå€¼é…ç½®ç±»å‹."""

    accuracy_drop_warning: float
    accuracy_drop_critical: float
    speed_drop_warning: float
    speed_drop_critical: float
    consecutive_errors_warning: int
    consecutive_errors_critical: int
    engagement_drop_warning: float
    session_timeout_warning: int
    session_timeout_critical: int


class PatternDetection(TypedDict):
    """æ¨¡å¼æ£€æµ‹é…ç½®ç±»å‹."""

    enable_pattern_analysis: bool
    analysis_window_minutes: int
    min_samples_for_analysis: int
    anomaly_threshold: float


class AlertRules(TypedDict):
    """é¢„è­¦è§„åˆ™é…ç½®ç±»å‹."""

    enable_smart_filtering: bool
    duplicate_alert_interval: int
    escalation_time: int
    auto_recovery_check: bool
    max_alerts_per_session: int


class NotificationConfig(TypedDict):
    """é€šçŸ¥é…ç½®ç±»å‹."""

    immediate_push: list[str]
    batch_push: list[str]
    push_interval: int
    enable_email_alerts: bool


class AlertConfig(TypedDict):
    """æ™ºèƒ½é¢„è­¦é…ç½®ç±»å‹."""

    thresholds: AlertThresholds
    pattern_detection: PatternDetection
    alert_rules: AlertRules
    notification: NotificationConfig


class IntelligentAlertService:
    """æ™ºèƒ½é¢„è­¦æœåŠ¡ - å­¦ä¹ æ•ˆæœä¸‹é™å’Œå¼‚å¸¸æ¨¡å¼è‡ªåŠ¨é¢„è­¦."""

    def __init__(self, db: AsyncSession) -> None:
        self.db = db
        self.redis_client: redis.Redis | None = None

        # æ™ºèƒ½é¢„è­¦é…ç½®
        self.alert_config: AlertConfig = {
            # åŸºç¡€é¢„è­¦é˜ˆå€¼
            "thresholds": {
                "accuracy_drop_warning": 0.15,  # æ­£ç¡®ç‡ä¸‹é™15%é¢„è­¦
                "accuracy_drop_critical": 0.25,  # æ­£ç¡®ç‡ä¸‹é™25%ä¸¥é‡é¢„è­¦
                "speed_drop_warning": 0.20,  # ç­”é¢˜é€Ÿåº¦ä¸‹é™20%é¢„è­¦
                "speed_drop_critical": 0.35,  # ç­”é¢˜é€Ÿåº¦ä¸‹é™35%ä¸¥é‡é¢„è­¦
                "consecutive_errors_warning": 3,  # è¿ç»­3æ¬¡é”™è¯¯é¢„è­¦
                "consecutive_errors_critical": 5,  # è¿ç»­5æ¬¡é”™è¯¯ä¸¥é‡é¢„è­¦
                "engagement_drop_warning": 0.3,  # å‚ä¸åº¦ä¸‹é™30%é¢„è­¦
                "session_timeout_warning": 600,  # 10åˆ†é’Ÿæ— æ´»åŠ¨é¢„è­¦
                "session_timeout_critical": 1800,  # 30åˆ†é’Ÿæ— æ´»åŠ¨ä¸¥é‡é¢„è­¦
            },
            # å¼‚å¸¸æ¨¡å¼æ£€æµ‹
            "pattern_detection": {
                "enable_pattern_analysis": True,
                "analysis_window_minutes": 30,  # 30åˆ†é’Ÿåˆ†æçª—å£
                "min_samples_for_analysis": 10,  # æœ€å°‘10ä¸ªæ ·æœ¬æ‰åˆ†æ
                "anomaly_threshold": 2.0,  # å¼‚å¸¸é˜ˆå€¼ï¼ˆæ ‡å‡†å·®å€æ•°ï¼‰
            },
            # é¢„è­¦è§„åˆ™
            "alert_rules": {
                "enable_smart_filtering": True,  # å¯ç”¨æ™ºèƒ½è¿‡æ»¤
                "duplicate_alert_interval": 300,  # 5åˆ†é’Ÿå†…ä¸é‡å¤ç›¸åŒé¢„è­¦
                "escalation_time": 900,  # 15åˆ†é’Ÿåå‡çº§é¢„è­¦çº§åˆ«
                "auto_recovery_check": True,  # è‡ªåŠ¨æ¢å¤æ£€æŸ¥
                "max_alerts_per_session": 10,  # æ¯ä¼šè¯æœ€å¤š10ä¸ªé¢„è­¦
            },
            # é€šçŸ¥é…ç½®
            "notification": {
                "immediate_push": ["critical"],  # ç«‹å³æ¨é€çš„é¢„è­¦çº§åˆ«
                "batch_push": ["warning", "info"],  # æ‰¹é‡æ¨é€çš„é¢„è­¦çº§åˆ«
                "push_interval": 30,  # æ‰¹é‡æ¨é€é—´éš”ï¼ˆç§’ï¼‰
                "enable_email_alerts": False,  # é‚®ä»¶é¢„è­¦ï¼ˆæš‚æœªå®ç°ï¼‰
            },
        }

    async def initialize_redis(self) -> None:
        """åˆå§‹åŒ–Redisè¿æ¥."""
        try:
            self.redis_client = redis.from_url(  # type: ignore[no-untyped-call]
                f"redis://{settings.REDIS_HOST}:{settings.REDIS_PORT}/{settings.REDIS_DB}",
                encoding="utf-8",
                decode_responses=True,
            )
            if self.redis_client:
                await self.redis_client.ping()
            logger.info("æ™ºèƒ½é¢„è­¦Redisè¿æ¥åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"æ™ºèƒ½é¢„è­¦Redisè¿æ¥åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.redis_client = None

    async def analyze_and_generate_alerts(
        self, student_id: int, session_id: int, current_metrics: dict[str, Any]
    ) -> list[dict[str, Any]]:
        """åˆ†æå¹¶ç”Ÿæˆæ™ºèƒ½é¢„è­¦."""
        try:
            logger.debug(f"å¼€å§‹æ™ºèƒ½é¢„è­¦åˆ†æ: å­¦ç”Ÿ{student_id}, ä¼šè¯{session_id}")

            alerts = []

            # 1. åŸºç¡€é˜ˆå€¼é¢„è­¦
            threshold_alerts = await self._check_threshold_alerts(
                student_id, session_id, current_metrics
            )
            alerts.extend(threshold_alerts)

            # 2. å¼‚å¸¸æ¨¡å¼æ£€æµ‹
            if self.alert_config["pattern_detection"]["enable_pattern_analysis"]:
                pattern_alerts = await self._detect_anomaly_patterns(
                    student_id, session_id, current_metrics
                )
                alerts.extend(pattern_alerts)

            # 3. å­¦ä¹ æ•ˆæœè¶‹åŠ¿åˆ†æ
            trend_alerts = await self._analyze_learning_trends(
                student_id, session_id, current_metrics
            )
            alerts.extend(trend_alerts)

            # 4. æ™ºèƒ½è¿‡æ»¤å’Œå»é‡
            if self.alert_config["alert_rules"]["enable_smart_filtering"]:
                alerts = await self._filter_and_deduplicate_alerts(student_id, session_id, alerts)

            # 5. è®°å½•é¢„è­¦å†å²
            if alerts:
                await self._record_alert_history(student_id, session_id, alerts)

            logger.info(f"æ™ºèƒ½é¢„è­¦åˆ†æå®Œæˆ: å­¦ç”Ÿ{student_id}, ç”Ÿæˆ{len(alerts)}ä¸ªé¢„è­¦")
            return alerts

        except Exception as e:
            logger.error(f"æ™ºèƒ½é¢„è­¦åˆ†æå¤±è´¥: {str(e)}")
            return []

    async def _check_threshold_alerts(
        self, student_id: int, session_id: int, metrics: dict[str, Any]
    ) -> list[dict[str, Any]]:
        """æ£€æŸ¥åŸºç¡€é˜ˆå€¼é¢„è­¦."""
        alerts = []
        thresholds = self.alert_config["thresholds"]

        try:
            # è·å–å†å²åŸºçº¿æ•°æ®
            baseline = await self._get_performance_baseline(student_id)

            # æ£€æŸ¥æ­£ç¡®ç‡ä¸‹é™
            accuracy_metrics = metrics.get("accuracy_metrics", {})
            current_accuracy = accuracy_metrics.get("current_accuracy", 0)
            baseline_accuracy = baseline.get("avg_accuracy", 0.7)

            accuracy_drop = baseline_accuracy - current_accuracy

            if accuracy_drop >= thresholds["accuracy_drop_critical"]:
                alerts.append(
                    {
                        "type": "accuracy_drop",
                        "severity": "critical",
                        "message": f"æ­£ç¡®ç‡ä¸¥é‡ä¸‹é™{accuracy_drop:.1%}",
                        "current_value": current_accuracy,
                        "baseline_value": baseline_accuracy,
                        "threshold": thresholds["accuracy_drop_critical"],
                        "recommendation": "å»ºè®®é™ä½éš¾åº¦æˆ–æä¾›é¢å¤–æŒ‡å¯¼",
                    }
                )
            elif accuracy_drop >= thresholds["accuracy_drop_warning"]:
                alerts.append(
                    {
                        "type": "accuracy_drop",
                        "severity": "warning",
                        "message": f"æ­£ç¡®ç‡ä¸‹é™{accuracy_drop:.1%}",
                        "current_value": current_accuracy,
                        "baseline_value": baseline_accuracy,
                        "threshold": thresholds["accuracy_drop_warning"],
                        "recommendation": "å»ºè®®å…³æ³¨å­¦ä¹ çŠ¶æ€",
                    }
                )

            # æ£€æŸ¥è¿ç»­é”™è¯¯
            consecutive_errors = accuracy_metrics.get("consecutive_errors", 0)

            if consecutive_errors >= thresholds["consecutive_errors_critical"]:
                alerts.append(
                    {
                        "type": "consecutive_errors",
                        "severity": "critical",
                        "message": f"è¿ç»­{consecutive_errors}æ¬¡ç­”é”™",
                        "current_value": consecutive_errors,
                        "threshold": thresholds["consecutive_errors_critical"],
                        "recommendation": "å»ºè®®æš‚åœè®­ç»ƒï¼Œæ£€æŸ¥å­¦ä¹ æ–¹æ³•",
                    }
                )
            elif consecutive_errors >= thresholds["consecutive_errors_warning"]:
                alerts.append(
                    {
                        "type": "consecutive_errors",
                        "severity": "warning",
                        "message": f"è¿ç»­{consecutive_errors}æ¬¡ç­”é”™",
                        "current_value": consecutive_errors,
                        "threshold": thresholds["consecutive_errors_warning"],
                        "recommendation": "å»ºè®®è°ƒæ•´å­¦ä¹ ç­–ç•¥",
                    }
                )

            # æ£€æŸ¥ç­”é¢˜é€Ÿåº¦ä¸‹é™
            speed_metrics = metrics.get("answer_speed", {})
            current_speed = speed_metrics.get("average_time", 0)
            baseline_speed = baseline.get("avg_answer_time", 60)

            if current_speed > 0 and baseline_speed > 0:
                speed_increase = (current_speed - baseline_speed) / baseline_speed

                if speed_increase >= thresholds["speed_drop_critical"]:
                    alerts.append(
                        {
                            "type": "speed_decline",
                            "severity": "critical",
                            "message": f"ç­”é¢˜é€Ÿåº¦ä¸¥é‡ä¸‹é™{speed_increase:.1%}",
                            "current_value": current_speed,
                            "baseline_value": baseline_speed,
                            "threshold": thresholds["speed_drop_critical"],
                            "recommendation": "å»ºè®®æ£€æŸ¥ç†è§£ç¨‹åº¦æˆ–é™ä½éš¾åº¦",
                        }
                    )
                elif speed_increase >= thresholds["speed_drop_warning"]:
                    alerts.append(
                        {
                            "type": "speed_decline",
                            "severity": "warning",
                            "message": f"ç­”é¢˜é€Ÿåº¦ä¸‹é™{speed_increase:.1%}",
                            "current_value": current_speed,
                            "baseline_value": baseline_speed,
                            "threshold": thresholds["speed_drop_warning"],
                            "recommendation": "å»ºè®®å…³æ³¨ç­”é¢˜æ•ˆç‡",
                        }
                    )

            # æ£€æŸ¥å‚ä¸åº¦ä¸‹é™
            engagement_metrics = metrics.get("engagement_metrics", {})
            engagement_level = engagement_metrics.get("engagement_level", "medium")
            activity_score = engagement_metrics.get("activity_score", 0.5)

            if engagement_level == "low" or activity_score < thresholds["engagement_drop_warning"]:
                alerts.append(
                    {
                        "type": "low_engagement",
                        "severity": "warning",
                        "message": "å­¦ä¹ å‚ä¸åº¦è¾ƒä½",
                        "current_value": activity_score,
                        "threshold": thresholds["engagement_drop_warning"],
                        "recommendation": "å»ºè®®è°ƒæ•´å­¦ä¹ å†…å®¹æˆ–ä¼‘æ¯",
                    }
                )

            # æ£€æŸ¥ä¼šè¯è¶…æ—¶
            last_activity = engagement_metrics.get("time_since_last_activity", 0)

            if last_activity >= thresholds["session_timeout_critical"]:
                alerts.append(
                    {
                        "type": "session_timeout",
                        "severity": "critical",
                        "message": f"å·²{last_activity // 60}åˆ†é’Ÿæ— æ´»åŠ¨",
                        "current_value": last_activity,
                        "threshold": thresholds["session_timeout_critical"],
                        "recommendation": "å»ºè®®ç»“æŸå½“å‰ä¼šè¯",
                    }
                )
            elif last_activity >= thresholds["session_timeout_warning"]:
                alerts.append(
                    {
                        "type": "session_timeout",
                        "severity": "warning",
                        "message": f"å·²{last_activity // 60}åˆ†é’Ÿæ— æ´»åŠ¨",
                        "current_value": last_activity,
                        "threshold": thresholds["session_timeout_warning"],
                        "recommendation": "å»ºè®®æ£€æŸ¥å­¦ä¹ çŠ¶æ€",
                    }
                )

            return alerts

        except Exception as e:
            logger.error(f"åŸºç¡€é˜ˆå€¼é¢„è­¦æ£€æŸ¥å¤±è´¥: {str(e)}")
            return []

    async def _detect_anomaly_patterns(
        self, student_id: int, session_id: int, current_metrics: dict[str, Any]
    ) -> list[dict[str, Any]]:
        """æ£€æµ‹å¼‚å¸¸å­¦ä¹ æ¨¡å¼."""
        alerts: list[dict[str, Any]] = []

        try:
            # è·å–åˆ†æçª—å£å†…çš„å†å²æ•°æ®
            window_minutes = self.alert_config["pattern_detection"]["analysis_window_minutes"]
            min_samples = self.alert_config["pattern_detection"]["min_samples_for_analysis"]

            historical_data = await self._get_historical_metrics(
                student_id, session_id, window_minutes
            )

            if len(historical_data) < min_samples:
                return alerts

            # åˆ†æç­”é¢˜æ—¶é—´å¼‚å¸¸
            time_anomaly = await self._detect_time_anomaly(historical_data, current_metrics)
            if time_anomaly:
                alerts.append(time_anomaly)

            # åˆ†ææ­£ç¡®ç‡æ³¢åŠ¨å¼‚å¸¸
            accuracy_anomaly = await self._detect_accuracy_anomaly(historical_data, current_metrics)
            if accuracy_anomaly:
                alerts.append(accuracy_anomaly)

            # åˆ†æå­¦ä¹ èŠ‚å¥å¼‚å¸¸
            rhythm_anomaly = await self._detect_rhythm_anomaly(historical_data, current_metrics)
            if rhythm_anomaly:
                alerts.append(rhythm_anomaly)

            return alerts

        except Exception as e:
            logger.error(f"å¼‚å¸¸æ¨¡å¼æ£€æµ‹å¤±è´¥: {str(e)}")
            return []

    async def _analyze_learning_trends(
        self, student_id: int, session_id: int, current_metrics: dict[str, Any]
    ) -> list[dict[str, Any]]:
        """åˆ†æå­¦ä¹ æ•ˆæœè¶‹åŠ¿."""
        alerts: list[dict[str, Any]] = []

        try:
            # è·å–æœ€è¿‘çš„å­¦ä¹ è¶‹åŠ¿æ•°æ®
            trend_data = await self._get_learning_trend_data(student_id, session_id)

            if not trend_data:
                return alerts

            # åˆ†ææ­£ç¡®ç‡è¶‹åŠ¿
            accuracy_trend = trend_data.get("accuracy_trend", "stable")
            if accuracy_trend == "declining":
                alerts.append(
                    {
                        "type": "learning_trend",
                        "severity": "warning",
                        "message": "å­¦ä¹ æ•ˆæœå‘ˆä¸‹é™è¶‹åŠ¿",
                        "trend": accuracy_trend,
                        "recommendation": "å»ºè®®è°ƒæ•´å­¦ä¹ ç­–ç•¥æˆ–å¯»æ±‚å¸®åŠ©",
                    }
                )

            # åˆ†æå­¦ä¹ æ•ˆç‡è¶‹åŠ¿
            efficiency_trend = trend_data.get("efficiency_trend", "stable")
            if efficiency_trend == "declining":
                alerts.append(
                    {
                        "type": "efficiency_trend",
                        "severity": "info",
                        "message": "å­¦ä¹ æ•ˆç‡å‘ˆä¸‹é™è¶‹åŠ¿",
                        "trend": efficiency_trend,
                        "recommendation": "å»ºè®®é€‚å½“ä¼‘æ¯æˆ–è°ƒæ•´å­¦ä¹ ç¯å¢ƒ",
                    }
                )

            # åˆ†æéš¾åº¦é€‚åº”æ€§
            difficulty_adaptation = current_metrics.get("difficulty_adaptation", {})
            adaptation_status = difficulty_adaptation.get("adaptation_status", "appropriate")

            if adaptation_status == "too_hard":
                alerts.append(
                    {
                        "type": "difficulty_mismatch",
                        "severity": "warning",
                        "message": "å½“å‰éš¾åº¦å¯èƒ½è¿‡é«˜",
                        "adaptation_status": adaptation_status,
                        "recommendation": "å»ºè®®é™ä½éš¾åº¦ç­‰çº§",
                    }
                )
            elif adaptation_status == "too_easy":
                alerts.append(
                    {
                        "type": "difficulty_mismatch",
                        "severity": "info",
                        "message": "å½“å‰éš¾åº¦å¯èƒ½è¿‡ä½",
                        "adaptation_status": adaptation_status,
                        "recommendation": "å»ºè®®æé«˜éš¾åº¦ç­‰çº§",
                    }
                )

            return alerts

        except Exception as e:
            logger.error(f"å­¦ä¹ è¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}")
            return []

    async def _filter_and_deduplicate_alerts(
        self, student_id: int, session_id: int, alerts: list[dict[str, Any]]
    ) -> list[dict[str, Any]]:
        """æ™ºèƒ½è¿‡æ»¤å’Œå»é‡é¢„è­¦."""
        if not alerts:
            return alerts

        try:
            filtered_alerts = []
            duplicate_interval = self.alert_config["alert_rules"]["duplicate_alert_interval"]
            max_alerts = self.alert_config["alert_rules"]["max_alerts_per_session"]

            # è·å–æœ€è¿‘çš„é¢„è­¦å†å²
            recent_alerts = await self._get_recent_alerts(
                student_id, session_id, duplicate_interval
            )
            recent_alert_types = {alert.get("type") for alert in recent_alerts}

            for alert in alerts:
                alert_type = alert.get("type")

                # æ£€æŸ¥æ˜¯å¦é‡å¤
                if alert_type not in recent_alert_types:
                    # æ·»åŠ æ—¶é—´æˆ³å’ŒID
                    alert.update(
                        {
                            "alert_id": f"{student_id}_{session_id}_{alert_type}_{int(datetime.now().timestamp())}",
                            "timestamp": datetime.now(),
                            "student_id": student_id,
                            "session_id": session_id,
                        }
                    )
                    filtered_alerts.append(alert)

            # é™åˆ¶é¢„è­¦æ•°é‡
            if len(filtered_alerts) > max_alerts:
                # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åºï¼Œä¿ç•™æœ€é‡è¦çš„é¢„è­¦
                severity_order = {"critical": 0, "warning": 1, "info": 2}
                filtered_alerts.sort(key=lambda x: severity_order.get(x.get("severity", "info"), 3))
                filtered_alerts = filtered_alerts[:max_alerts]

            return filtered_alerts

        except Exception as e:
            logger.error(f"é¢„è­¦è¿‡æ»¤å¤±è´¥: {str(e)}")
            return alerts

    async def _record_alert_history(
        self, student_id: int, session_id: int, alerts: list[dict[str, Any]]
    ) -> None:
        """è®°å½•é¢„è­¦å†å²."""
        if not self.redis_client or not alerts:
            return

        try:
            for alert in alerts:
                # è®°å½•åˆ°Redis
                alert_key = f"alert_history:{student_id}:{session_id}"
                timestamp = int(datetime.now().timestamp())

                await self.redis_client.zadd(alert_key, {json.dumps(alert, default=str): timestamp})

                # è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆ7å¤©ï¼‰
                await self.redis_client.expire(alert_key, 86400 * 7)

                # è®°å½•å…¨å±€é¢„è­¦ç»Ÿè®¡
                stats_key = f"alert_stats:{student_id}"
                await self.redis_client.hincrby(stats_key, f"total_{alert['type']}", 1)
                await self.redis_client.hincrby(stats_key, f"severity_{alert['severity']}", 1)
                await self.redis_client.expire(stats_key, 86400 * 30)

        except Exception as e:
            logger.error(f"è®°å½•é¢„è­¦å†å²å¤±è´¥: {str(e)}")

    async def _get_performance_baseline(self, student_id: int) -> dict[str, Any]:
        """è·å–æ€§èƒ½åŸºçº¿æ•°æ®."""
        if not self.redis_client:
            return await self._calculate_baseline_from_db(student_id)

        try:
            baseline_key = f"baseline:{student_id}"
            baseline_data = await self.redis_client.hgetall(baseline_key)

            if baseline_data:
                return {
                    k: (
                        json.loads(v)
                        if v.startswith("{") or v.startswith("[")
                        else float(v)
                        if "." in v
                        else v
                    )
                    for k, v in baseline_data.items()
                }
            else:
                return await self._calculate_baseline_from_db(student_id)

        except Exception as e:
            logger.error(f"è·å–æ€§èƒ½åŸºçº¿å¤±è´¥: {str(e)}")
            return await self._calculate_baseline_from_db(student_id)

    async def _calculate_baseline_from_db(self, student_id: int) -> dict[str, Any]:
        """ä»æ•°æ®åº“è®¡ç®—åŸºçº¿æ•°æ®."""
        try:
            cutoff_date = datetime.now() - timedelta(days=30)

            stmt = (
                select(TrainingRecord)
                .join(TrainingSession, TrainingRecord.session_id == TrainingSession.id)
                .where(
                    and_(
                        TrainingSession.student_id == student_id,
                        TrainingRecord.created_at >= cutoff_date,
                    )
                )
                .order_by(desc(TrainingRecord.created_at))
                .limit(100)
            )

            result = await self.db.execute(stmt)
            records = result.scalars().all()

            if not records:
                return {"avg_accuracy": 0.7, "avg_answer_time": 60.0}

            # è®¡ç®—åŸºçº¿æŒ‡æ ‡
            correct_count = sum(1 for r in records if r.is_correct)
            avg_accuracy = correct_count / len(records)

            times = [r.time_spent for r in records if r.time_spent]
            avg_answer_time = sum(times) / len(times) if times else 60.0

            return {
                "avg_accuracy": avg_accuracy,
                "avg_answer_time": avg_answer_time,
                "sample_size": len(records),
            }

        except Exception as e:
            logger.error(f"è®¡ç®—åŸºçº¿æ•°æ®å¤±è´¥: {str(e)}")
            return {"avg_accuracy": 0.7, "avg_answer_time": 60.0}

    async def _get_historical_metrics(
        self, student_id: int, session_id: int, window_minutes: int
    ) -> list[dict[str, Any]]:
        """è·å–å†å²æŒ‡æ ‡æ•°æ®."""
        if not self.redis_client:
            return []

        try:
            timeseries_key = f"metrics:timeseries:{student_id}:{session_id}"
            cutoff_timestamp = int((datetime.now() - timedelta(minutes=window_minutes)).timestamp())

            # è·å–æ—¶é—´çª—å£å†…çš„æ•°æ®
            data = await self.redis_client.zrangebyscore(
                timeseries_key, cutoff_timestamp, "+inf", withscores=True
            )

            metrics_list = []
            for item, timestamp in data:
                try:
                    metrics = json.loads(item)
                    metrics["timestamp"] = timestamp
                    metrics_list.append(metrics)
                except json.JSONDecodeError:
                    continue

            return metrics_list

        except Exception as e:
            logger.error(f"è·å–å†å²æŒ‡æ ‡å¤±è´¥: {str(e)}")
            return []

    async def _detect_time_anomaly(
        self, historical_data: list[dict[str, Any]], current_metrics: dict[str, Any]
    ) -> dict[str, Any] | None:
        """æ£€æµ‹ç­”é¢˜æ—¶é—´å¼‚å¸¸."""
        try:
            # æå–å†å²ç­”é¢˜æ—¶é—´
            historical_times = []
            for data in historical_data:
                speed_metrics = data.get("answer_speed", {})
                avg_time = speed_metrics.get("average_time", 0)
                if avg_time > 0:
                    historical_times.append(avg_time)

            if len(historical_times) < 5:
                return None

            # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
            import statistics

            mean_time = statistics.mean(historical_times)
            stdev_time = statistics.stdev(historical_times) if len(historical_times) > 1 else 0

            # è·å–å½“å‰ç­”é¢˜æ—¶é—´
            current_speed = current_metrics.get("answer_speed", {})
            current_time = current_speed.get("average_time", 0)

            if current_time <= 0 or stdev_time <= 0:
                return None

            # è®¡ç®—Zåˆ†æ•°
            z_score = abs(current_time - mean_time) / stdev_time
            anomaly_threshold = self.alert_config["pattern_detection"]["anomaly_threshold"]

            if z_score > anomaly_threshold:
                return {
                    "type": "time_anomaly",
                    "severity": "warning",
                    "message": f"ç­”é¢˜æ—¶é—´å¼‚å¸¸ï¼ˆZåˆ†æ•°: {z_score:.2f}ï¼‰",
                    "current_value": current_time,
                    "mean_value": mean_time,
                    "z_score": z_score,
                    "recommendation": "å»ºè®®æ£€æŸ¥å­¦ä¹ çŠ¶æ€æˆ–ç½‘ç»œè¿æ¥",
                }

            return None

        except Exception as e:
            logger.error(f"æ—¶é—´å¼‚å¸¸æ£€æµ‹å¤±è´¥: {str(e)}")
            return None

    async def _detect_accuracy_anomaly(
        self, historical_data: list[dict[str, Any]], current_metrics: dict[str, Any]
    ) -> dict[str, Any] | None:
        """æ£€æµ‹æ­£ç¡®ç‡æ³¢åŠ¨å¼‚å¸¸."""
        try:
            # æå–å†å²æ­£ç¡®ç‡
            historical_accuracies = []
            for data in historical_data:
                accuracy_metrics = data.get("accuracy_metrics", {})
                accuracy = accuracy_metrics.get("current_accuracy", 0)
                if accuracy > 0:
                    historical_accuracies.append(accuracy)

            if len(historical_accuracies) < 5:
                return None

            # è®¡ç®—å˜å¼‚ç³»æ•°
            import statistics

            mean_accuracy = statistics.mean(historical_accuracies)
            stdev_accuracy = (
                statistics.stdev(historical_accuracies) if len(historical_accuracies) > 1 else 0
            )

            if mean_accuracy <= 0:
                return None

            coefficient_of_variation = stdev_accuracy / mean_accuracy

            # å¦‚æœå˜å¼‚ç³»æ•°è¿‡å¤§ï¼Œè¯´æ˜æ­£ç¡®ç‡æ³¢åŠ¨å¼‚å¸¸
            if coefficient_of_variation > 0.3:  # 30%çš„å˜å¼‚ç³»æ•°é˜ˆå€¼
                return {
                    "type": "accuracy_volatility",
                    "severity": "info",
                    "message": f"æ­£ç¡®ç‡æ³¢åŠ¨è¾ƒå¤§ï¼ˆå˜å¼‚ç³»æ•°: {coefficient_of_variation:.2f}ï¼‰",
                    "mean_accuracy": mean_accuracy,
                    "coefficient_of_variation": coefficient_of_variation,
                    "recommendation": "å»ºè®®ä¿æŒç¨³å®šçš„å­¦ä¹ èŠ‚å¥",
                }

            return None

        except Exception as e:
            logger.error(f"æ­£ç¡®ç‡å¼‚å¸¸æ£€æµ‹å¤±è´¥: {str(e)}")
            return None

    async def _detect_rhythm_anomaly(
        self, historical_data: list[dict[str, Any]], current_metrics: dict[str, Any]
    ) -> dict[str, Any] | None:
        """æ£€æµ‹å­¦ä¹ èŠ‚å¥å¼‚å¸¸."""
        try:
            # åˆ†æç­”é¢˜é—´éš”
            timestamps = [data.get("timestamp", 0) for data in historical_data]
            timestamps.sort()

            if len(timestamps) < 3:
                return None

            # è®¡ç®—ç­”é¢˜é—´éš”
            intervals = []
            for i in range(1, len(timestamps)):
                interval = timestamps[i] - timestamps[i - 1]
                intervals.append(interval)

            if not intervals:
                return None

            # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸é•¿çš„é—´éš”
            import statistics

            mean_interval = statistics.mean(intervals)
            max_interval = max(intervals)

            # å¦‚æœæœ€å¤§é—´éš”è¶…è¿‡å¹³å‡é—´éš”çš„3å€ï¼Œè®¤ä¸ºæ˜¯èŠ‚å¥å¼‚å¸¸
            if max_interval > mean_interval * 3 and max_interval > 300:  # 5åˆ†é’Ÿ
                return {
                    "type": "rhythm_anomaly",
                    "severity": "info",
                    "message": f"å­¦ä¹ èŠ‚å¥ä¸è§„å¾‹ï¼ˆæœ€å¤§é—´éš”: {max_interval // 60}åˆ†é’Ÿï¼‰",
                    "max_interval": max_interval,
                    "mean_interval": mean_interval,
                    "recommendation": "å»ºè®®ä¿æŒè§„å¾‹çš„å­¦ä¹ èŠ‚å¥",
                }

            return None

        except Exception as e:
            logger.error(f"å­¦ä¹ èŠ‚å¥å¼‚å¸¸æ£€æµ‹å¤±è´¥: {str(e)}")
            return None

    async def _get_learning_trend_data(self, student_id: int, session_id: int) -> dict[str, Any]:
        """è·å–å­¦ä¹ è¶‹åŠ¿æ•°æ®."""
        try:
            # è·å–æœ€è¿‘çš„è®­ç»ƒè®°å½•
            cutoff_date = datetime.now() - timedelta(hours=2)

            stmt = (
                select(TrainingRecord)
                .where(
                    and_(
                        TrainingRecord.session_id == session_id,
                        TrainingRecord.created_at >= cutoff_date,
                    )
                )
                .order_by(TrainingRecord.created_at)
            )

            result = await self.db.execute(stmt)
            records = result.scalars().all()

            if len(records) < 10:
                return {}

            # åˆ†ææ­£ç¡®ç‡è¶‹åŠ¿
            mid_point = len(records) // 2
            early_records = records[:mid_point]
            recent_records = records[mid_point:]

            early_accuracy = sum(1 for r in early_records if r.is_correct) / len(early_records)
            recent_accuracy = sum(1 for r in recent_records if r.is_correct) / len(recent_records)

            if recent_accuracy < early_accuracy - 0.1:
                accuracy_trend = "declining"
            elif recent_accuracy > early_accuracy + 0.1:
                accuracy_trend = "improving"
            else:
                accuracy_trend = "stable"

            # åˆ†ææ•ˆç‡è¶‹åŠ¿
            early_times = [r.time_spent for r in early_records if r.time_spent]
            recent_times = [r.time_spent for r in recent_records if r.time_spent]

            if early_times and recent_times:
                early_avg_time = sum(early_times) / len(early_times)
                recent_avg_time = sum(recent_times) / len(recent_times)

                if recent_avg_time > early_avg_time * 1.2:
                    efficiency_trend = "declining"
                elif recent_avg_time < early_avg_time * 0.8:
                    efficiency_trend = "improving"
                else:
                    efficiency_trend = "stable"
            else:
                efficiency_trend = "unknown"

            return {
                "accuracy_trend": accuracy_trend,
                "efficiency_trend": efficiency_trend,
                "early_accuracy": early_accuracy,
                "recent_accuracy": recent_accuracy,
                "sample_size": len(records),
            }

        except Exception as e:
            logger.error(f"è·å–å­¦ä¹ è¶‹åŠ¿æ•°æ®å¤±è´¥: {str(e)}")
            return {}

    async def _get_recent_alerts(
        self, student_id: int, session_id: int, interval_seconds: int
    ) -> list[dict[str, Any]]:
        """è·å–æœ€è¿‘çš„é¢„è­¦è®°å½•."""
        if not self.redis_client:
            return []

        try:
            alert_key = f"alert_history:{student_id}:{session_id}"
            cutoff_timestamp = int(
                (datetime.now() - timedelta(seconds=interval_seconds)).timestamp()
            )

            data = await self.redis_client.zrangebyscore(alert_key, cutoff_timestamp, "+inf")

            alerts = []
            for item in data:
                try:
                    alert = json.loads(item)
                    alerts.append(alert)
                except json.JSONDecodeError:
                    continue

            return alerts

        except Exception as e:
            logger.error(f"è·å–æœ€è¿‘é¢„è­¦å¤±è´¥: {str(e)}")
            return []

    async def get_alert_statistics(self, student_id: int) -> dict[str, Any]:
        """è·å–é¢„è­¦ç»Ÿè®¡ä¿¡æ¯."""
        if not self.redis_client:
            return {}

        try:
            stats_key = f"alert_stats:{student_id}"
            stats = await self.redis_client.hgetall(stats_key)

            return {
                "student_id": student_id,
                "statistics": stats,
                "total_alerts": sum(int(v) for k, v in stats.items() if k.startswith("total_")),
                "critical_alerts": int(stats.get("severity_critical", 0)),
                "warning_alerts": int(stats.get("severity_warning", 0)),
                "info_alerts": int(stats.get("severity_info", 0)),
            }

        except Exception as e:
            logger.error(f"è·å–é¢„è­¦ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {}

    def update_alert_config(self, config_updates: dict[str, Any]) -> dict[str, Any]:
        """æ›´æ–°é¢„è­¦é…ç½®."""
        try:
            # æ·±åº¦æ›´æ–°é…ç½®
            def deep_update(base_dict: dict[str, Any], update_dict: dict[str, Any]) -> None:
                for key, value in update_dict.items():
                    if (
                        key in base_dict
                        and isinstance(base_dict[key], dict)
                        and isinstance(value, dict)
                    ):
                        deep_update(base_dict[key], value)
                    else:
                        base_dict[key] = value

            # å°†AlertConfigè½¬æ¢ä¸ºæ™®é€šå­—å…¸è¿›è¡Œæ›´æ–°
            config_dict = dict(self.alert_config)
            deep_update(config_dict, config_updates)
            # æ›´æ–°å›AlertConfigï¼ˆè¿™é‡Œå‡è®¾æ›´æ–°åçš„ç»“æ„ä»ç„¶ç¬¦åˆAlertConfigï¼‰
            self.alert_config.update(config_dict)  # type: ignore[typeddict-item]

            logger.info(f"é¢„è­¦é…ç½®å·²æ›´æ–°: {config_updates}")
            return dict(self.alert_config)

        except Exception as e:
            logger.error(f"æ›´æ–°é¢„è­¦é…ç½®å¤±è´¥: {str(e)}")
            return dict(self.alert_config)
