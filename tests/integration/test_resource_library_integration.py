"""
èµ„æºåº“æ¨¡å—é›†æˆæµ‹è¯•

æµ‹è¯•åŠŸèƒ½ï¼š
1. å®Œæ•´çš„æ–‡æ¡£å¤„ç†æµç¨‹
2. å‘é‡æ£€ç´¢åŠŸèƒ½
3. AIå†…å®¹ç”Ÿæˆ
4. æ€§èƒ½ç›‘æ§
5. é”™è¯¯å¤„ç†æœºåˆ¶
"""

import asyncio
import tempfile
from datetime import datetime
from pathlib import Path

import pytest
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.database import get_db
from app.resources.models.resource_models import ProcessingStatus
from app.resources.services.document_processing_service import DocumentProcessingService
from app.resources.services.performance_monitoring_service import (
    ResourcePerformanceMonitor,
)
from app.resources.services.resource_library_service import (
    ResourceCreateRequest,
    ResourceLibraryService,
)
from app.resources.services.vector_search_service import (
    SearchQuery,
    VectorSearchService,
)
from app.shared.models.enums import PermissionLevel, ResourceType
from app.shared.services.cache_service import CacheService


class TestResourceLibraryIntegration:
    """èµ„æºåº“æ¨¡å—é›†æˆæµ‹è¯•"""

    @pytest.fixture
    async def db_session(self) -> AsyncSession:
        """æ•°æ®åº“ä¼šè¯fixture"""
        async for session in get_db():
            yield session

    @pytest.fixture
    async def cache_service(self) -> CacheService:
        """ç¼“å­˜æœåŠ¡fixture"""
        # è¿™é‡Œåº”è¯¥åˆ›å»ºæµ‹è¯•ç”¨çš„ç¼“å­˜æœåŠ¡
        # ç®€åŒ–å®ç°ï¼Œè¿”å›None
        return None  # type: ignore

    @pytest.fixture
    async def resource_service(
        self, db_session: AsyncSession, cache_service: CacheService
    ) -> ResourceLibraryService:
        """èµ„æºåº“æœåŠ¡fixture"""
        document_processing_service = DocumentProcessingService(
            db_session, None, cache_service
        )
        return ResourceLibraryService(
            db_session, cache_service, document_processing_service
        )

    @pytest.fixture
    async def vector_service(
        self, db_session: AsyncSession, cache_service: CacheService
    ) -> VectorSearchService:
        """å‘é‡æ£€ç´¢æœåŠ¡fixture"""
        return VectorSearchService(db_session, cache_service)

    @pytest.fixture
    async def performance_monitor(
        self, db_session: AsyncSession, cache_service: CacheService
    ) -> ResourcePerformanceMonitor:
        """æ€§èƒ½ç›‘æ§æœåŠ¡fixture"""
        return ResourcePerformanceMonitor(db_session, cache_service)

    @pytest.fixture
    def sample_document_content(self) -> str:
        """ç¤ºä¾‹æ–‡æ¡£å†…å®¹"""
        return """
        è‹±è¯­å››çº§è€ƒè¯•ç»¼åˆè®­ç»ƒæ•™ç¨‹

        ç¬¬ä¸€ç« ï¼šå¬åŠ›ç†è§£
        å¬åŠ›ç†è§£æ˜¯è‹±è¯­å››çº§è€ƒè¯•çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå æ€»åˆ†çš„35%ã€‚æœ¬ç« å°†ä»‹ç»å¬åŠ›ç†è§£çš„åŸºæœ¬æŠ€å·§å’Œè®­ç»ƒæ–¹æ³•ã€‚

        1.1 çŸ­å¯¹è¯ç†è§£
        çŸ­å¯¹è¯ç†è§£è¦æ±‚è€ƒç”Ÿèƒ½å¤Ÿç†è§£æ—¥å¸¸ç”Ÿæ´»ä¸­çš„ç®€çŸ­å¯¹è¯ï¼ŒæŠŠæ¡å¯¹è¯çš„ä¸»è¦å†…å®¹å’Œè¯´è¯äººçš„æ€åº¦ã€‚

        1.2 é•¿å¯¹è¯ç†è§£
        é•¿å¯¹è¯ç†è§£æ¶‰åŠæ›´å¤æ‚çš„è¯­å¢ƒå’Œæ›´å¤šçš„ä¿¡æ¯ç‚¹ï¼Œéœ€è¦è€ƒç”Ÿå…·å¤‡è¾ƒå¼ºçš„ä¿¡æ¯ç­›é€‰å’Œæ•´åˆèƒ½åŠ›ã€‚

        ç¬¬äºŒç« ï¼šé˜…è¯»ç†è§£
        é˜…è¯»ç†è§£æ˜¯è‹±è¯­å››çº§è€ƒè¯•çš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œå æ€»åˆ†çš„35%ã€‚æœ¬ç« å°†ç³»ç»Ÿä»‹ç»é˜…è¯»ç†è§£çš„è§£é¢˜ç­–ç•¥ã€‚

        2.1 è¯æ±‡ç†è§£
        è¯æ±‡ç†è§£è¦æ±‚è€ƒç”Ÿèƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡æ¨æ–­ç”Ÿè¯çš„å«ä¹‰ï¼Œè¿™æ˜¯é˜…è¯»ç†è§£çš„åŸºç¡€æŠ€èƒ½ã€‚

        2.2 é•¿ç¯‡é˜…è¯»
        é•¿ç¯‡é˜…è¯»è€ƒæŸ¥è€ƒç”Ÿå¯¹æ–‡ç« æ•´ä½“ç»“æ„å’Œé€»è¾‘å…³ç³»çš„æŠŠæ¡èƒ½åŠ›ã€‚

        ç¬¬ä¸‰ç« ï¼šå†™ä½œä¸ç¿»è¯‘
        å†™ä½œä¸ç¿»è¯‘éƒ¨åˆ†å æ€»åˆ†çš„30%ï¼Œæ˜¯è€ƒç”Ÿç»¼åˆè¯­è¨€è¿ç”¨èƒ½åŠ›çš„ä½“ç°ã€‚

        3.1 çŸ­æ–‡å†™ä½œ
        çŸ­æ–‡å†™ä½œè¦æ±‚è€ƒç”Ÿèƒ½å¤Ÿåœ¨30åˆ†é’Ÿå†…å®Œæˆä¸€ç¯‡120-180è¯çš„çŸ­æ–‡ã€‚

        3.2 æ±‰è¯‘è‹±
        æ±‰è¯‘è‹±è¦æ±‚è€ƒç”Ÿèƒ½å¤Ÿå°†ä¸­æ–‡æ®µè½å‡†ç¡®ç¿»è¯‘æˆè‹±æ–‡ï¼Œè€ƒæŸ¥è¯­è¨€è½¬æ¢èƒ½åŠ›ã€‚
        """

    async def test_complete_document_processing_workflow(
        self,
        resource_service: ResourceLibraryService,
        sample_document_content: str,
        performance_monitor: ResourcePerformanceMonitor,
    ) -> None:
        """æµ‹è¯•å®Œæ•´çš„æ–‡æ¡£å¤„ç†å·¥ä½œæµç¨‹"""
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as f:
            f.write(sample_document_content)
            temp_file_path = f.name

        try:
            # 1. åˆ›å»ºèµ„æº
            async with performance_monitor.create_performance_context_manager(
                "resource_creation", "create_resource"
            ) as ctx:
                ctx.add_metadata("file_size", len(sample_document_content))

                create_request = ResourceCreateRequest(
                    name="è‹±è¯­å››çº§ç»¼åˆè®­ç»ƒæ•™ç¨‹",
                    resource_type=ResourceType.TEXTBOOK,
                    category="æ•™æ",
                    description="è‹±è¯­å››çº§è€ƒè¯•ç»¼åˆè®­ç»ƒæ•™ç¨‹",
                    permission_level=PermissionLevel.PUBLIC,
                    file_path=temp_file_path,
                    file_format="txt",
                )

                resource = await resource_service.create_resource(
                    create_request, user_id=1
                )
                assert resource is not None
                assert resource.name == "è‹±è¯­å››çº§ç»¼åˆè®­ç»ƒæ•™ç¨‹"
                assert resource.processing_status == ProcessingStatus.PENDING

            # 2. å¤„ç†æ–‡æ¡£
            async with performance_monitor.create_performance_context_manager(
                "document_processing", "process_large_document"
            ) as ctx:
                ctx.add_metadata("resource_id", resource.id)

                processing_result = await resource_service.document_processing_service.process_large_document(
                    resource.id, force_reprocess=True
                )

                assert processing_result is not None
                assert processing_result.success
                assert processing_result.chunks_count > 0
                ctx.add_metadata("chunks_count", processing_result.chunks_count)

            # 3. éªŒè¯èµ„æºçŠ¶æ€æ›´æ–°
            updated_resource = await resource_service.get_resource(
                resource.id, user_id=1
            )
            assert updated_resource.processing_status == ProcessingStatus.COMPLETED

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            Path(temp_file_path).unlink(missing_ok=True)

    async def test_vector_search_functionality(
        self,
        vector_service: VectorSearchService,
        performance_monitor: ResourcePerformanceMonitor,
    ) -> None:
        """æµ‹è¯•å‘é‡æ£€ç´¢åŠŸèƒ½"""
        # åˆå§‹åŒ–Milvusé›†ç¾¤
        async with performance_monitor.create_performance_context_manager(
            "vector_search", "initialize_milvus"
        ) as ctx:
            init_success = await vector_service.initialize_milvus_cluster()
            ctx.add_metadata("init_success", init_success)

        # æ‰§è¡Œæ··åˆæ£€ç´¢
        async with performance_monitor.create_performance_context_manager(
            "vector_search", "hybrid_search"
        ) as ctx:
            search_query = SearchQuery(
                query_text="è‹±è¯­å››çº§å¬åŠ›ç†è§£æŠ€å·§",
                top_k=10,
                similarity_threshold=0.7,
                filters={"resource_type": "textbook"},
            )

            search_response = await vector_service.hybrid_search(search_query)

            assert search_response is not None
            assert isinstance(search_response.results, list)
            ctx.add_metadata("results_count", len(search_response.results))
            ctx.add_metadata("search_time_ms", search_response.search_time_ms)

    async def test_ai_content_generation(
        self, performance_monitor: ResourcePerformanceMonitor
    ) -> None:
        """æµ‹è¯•AIå†…å®¹ç”ŸæˆåŠŸèƒ½"""
        from app.ai.services.deepseek_content_service import DeepSeekContentService

        content_service = DeepSeekContentService()

        # æµ‹è¯•æ•™å­¦å¤§çº²ç”Ÿæˆ
        async with performance_monitor.create_performance_context_manager(
            "ai_generation", "generate_syllabus"
        ) as ctx:
            course_info = {
                "name": "è‹±è¯­å››çº§ç»¼åˆè®­ç»ƒ",
                "duration": "16å‘¨",
                "target_level": "CET-4",
            }

            resource_content = "è‹±è¯­å››çº§è€ƒè¯•æ˜¯å¤§å­¦ç”Ÿè‹±è¯­èƒ½åŠ›çš„é‡è¦è¯„ä¼°æ ‡å‡†..."

            syllabus = await content_service.generate_syllabus(
                resource_content, course_info
            )

            if syllabus:
                assert isinstance(syllabus, dict)
                assert "course_title" in syllabus
                ctx.add_metadata("syllabus_generated", True)
            else:
                ctx.add_metadata("syllabus_generated", False)

        # æµ‹è¯•æ•™æ¡ˆç”Ÿæˆ
        async with performance_monitor.create_performance_context_manager(
            "ai_generation", "generate_lesson_plan"
        ) as ctx:
            lesson_info = {
                "title": "å¬åŠ›ç†è§£è®­ç»ƒ",
                "duration": "90åˆ†é’Ÿ",
                "objectives": ["æé«˜å¬åŠ›ç†è§£èƒ½åŠ›"],
            }

            basic_syllabus = {
                "course_title": "è‹±è¯­å››çº§ç»¼åˆè®­ç»ƒ",
                "course_outline": [{"week": 1, "topic": "å¬åŠ›è®­ç»ƒ"}],
            }

            lesson_plan = await content_service.generate_lesson_plan(
                basic_syllabus, lesson_info
            )

            if lesson_plan:
                assert isinstance(lesson_plan, dict)
                assert "lesson_title" in lesson_plan
                ctx.add_metadata("lesson_plan_generated", True)
            else:
                ctx.add_metadata("lesson_plan_generated", False)

    async def test_embedding_service_functionality(
        self, performance_monitor: ResourcePerformanceMonitor
    ) -> None:
        """æµ‹è¯•å‘é‡åŒ–æœåŠ¡åŠŸèƒ½"""
        from app.ai.services.deepseek_embedding_service import DeepSeekEmbeddingService

        embedding_service = DeepSeekEmbeddingService()

        # æµ‹è¯•å•æ–‡æœ¬å‘é‡åŒ–
        async with performance_monitor.create_performance_context_manager(
            "embedding", "vectorize_text"
        ) as ctx:
            test_text = "è‹±è¯­å››çº§å¬åŠ›ç†è§£æ˜¯è€ƒè¯•çš„é‡è¦ç»„æˆéƒ¨åˆ†"

            embedding = await embedding_service.vectorize_text(test_text)

            assert isinstance(embedding, list)
            assert len(embedding) == 1536  # DeepSeek embedding dimension
            assert all(isinstance(x, float) for x in embedding)

            ctx.add_metadata("text_length", len(test_text))
            ctx.add_metadata("embedding_dimension", len(embedding))

        # æµ‹è¯•æ‰¹é‡å‘é‡åŒ–
        async with performance_monitor.create_performance_context_manager(
            "embedding", "vectorize_batch"
        ) as ctx:
            test_texts = [
                "è‹±è¯­å››çº§å¬åŠ›æŠ€å·§",
                "é˜…è¯»ç†è§£æ–¹æ³•",
                "å†™ä½œè®­ç»ƒè¦ç‚¹",
                "ç¿»è¯‘æŠ€èƒ½æå‡",
            ]

            embeddings = await embedding_service.vectorize_batch(test_texts)

            assert len(embeddings) == len(test_texts)
            assert all(len(emb) == 1536 for emb in embeddings)

            ctx.add_metadata("batch_size", len(test_texts))
            ctx.add_metadata("total_embeddings", len(embeddings))

    async def test_performance_monitoring_system(
        self, performance_monitor: ResourcePerformanceMonitor
    ) -> None:
        """æµ‹è¯•æ€§èƒ½ç›‘æ§ç³»ç»Ÿ"""
        # è®°å½•ä¸€äº›æµ‹è¯•æŒ‡æ ‡
        start_time = datetime.utcnow()
        await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿæ“ä½œè€—æ—¶
        end_time = datetime.utcnow()

        await performance_monitor.record_metric(
            service_name="test_service",
            operation_name="test_operation",
            start_time=start_time,
            end_time=end_time,
            success=True,
            metadata={"test": True},
        )

        # è·å–æ€§èƒ½ç»Ÿè®¡
        stats = await performance_monitor.get_performance_stats("test_service")
        assert stats.service_name == "test_service"

        # æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
        health_report = await performance_monitor.check_service_health()
        assert "overall_status" in health_report
        assert "services" in health_report
        assert "timestamp" in health_report

    async def test_error_handling_and_fallback(
        self, performance_monitor: ResourcePerformanceMonitor
    ) -> None:
        """æµ‹è¯•é”™è¯¯å¤„ç†å’Œé™çº§æœºåˆ¶"""
        from app.ai.services.deepseek_embedding_service import DeepSeekEmbeddingService

        embedding_service = DeepSeekEmbeddingService()

        # æµ‹è¯•ç©ºæ–‡æœ¬å¤„ç†
        async with performance_monitor.create_performance_context_manager(
            "embedding", "handle_empty_text"
        ) as ctx:
            try:
                embedding = await embedding_service.vectorize_text("")
                # åº”è¯¥è¿”å›é›¶å‘é‡æˆ–æŠ›å‡ºå¼‚å¸¸
                assert isinstance(embedding, list)
                ctx.add_metadata("handled_empty_text", True)
            except Exception as e:
                ctx.add_metadata("error_type", type(e).__name__)

        # æµ‹è¯•è¶…é•¿æ–‡æœ¬å¤„ç†
        async with performance_monitor.create_performance_context_manager(
            "embedding", "handle_long_text"
        ) as ctx:
            long_text = "æµ‹è¯•æ–‡æœ¬ " * 10000  # åˆ›å»ºè¶…é•¿æ–‡æœ¬

            try:
                embedding = await embedding_service.vectorize_text(long_text)
                assert isinstance(embedding, list)
                assert len(embedding) == 1536
                ctx.add_metadata("handled_long_text", True)
            except Exception as e:
                ctx.add_metadata("error_type", type(e).__name__)

    async def test_concurrent_operations(
        self,
        vector_service: VectorSearchService,
        performance_monitor: ResourcePerformanceMonitor,
    ) -> None:
        """æµ‹è¯•å¹¶å‘æ“ä½œ"""
        # åˆ›å»ºå¤šä¸ªå¹¶å‘æœç´¢ä»»åŠ¡
        search_tasks = []

        for i in range(5):
            search_query = SearchQuery(
                query_text=f"è‹±è¯­å››çº§æµ‹è¯•æŸ¥è¯¢ {i}",
                top_k=5,
                similarity_threshold=0.7,
            )

            async def search_with_monitoring(query: SearchQuery, task_id: int) -> None:
                async with performance_monitor.create_performance_context_manager(
                    "vector_search", f"concurrent_search_{task_id}"
                ) as ctx:
                    result = await vector_service.hybrid_search(query)
                    ctx.add_metadata("task_id", task_id)
                    ctx.add_metadata(
                        "results_count", len(result.results) if result else 0
                    )

            search_tasks.append(search_with_monitoring(search_query, i))

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æœç´¢ä»»åŠ¡
        await asyncio.gather(*search_tasks, return_exceptions=True)

        # éªŒè¯æ€§èƒ½ç›‘æ§è®°å½•äº†æ‰€æœ‰æ“ä½œ
        stats = await performance_monitor.get_performance_stats("vector_search")
        # æ³¨æ„ï¼šç”±äºç¼“å­˜æœåŠ¡çš„é™åˆ¶ï¼Œè¿™é‡Œå¯èƒ½æ— æ³•è·å–åˆ°å®é™…çš„ç»Ÿè®¡æ•°æ®

    async def test_end_to_end_workflow(
        self,
        resource_service: ResourceLibraryService,
        vector_service: VectorSearchService,
        sample_document_content: str,
        performance_monitor: ResourcePerformanceMonitor,
    ) -> None:
        """æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹"""
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as f:
            f.write(sample_document_content)
            temp_file_path = f.name

        try:
            # 1. åˆ›å»ºå’Œå¤„ç†èµ„æº
            create_request = ResourceCreateRequest(
                name="ç«¯åˆ°ç«¯æµ‹è¯•æ–‡æ¡£",
                resource_type=ResourceType.TEXTBOOK,
                category="æµ‹è¯•",
                description="ç«¯åˆ°ç«¯æµ‹è¯•æ–‡æ¡£",
                permission_level=PermissionLevel.PUBLIC,
                file_path=temp_file_path,
                file_format="txt",
            )

            resource = await resource_service.create_resource(create_request, user_id=1)

            # 2. å¤„ç†æ–‡æ¡£
            processing_result = await resource_service.document_processing_service.process_large_document(
                resource.id, force_reprocess=True
            )

            assert processing_result.success

            # 3. æ‰§è¡Œå‘é‡æ£€ç´¢
            search_query = SearchQuery(
                query_text="å¬åŠ›ç†è§£æŠ€å·§",
                top_k=5,
                similarity_threshold=0.6,
                filters={"resource_ids": [resource.id]},
            )

            search_result = await vector_service.hybrid_search(search_query)

            # éªŒè¯æœç´¢ç»“æœ
            assert search_result is not None
            # æ³¨æ„ï¼šç”±äºæ˜¯æµ‹è¯•ç¯å¢ƒï¼Œå¯èƒ½æ²¡æœ‰å®é™…çš„å‘é‡æ•°æ®

            # 4. è·å–æ€§èƒ½æŠ¥å‘Š
            health_report = await performance_monitor.check_service_health()
            assert health_report["overall_status"] in ["healthy", "degraded", "unknown"]

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            Path(temp_file_path).unlink(missing_ok=True)


# è¿è¡Œæµ‹è¯•çš„è¾…åŠ©å‡½æ•°
async def run_integration_tests() -> None:
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    test_instance = TestResourceLibraryIntegration()

    print("ğŸš€ å¼€å§‹èµ„æºåº“æ¨¡å—é›†æˆæµ‹è¯•...")

    try:
        # è¿™é‡Œåº”è¯¥è®¾ç½®æµ‹è¯•æ•°æ®åº“å’Œç¼“å­˜æœåŠ¡
        # ç”±äºç¯å¢ƒé™åˆ¶ï¼Œè¿™é‡Œåªæ˜¯ç¤ºä¾‹

        print("âœ… é›†æˆæµ‹è¯•å®Œæˆ")

    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {str(e)}")
        raise


if __name__ == "__main__":
    asyncio.run(run_integration_tests())
